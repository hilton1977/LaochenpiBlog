{"meta":{"title":"老陈皮加工厂","subtitle":null,"description":null,"author":"老陈皮","url":"http://laochenpi.top"},"pages":[],"posts":[{"title":"Linux 字体背景颜色设置","slug":"Linux-字体背景颜色设置","date":"2019-08-08T07:18:38.000Z","updated":"2019-08-09T07:39:39.320Z","comments":true,"path":"2019/08/08/Linux-字体背景颜色设置/","link":"","permalink":"http://laochenpi.top/2019/08/08/Linux-字体背景颜色设置/","excerpt":"","text":"颜色范围 例如我们打印红色警告字体 echo -e &#39;\\033[31m[警告]红色警告提示\\031[0m&#39;其中\\033[31m为红色颜色 颜色设置12345678echo -e \"\\033[40;37m oldboy trainning \\033[0m\" 黑底白字（字体颜色匹配上面的，自己更改）echo -e \"\\033[41;37m oldboy trainning \\033[0m\" 红底白字echo -e \"\\033[42;37m oldboy trainning \\033[0m\" 绿底白字echo -e \"\\033[43;37m oldboy trainning \\033[0m\" 黄底白字echo -e \"\\033[44;37m oldboy trainning \\033[0m\" 蓝底白字echo -e \"\\033[45;37m oldboy trainning \\033[0m\" 紫底白字echo -e \"\\033[46;37m oldboy trainning \\033[0m\" 天蓝白字echo -e \"\\033[47;30m oldboy trainning \\033[0m\" 白底黑字","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 中判断条件","slug":"Linux-中判断条件","date":"2019-08-08T02:38:34.000Z","updated":"2019-08-09T07:11:31.105Z","comments":true,"path":"2019/08/08/Linux-中判断条件/","link":"","permalink":"http://laochenpi.top/2019/08/08/Linux-中判断条件/","excerpt":"","text":"学习记录下 Linux下判断条件 便于回来翻查 if 基本语法1234567if [comand];then 执行语句elif[comand];then 执行语句else 执行语句fi 文件判断[-d File] 存在且为文件夹[-f File] 存在且为普通文件[-s File] 存在且大小不为0[-x File] 存在且为可执行[-r File] 存在且为可读[-w File] 存在且为写 字符串判断[-z String] 是否为空长度为0[-n String] 是否为非空 non-zero[String] 是否为非空与[-n String]一样的功能[String1 == String2] String 是否相等[String1 != String2] String 是否不相等 数字判断[Int1 -eq Int2] 是否相等[Int1 -ne Int2] 是否不相等[Int1 -gt Int2] 是否大于[Int1 -lt Int2] 是否小于[Int1 -ge Int2] 是否大于等于[Int1 -le Int2] 是否小于等于 逻辑连接符-a 且 &amp;&amp;-o 或者 ||! 非","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"VPS 一键搭建脚本","slug":"VPS-一键搭建脚本","date":"2019-08-07T02:49:11.000Z","updated":"2019-08-08T06:38:45.328Z","comments":true,"path":"2019/08/07/VPS-一键搭建脚本/","link":"","permalink":"http://laochenpi.top/2019/08/07/VPS-一键搭建脚本/","excerpt":"","text":"每次换VPS我都要重新手打下脚本去装V2Ray2，然后装各种软件环境还要把自己的博客搬过来真的麻烦，重复的动作让人枯燥所以想起编写个脚本一键执行，懒人就用懒方法 脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576start_menu()&#123; echo \"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 小明 VPS 管理一键脚本 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"echo \"1 - V2Ray管理脚本\"echo \"2 - BBR 加速脚本\"echo \"3 - 老陈皮 Blog 环境搭建\"echo \"4 - 退出脚本\"echoread -p \"请输入数字:\" numcase \"$num\" in 1) v2ray_manager ;;2) bbr_manager ;;3) install_blog ;;4) exit 0 ;;*) echo&amp;&amp;echo \"无法找到对应脚本执行3s后回到主界面\"&amp;&amp;sleep 3s&amp;&amp;start_menu ;;esac &#125;# 安装V2Rayv2ray_manager()&#123; echo echo '&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; V2Ray管理脚本 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;' echo '1 - 启动服务' echo '2 - 停止服务' echo '3 - 重启服务' echo '4 - 查看配置' echo '5 - 退出脚本' echo read -p \"请输入数字:\" num case $num in 1) systemctl start v2ray || v2ray_manager ;; 2) systemctl stop v2ray || v2ray_manager ;; 3) systemctl start v2ray || v2ray_manager ;; 4) echo$(cat /etc/v2ray/config.json) || v2ray_manager ;; 5) start_menu ;; *) echo&amp;&amp;echo \"无法找到对应脚本执行3s后回到主界面\" &amp;&amp; sleep 3s &amp;&amp; v2ray_manager ;; esac&#125;bbr_manager()&#123; echo '&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; BBR加速模块配置 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;' echo bash &lt;(curl -s https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh) start_menu&#125;install_blog()&#123; echo '安装老陈皮'&#125;start_menu","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"心得","slug":"心得","permalink":"http://laochenpi.top/tags/心得/"}]},{"title":"Java 排序方法总结","slug":"Java-排序方法总结","date":"2019-07-25T08:42:11.000Z","updated":"2019-08-01T01:16:48.926Z","comments":true,"path":"2019/07/25/Java-排序方法总结/","link":"","permalink":"http://laochenpi.top/2019/07/25/Java-排序方法总结/","excerpt":"","text":"经常项目中会遇到排序问题面试也会问，收集下各种排序思想和代码实现以便加深记忆 插入排序 （Insertion Sort）将数组中所有的元素依次跟之前的元素相比较，如遇到比自身小的元素则进行交换直到比较所有元素 代码实现123456789101112131415161718192021public static void main(String[] args) &#123; int[] insert_sort = new int[]&#123;55, 2, 23, 98, 35&#125;; System.out.println(\"未排序\" + Arrays.toString(insert_sort)); /** * 外循环取出移动元素 */ for (int i = 1; i &lt; insert_sort.length; i++) &#123; int comparativeValue = insert_sort[i]; /** * 内循环比较值前所有元素进行对比 * 小于则进行位置后移直到所有元素比较完毕或遇到大于等于的元素进去插入 */ int j = i; while (j &gt; 0 &amp;&amp; insert_sort[j - 1] &gt; comparativeValue) &#123; insert_sort[j] = insert_sort[j - 1]; j--; &#125; insert_sort[j] = comparativeValue; System.out.println(\"第\" + i + \"次移动元素\" + comparativeValue + \"后\" + Arrays.toString(insert_sort)); &#125; &#125; 平均时间复杂度 最好情况 最坏情况 空间复杂度 $O(n^2)$ $O(n)$ $O(n^2)$ O(1) 希尔排序（Shell Sort）希尔排序又称递减增量排序算法属于插入排序改进版，算法思想为讲整个待排序记录分割为若干个子序列进行直接插入排序，然后再对所有子序列进行直接插入排序 冒泡排序快速排序","categories":[],"tags":[]},{"title":"学习红黑树","slug":"学习红黑树","date":"2019-07-25T01:55:02.000Z","updated":"2019-07-30T02:19:44.956Z","comments":true,"path":"2019/07/25/学习红黑树/","link":"","permalink":"http://laochenpi.top/2019/07/25/学习红黑树/","excerpt":"","text":"二叉查找树二叉查找树（binary search tree）也称为有序二叉树（order binary tree）或排序二叉树（sorted binary tree） 若任意节点的左子树不空，则左子树的所有结点的值都小于它们的根节点 若任意节点的右子树不空，则右子树的所有结点的值都大于它们的根节点 没有键值相等的节点（no duplicate nodes） 由 $n$ 个节点构造的二叉树的高度为 $lgn$ 空间复杂度为 $O(lgn)$，当树不再平衡退化成一颗 $n$ 个节点的线性链后，空间复杂度则为 $O(n)$ 红黑树红黑树（red black tree）也称为平衡二叉B树（symmetric binary B-trees）通过特殊操作保持二叉查找树的平衡，插入、删除、查找的空间复杂度为 $O(lgn)$，一个 $n$ 个节点的红黑树的高度为 $2log(n+1)$，高度为 $h$ 的红黑树包含的节点至少为 $2^{bh(x)}-1$ 个 每个节点的颜色是红色或黑色 根节点的颜色始终是黑色 每个红色节点的子节点必然是两个黑色 每个叶子到根的所有路径上不能有两个连续的红色节点 树的旋转红黑树在进入插入或者删除操作后可能会违背红黑树的性质，为了保证其平衡性需要通过改变节点颜色和结构使其继续保持其特性，改变树结构的操作称为树的旋转 左旋pivot节点进行左旋，pivot的右子节点成为新父节点且其左子节点成为左旋节点右子节点 右旋pivot节点进行右旋，pivot的左子节点成为新父节点且其右子节点成为右旋节点的左子节点","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"复习","slug":"复习","permalink":"http://laochenpi.top/tags/复习/"}]},{"title":"fast-fail 和 fast-safe的区别","slug":"fast-fail和fast-safe的区别","date":"2019-07-24T03:25:10.000Z","updated":"2019-07-30T02:24:26.742Z","comments":true,"path":"2019/07/24/fast-fail和fast-safe的区别/","link":"","permalink":"http://laochenpi.top/2019/07/24/fast-fail和fast-safe的区别/","excerpt":"","text":"回头复习下一些面试常见的一些问题 fast-fail 和 fast-safe 两种机制 fast-failfast-fail 快速失败，在java.util包下的集合进行迭代遍历时会调用checkForComodification方法检查，当modCount != expectedModCount时会抛出ConcurrentModificationException异常1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; 注意在多线程环境下并发操作集合可能会导致modCount与expectedModCount的值和预期不一致导致条件判断通过不会抛出异常，因此在多线程环境下应该使用java.concurrent包下的集合 fast-safefast-safe 安全失败，任何对集合结构的修改都会在一个复制的集合上进行修改，因此不会抛出ConcurrentModificationException 注意由于 fast-safe 遍历是采用了复制原有集合内容作为一个新的集合进行遍历，所以会带来更大的内存消耗且原始数据发现变化后是不能被迭代器所检测发现数据变化 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModificationException Yes No Clone Object No Yes Memory OverHead No Yes Examples ArrayList、HashMap、HashSet CopyOnWriteArrayList、ConcurrentHashMap","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"Java 集合总结","slug":"Java-集合总结","date":"2019-07-22T08:43:25.000Z","updated":"2019-07-24T02:18:14.266Z","comments":true,"path":"2019/07/22/Java-集合总结/","link":"","permalink":"http://laochenpi.top/2019/07/22/Java-集合总结/","excerpt":"","text":"记录回顾下 Java 集合内容，面试会经常会问到各种集合的特点和区别，在不同情况下合理使用集合处理数据 Java 集合Java 集合分为两大接口Collection（元素集合）、Map（键值对集合），根据两大接口又分为各类集合 Map 键值对Map 由 key 和 value 键值对组成，key 不重复存入重复的 key 会覆盖原有 value 集合 数据结构 是否有序 线程安全 特点 HashMap 数组和链表 无序 不安全 链表长度大于阈值8则转化成红黑树，小于6则转回链表 TreeMap red-black（红-黑）树 无序 不安全 映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序 LinkedHashMap 链表 有序 不安全 允许使用 Null 键值 Collection 集合List 接口List 代表有序的 Collection 且元素可以重复，用户对插入的元素位置精确把控，数组维护整个集合顺序，同时可以通过 index 下标直接访问相应的元素 集合 数据结构 是否有序 线程安全 特点 ArrayList 数组 有序 不安全 随机访问、查询效率高 Vector 数组 有序 安全 LinkedList 双向链表 有序 不安全 插入删除效率高，可从头尾顺序进行插入删除 Set 接口Set 代表无序的 Collection 且不包含重复元素，可以存入有且只有一个Null元素 集合 数据结构 是否有序 线程安全 特点 HashSet 简化版 HashMap 无序 不安全 内部由 HashMap 实现 key 为存入数据 Value 都为同一个 Object 对象，HashMap 的 key不可重复特性实现去重效果 TreeSet TreeMap 实现 无序 不安全 内部由 TreeMap 实现的有序二叉树，基本类型按照自然顺序排序，对象则根据 Comparator 进行自动排序 LinkedHashSet 双向链表 有序 不安全 HashSet 子类内部由链表来维护插入元素顺序","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"复习","slug":"复习","permalink":"http://laochenpi.top/tags/复习/"}]},{"title":"Maven 属性","slug":"Maven 属性","date":"2019-07-18T02:00:03.000Z","updated":"2019-07-24T02:17:00.437Z","comments":true,"path":"2019/07/18/Maven 属性/","link":"","permalink":"http://laochenpi.top/2019/07/18/Maven 属性/","excerpt":"","text":"Maven 内置属性Maven 预定义,用户可以直接使用 ${basedir} 表示项目根目录，即包含pom.xml文件目录 ${version} 表示项目版本 ${project.basedir} 同 ${basedir} ${project.baseUri} 表示项目文件地址 ${maven.build.timestamp} 表示项目构件开始时间 Maven POM 属性使用 pom 属性可以引用到pom.xml文件对应元素的值 ${project.build.directory} 表示主源码路径 ${project.build.sourceEncoding} 表示主源码的编码格式 ${project.build.sourceDirectory} 表示主源码路径 ${project.build.finalName} 表示输出文件名称 ${project.version} 表示项目版本,与${version}相同 Maven 自定义属性通过在pom.xml定义属性可以在其他地方引用通常在项目中用于定义引入jar的版本等123456789&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;version.spring&gt;3.2.9.RELEASE&lt;/version.spring&gt; &lt;version.jackson&gt;2.4.4&lt;/version.jackson&gt; &lt;java.version&gt;1.7&lt;/java.version&gt; &lt;log4j2.version&gt;2.6.2&lt;/log4j2.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt; 环境变量属性所有的环境变量都可以用以env.开头的 Maven 属性引用，所有的环境变量都可以用以env.开头的Maven属性引用，${env.JAVA_HOME}表示JAVA_HOME环境变量的值 参考如下：http://maven.apache.org/guides/introduction/introduction-to-the-pom.htmlhttp://maven.apache.org/pom.htmlhttp://maven.apache.org/settings.html","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://laochenpi.top/tags/Maven/"}]},{"title":"V2Ray 搭建记录","slug":"V2Ray搭建记录","date":"2019-07-17T03:24:48.000Z","updated":"2019-08-01T01:25:02.343Z","comments":true,"path":"2019/07/17/V2Ray搭建记录/","link":"","permalink":"http://laochenpi.top/2019/07/17/V2Ray搭建记录/","excerpt":"","text":"Vultr 上次的一次特殊事件被封了，后来无意间看到了新的云梯 V2Ray 搭建起来更方便简单，搜了下教程重新搭建并记录 V2Ray 服务安装执行官网的一键脚本，执行完毕会自动安装好unzip与deamon软件，应用程序默认安装在/usr/bin/v2ray/v2ray，当有新版本发布只需再执行该脚本即可 1bash &lt;(curl -L -s https://install.direct/go.sh) V2Ray 配置文件安装完毕可以通过cat /etc/v2ray/config.json查看配置文件，可以通过vi命令修改保存配置文件达到自定义1234567891011121314151617181920212223242526272829303132&#123; \"inbounds\": [&#123; \"port\": 10067, \"protocol\": \"vmess\", \"settings\": &#123; \"clients\": [ &#123; \"id\": \"08e9a92c-8f5d-45ce-8791-44f0d13379e7\", \"level\": 1, \"alterId\": 64 &#125; ] &#125; &#125;], \"outbounds\": [&#123; \"protocol\": \"freedom\", \"settings\": &#123;&#125; &#125;,&#123; \"protocol\": \"blackhole\", \"settings\": &#123;&#125;, \"tag\": \"blocked\" &#125;], \"routing\": &#123; \"rules\": [ &#123; \"type\": \"field\", \"ip\": [\"geoip:private\"], \"outboundTag\": \"blocked\" &#125; ] &#125;&#125; 配置文件中的id、端口、alterId需要和客户端的配置保持一致 服务端使用脚本安装成功之后默认就是vmess协议 V2Ray 相关脚本第一次安装完毕V2Ray不会自行启动需要通过以下脚本启动、停止、查看状态123456## 启动systemctl start v2ray## 停止systemctl stop v2ray## 状态systemctl status v2ray 由于防火墙原因会导致启用了服务但是无法连接问题，需要把服务相关端口加入防火墙白名单1234567## 查看开启的端口firewall-cmd --zone=public --list-ports## 加入新端口 100067 80 端口firewall-cmd --zone=public --add-port=80/tcp --permanentfirewall-cmd --zone=public --add-port=10067/tcp --permanentfirewall-cmd --reload V2RayN 客户端下载 V2Ray-Core 解压点击v2rayN.exe应用添加Vmess服务器 填写完毕启用Http代理修改代理模式为PAC模式，然后就可以愉快的在上google，手机端可以使用v2rayNG BBR 加速搭建好了V2Ray你感觉速度不够快连接效果不够好，我们可以通过脚本开启BBR12345#安装wget，digitalocean默认没有安装wget，安装一下yum -y install wget#执行BBR PLUS修正版一键脚本wget -N --no-check-certificate \"https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh\" &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh 根据自身情况安装内核重启系统后安装BBR加速","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"心得","slug":"心得","permalink":"http://laochenpi.top/tags/心得/"}]},{"title":"Vue 复杂的 table 表单代码块","slug":"Vue复杂的table表单代码块","date":"2019-07-17T02:51:26.000Z","updated":"2019-07-17T03:21:03.201Z","comments":true,"path":"2019/07/17/Vue复杂的table表单代码块/","link":"","permalink":"http://laochenpi.top/2019/07/17/Vue复杂的table表单代码块/","excerpt":"","text":"记录项目中遇到的Element UI 中遇到的各种情况 代码块 Vue Form Table 双向绑定 form 和 table配合使用其中refundPsgList循环出来的元素在数据双向绑定上prop的值需要特殊改造，使用scope.$index来进行绑定，一般情况下prop和对应的v-model保持一致1234567891011121314151617181920212223242526272829&lt;el-form :model=\"refundCashDetail\" ref=\"refundCashDetail\"&gt; &lt;el-table :data=\"refundCashDetail.refundPsgList\" size=\"mini\" border style=\"width: 100%\"&gt; &lt;el-table-column width=\"60\" label=\"序号\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &#123;&#123; scope.$index + 1 &#125;&#125; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column prop=\"name\" label=\"姓名\" align=\"center\"&gt;&lt;/el-table-column&gt; &lt;el-table-column label=\"实际退定金\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-form-item :prop=\"'refundPsgList.'+ scope.$index +'.practicalCash'\" :inline-message=\"true\" :rules=\"[&#123; type: 'number',required:true,message:'金额不能为空',trigger: 'blur'&#125;]\"&gt; &lt;el-input-number :placeholder=\"scope.row.oneDeposit+'/每人'\" v-model.number=\"scope.row.practicalCash\" :max=\"refundCashDetail.orderDetail.oneDeposit\" autocomplete=\"off\" :min=\"0\"/&gt; &lt;/el-form-item&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt;&lt;/el-form&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"阿里巴巴诊断器","slug":"阿里巴巴诊断器","date":"2019-04-28T01:41:02.000Z","updated":"2019-04-30T03:40:52.866Z","comments":true,"path":"2019/04/28/阿里巴巴诊断器/","link":"","permalink":"http://laochenpi.top/2019/04/28/阿里巴巴诊断器/","excerpt":"","text":"Arthas 是阿里巴巴开源的一款 Java 诊断器，可查看Jvm运行状态、堆栈异常、Class运行加载情况反编译等 Arthas 安装Artas 建议安装使用arthas-boot.jar，安装地址 https://alibaba.github.io/arthas/arthas-boot.jar1234# Linux 下载wget https://alibaba.github.io/arthas/arthas-boot.jar# 运行java -jar arthas-boot.jar 运行可以查看到所有运行的java进程，可以通过Web Console进行调试，默认地址为 http://127.0.0.1:8563/ 也可以通过IP访问其他机器上的Arthas 命令分类基础命令 help——查看命令帮助信息 cat——打印文件内容，和linux里的cat命令类似 pwd——返回当前的工作目录，和linux命令类似 cls——清空当前屏幕区域 session——查看当前会话的信息 reset——重置增强类，将被Arthas增强过的类全部还原，Arthas服务端关闭时会重置所有增强过的类 version——输出当前目标 Java 进程所加载的 Arthas 版本号 history——打印命令历史 quit——退出当前Arthas客户端，其他Arthas客户端不受影响 shutdown——关闭Arthas服务端，所有Arthas客户端全部退出 keymap——Arthas快捷键列表及自定义快捷键 Jvm相关 dashboard——当前系统的实时数据面板 thread——查看当前 JVM 的线程堆栈信息 jvm——查看当前 JVM 的信息 sysprop——查看和修改JVM的系统属性 sysenv——查看JVM的环境变量 getstatic——查看类的静态属性 ognl——执行ognl表达式 常用指令123456789101112131415161718192021222324252627282930# 查看所有线程 无参thread# 查看前3最占用CPU线程堆栈thread -n 3 # 查看线程ID为5的堆栈thread 5# 查看阻塞的线程堆栈（只支持`synchronized`关键字阻塞的线程）threah -b# 查看某线程采样时间间隔thread 3 -i 3000# 查看Jvm属性的值 无参则是所有sysprpo [属性]# 查看Jvm环境变量 无参则是所有sysenv [属性]# 查看搜索所有加载的类 配合 * 模糊查询sc [通配符*]# 查找加载UserController的 ClassLoadersc -d *UserController | grep classLoaderHash# 查看某类的详情以及成员变量sc [类路径] -d -f# 查看某类的方法 配合 * 模糊查询 -d 显示详情sm [类路径] [方法名] -d# 反编译 默认情况下，反编译结果里会带有ClassLoader信息# 通过--source-only选项，可以只打印源代码。方便和mc/redefine命令结合使用# 使用 &gt; 指定路径生成文件jad [类路径] [方法名] &gt; [生成路径]# 监控器 -c 周期时间 默认值120秒 返回方法调用情况 monitor -c 30 [类路径] [方法名]# 观察类方法运行情况 分4种观察点 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后watch [类路径] [方法名] [ognl表达式] 详细的文档可以查看 https://alibaba.github.io/arthas/index.html","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"Http 知识","slug":"Http 知识","date":"2019-04-24T07:23:55.000Z","updated":"2019-07-24T07:08:18.529Z","comments":true,"path":"2019/04/24/Http 知识/","link":"","permalink":"http://laochenpi.top/2019/04/24/Http 知识/","excerpt":"","text":"记录一些常用的 Http 知识用于以后回来查询复习了解 Http 状态码当你请求服务器后会返回各种Http状态码用于表示请求状态，最常见的有404、500、200、304 2XX 成功处理请求200 （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。201 （已创建） 请求成功并且服务器创建了新的资源。202 （已接受） 服务器已接受请求，但尚未处理。203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。204 （无内容） 服务器成功处理了请求，但没有返回任何内容。205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。206 （部分内容） 服务器成功处理了部分 GET 请求。 3XX 请求完成，需要进一步操作300 （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 4XX 请求错误，无法处理400 （错误请求） 服务器不理解请求的语法。401 （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。403 （禁止） 服务器拒绝请求。404 （未找到） 服务器找不到请求的网页。405 （方法禁用） 禁用请求中指定的方法。406 （不接受） 无法使用请求的内容特性响应请求的网页。407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。408 （请求超时） 服务器等候请求时发生超时。409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。415 （不支持的媒体类型） 请求的格式不受请求页面的支持。416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。417 （未满足期望值） 服务器未满足”期望”请求标头字段的要求。 5XX 请求完成，但是服务器内部发生错误500 （服务器内部错误） 服务器遇到错误，无法完成请求。501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。502 （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。503 （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://laochenpi.top/tags/前端/"}]},{"title":"SpringMVC 运行原理","slug":"SpringMVC 工作原理","date":"2019-04-22T06:56:12.000Z","updated":"2019-04-24T01:59:31.001Z","comments":true,"path":"2019/04/22/SpringMVC 工作原理/","link":"","permalink":"http://laochenpi.top/2019/04/22/SpringMVC 工作原理/","excerpt":"","text":"面试经常会问到 SpringMVC 运行原理真是一脸懵逼，太细节的都不记得了就知道撸代码，现在记录并复习下。 SpringMVC 工作原理 用户通过浏览器访问项目，请求会发送到DispatcherServlet前端控制器 通过HandlerMapping找到对应的Controller对应注解@RequestMapping的值 根据Controller方法通过HandlerAdapter处理适配器查找handler HandlerAdapter执行适配的handler开始正式的业务逻辑执行 处理完业务会返回ModleAndView，Model为返回数据，View为返回的视图 根据View执行ViewResolver找到对应逻辑页面 DispatcherSerlvet会把Model传给View进行页面渲染 DispatcherServlet前端控制器是 SpringMVC 的核心是所有请求的入口函数，处理请求、转发请求、处理结果、返回结果，默认初始化一些HandlerAdapter、HandMapping、HandlerExceptionResolver等组件12345678static &#123; try &#123; ClassPathResource resource = new ClassPathResource(\"DispatcherServlet.properties\", DispatcherServlet.class); defaultStrategies = PropertiesLoaderUtils.loadProperties(resource); &#125; catch (IOException var1) &#123; throw new IllegalStateException(\"Could not load 'DispatcherServlet.properties': \" + var1.getMessage()); &#125; &#125; 读取DispatcherServlet.properties初始化使用的策略123456789101112131415protected void onRefresh(ApplicationContext context) &#123; this.initStrategies(context);&#125;protected void initStrategies(ApplicationContext context) &#123; this.initMultipartResolver(context); this.initLocaleResolver(context); this.initThemeResolver(context); this.initHandlerMappings(context); this.initHandlerAdapters(context); this.initHandlerExceptionResolvers(context); this.initRequestToViewNameTranslator(context); this.initViewResolvers(context); this.initFlashMapManager(context);&#125; 通过继承FrameworkServlet抽象类复写onRefresh方法，根据上下文ApplicationContext对象执行initStrategies初始化策略。 HandlerMapping根据请求的Url找到对应的Handler，即我们项目中平时所谓的Controller，我们可以通过配置文件、注解方式、实现接口方式。 BeanNameUrlHandlerMapping 通过bean名称或别名，必须已/开头和方法类必须实现Controller接口。 123456789&lt;bean name=\"/beanNameUrlController\" class=\"com.test.web.MessageControl\"/&gt;public class MessageControl implements Controller &#123; public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponseresponse) throws Exception &#123; ModelAndView mav = new ModelAndView(\"index\"); return mav; &#125;&#125; SimpleUrlHandlerMapping 123456789101112131415161718&lt;bean class=\"org.springframework.web.servlet.handler.SimpleUrlHandlerMapping\"&gt; &lt;property name=\"mappings\"&gt; &lt;props&gt; &lt;prop key=\"/test.do\"&gt;testController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"testController\" class=\"com.test.controller.SimpleUrlHandlerMappingController\" /&gt; public class SimpleUrlHandlerMappingController implements Controller &#123; protected final Log logger = LogFactory.getLog(this.getClass()); //@Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; logger.info(\"run here\"); return null;&#125; RequestMappingHandlerMapping 项目中最常用的一种配置方法，配合@Controller和@RequestMapping一起使用。 12345678910111213141516171819&lt;!-- 注册HandlerMapper、HandlerAdapter两个映射类 --&gt;&lt;mvc:annotation-driven /&gt; &lt;!-- 访问静态资源 --&gt;&lt;mvc:default-servlet-handler /&gt; &lt;!-- 配置扫描的包 --&gt;&lt;context:component-scan base-package=\"com.test.*\" /&gt; @RestController@RequestMapping(\"/hello\")public class HelloController &#123; protected final Log logger = LogFactory.getLog(this.getClass()); @RequestMapping(\"/index\") public String index()&#123; return \"test\";&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/tags/Spring/"}]},{"title":"JVM 对象创建过程","slug":"JVM 对象创建","date":"2019-04-17T13:01:28.000Z","updated":"2019-07-24T07:08:30.072Z","comments":true,"path":"2019/04/17/JVM 对象创建/","link":"","permalink":"http://laochenpi.top/2019/04/17/JVM 对象创建/","excerpt":"","text":"JVM 复习基本概念学习和记录 对象创建过程 类加载检查：遇到new指令时，先会检查下常量池是否存在该类的符号引用，并检查是否加载过、解析、和初始化过，如果没有则进行类加载过程。 分配内存：类加载检查通过，虚拟机会在Java 堆中为对象划分一块区域， 内存大小在类加载完成后确定，","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Jvm","slug":"Jvm","permalink":"http://laochenpi.top/tags/Jvm/"}]},{"title":"Redis 数据类型及应用场景","slug":"Redis数据类型及应用场景","date":"2019-04-10T08:19:30.000Z","updated":"2019-04-15T08:18:15.087Z","comments":true,"path":"2019/04/10/Redis数据类型及应用场景/","link":"","permalink":"http://laochenpi.top/2019/04/10/Redis数据类型及应用场景/","excerpt":"","text":"记录学习 Redis 的数据类型以及实际项目中的运用场景 Redis 存储类型Redis 面试经常会闻到支持那些存储类型，常用的类型有String、Hash、List、Set、Sorted Set等。 StringStrings 数据类结构是最简单的 Key-value类型，Value 的值根据执行的命令可为数值或字符串。 常用命令: set,get,decr,incr,mget 等。 应用场景：例如计数器功能incr可以运用于接口调用次数每次调用增加+1，配合decr每次减少-1，执行完毕会返回操作之后的值。 HashHash 键值对格式，适合存放对象信息例如用户信息，用户名ID对应的用户信息value。有时候我们使用的是序列化对象取出和存在都需要序列化消耗性能。 常用命令： hget,hset,hgetall ，Hash 实现有2种在数据量较小时会采用类似一维数组紧凑存储,对应的value的redisObject的encoding为zipmap，当数据足够大时内部会自动转化成真正HashMap结构，encoding为ht。 应用场景：例如用户信息、后台列表信息、用户的权限信息等。 ListList 链表，Redis 实现为一个双向链表，即可以反向查询和遍历，更方便操作但也带来更多的性能消耗。 常用命令: lpush,rpush,lpop,rpop,lrange等 应用场景：例如使用lrange可以做分页操作，一些列表信息展示，使用ltrim限制长度可限制最新N条数据。lpsuh、rpush添加数据，lpop、rpop删除数据。 SetSet 类似List的功能，主要功能可以去重当你不希望有重复数据可以使用，并且可以判断是否某数据是否在集合内还可以处理2个Set交集、并集、差集。 常用命令： sadd,spop,smembers,sunion等，实现方式是value永远为null的HashMap，通过计算Hash的方式来快速排重。 应用场景：例如用户权限公共的权限交集，微博里的共同好友、共同关注等。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://laochenpi.top/tags/redis/"}]},{"title":"SkyWalking 搭建记录","slug":"SkyWalking搭建记录","date":"2019-04-02T03:08:24.000Z","updated":"2019-04-23T08:01:45.635Z","comments":true,"path":"2019/04/02/SkyWalking搭建记录/","link":"","permalink":"http://laochenpi.top/2019/04/02/SkyWalking搭建记录/","excerpt":"","text":"记录搭建Skywalking 6.0过程和详细遇到的问题 SkyWalkingSkyWalking 是观察性分析平台和应用性能管理系统，提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。它是一款国产开源软件源码在github上，官方网站为 http://skywalking.apache.org/zh/ Github https://github.com/apache/incubator-skywalking/ AgentAgent探针项目里面包含skywalking-agent.jar，使用JavaAgent做字节码侵入，对代码无侵入，收集格式化数据然后通过Http或gRpc方式发送到SkyWalking Collector。通过agent.config配置探针 agent.namespace： 跨进程链路中的header，不同的namespace会导致跨进程的链路中断 agent.service_name：一个服务（项目）的唯一标识，这个字段决定了在sw的UI上的关于service的展示名称 agent.sample_n_per_3_secs：客户端采样率，默认是-1代表全采样 agent.authentication： 与collector进行通信的安全认证，需要同collector中配置相同 agent.ignore_suffix：忽略特定请求后缀的trace collector.backend_service：agent需要同collector进行数据传输的IP和端口 logging.level：agent记录日志级别 集成方式常用的Java项目运行方式Jar方式或者War通过容器启动，例如Tomcat Jar 配置JVM运行添加探针 -javaagent:[skywalking-agent.jar绝对路径] -Dskywalking.agent.application_code=[应用名] 多应用使用同一个Agent通过系统变量设置应用名称 Tomcat tomcat目录bin下的catalina脚本1234WindowCATALINA_OPTS = -javaagent:[skywalking-agent.jar绝对路径]LinuxCATALINA_OPTS=\"$CATALINA_OPTS -javaagent:[skywalking-agent.jar绝对路径]\"; export CATALINA_OPTS ConfigConfig文件夹中包含了application.yml配置文件，可以配置收集的数据存储方式，默认是h2一般使用elasticsearch作为存储方式。1234567891011storage: elasticsearch: nameSpace: es5-cluster clusterNodes: 192.168.105.13:9200 indexShardsNumber: 2 indexReplicasNumber: 0 # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: 2000 # Execute the bulk every 2000 requests bulkSize: 20 # flush the bulk every 20mb flushInterval: 10 # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: 2 # the number of concurrent requests 启动bin文件夹中的startup.bat或者start.sh根据系统来执行，会启动2个项目Skywalking-Collector用于收集数据并把数据存储到Es中，Skywalking-WebApp用于展示收集的数据，2个项目的日志在logs中记录生成，通过http://localhot:8080查看运行情况 注意事项 Skywalking 6.0 相对 5.0简化了配置项，数据落地添加了MySql方式，需要注意Elasticsearch要求的版本也不一样，从_5.X__到6.X Skywalking UI默认的登录密码为admin，可以在webapp.yml中自行配置 Skywalking-WebApp和Skywalking-Collector如果跟探针不在同一机器上，修改Collector的配置文件application.yml的host，以便于探针收集的数据能准确的发送到Collector，同时修改探针agent.config配置项collector.servers地址。 1234567891011121314151617core: default: restHost: 192.168.104.162 restPort: 12800 restContextPath: / gRPCHost: 192.168.104.162 gRPCPort: 11800 downsampling: - Hour - Day - Month # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted. recordDataTTL: 90 # Unit is minute minuteMetricsDataTTL: 90 # Unit is minute hourMetricsDataTTL: 36 # Unit is hour dayMetricsDataTTL: 45 # Unit is day monthMetricsDataTTL: 18 # Unit is month naming中的地址对应了webapp.yml中listOfServers: 127.0.0.1:12800，UI使用rest http通信对应配置文件的restHost和restPort，agent在大多数场景下使用gRpc方式通信，在语言不支持的情况下会使用http通信。 参考资料 http://www.primeton.com/read.php?id=2751","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"http://laochenpi.top/tags/中间件/"}]},{"title":"MySQL 千行命令","slug":"MySQL千行命令","date":"2019-04-01T06:31:10.000Z","updated":"2019-04-01T08:47:55.986Z","comments":true,"path":"2019/04/01/MySQL千行命令/","link":"","permalink":"http://laochenpi.top/2019/04/01/MySQL千行命令/","excerpt":"","text":"转载 https://github.com/Snailclimb/JavaGuide 项目中收集的各类 MySQL 指令 基本操作 数据库操作 表的操作 字符集编码 数据类型(列类型) 列属性(列约束) 建表规范 UNION 子查询 连接查询(join) TRUNCATE 备份与还原 视图 事务(transaction) 锁表 触发器 SQL编程 存储过程 用户和权限管理 表维护 杂项 基本操作123456789/* Windows服务 */-- 启动MySQLnet start mysql-- 创建Windows服务sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)/* 连接与断开服务器 */mysql -h 地址 -P 端口 -u 用户名 -p 密码SHOW PROCESSLIST -- 显示哪些线程正在运行SHOW VARIABLES -- 显示系统变量信息 数据库操作12345678910111213141516171819/* 数据库操作 */ -------------------- 查看当前数据库SELECT DATABASE();-- 显示当前时间、用户名、数据库版本SELECT now(), user(), version();-- 创建库CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项# 数据库选项： CHARACTER SET charset_name COLLATE collation_name-- 查看已有库SHOW DATABASES[ LIKE 'PATTERN']-- 查看当前库信息SHOW CREATE DATABASE 数据库名-- 修改库的选项信息ALTER DATABASE 库名 选项信息-- 删除库DROP DATABASE[ IF EXISTS] 数据库名# 同时删除该数据库相关的目录及其目录内容 表的操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677-- 创建表CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项] 每个字段必须有数据类型 最后一个字段后不能有逗号 TEMPORARY 临时表，会话结束时表自动消失 对于字段的定义： 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string'] -- 表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 &#123;LOGS|STATUS&#125; -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = '目录' -- 索引文件目录 INDEX DIRECTORY = '目录' -- 表注释 COMMENT = 'string' -- 分区选项 PARTITION BY ... (详细见手册)-- 查看所有表 SHOW TABLES[ LIKE 'pattern'] SHOW TABLES FROM 库名-- 查看表机构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE 'PATTERN'] SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']-- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项 eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构（13.1.2. ALTER TABLE语法） ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键-- 删除表DROP TABLE[ IF EXISTS] 表名 ...-- 清空表数据TRUNCATE [TABLE] 表名-- 复制表结构CREATE TABLE 表名 LIKE 要复制的表名-- 复制表结构和数据CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名-- 检查表是否有错误CHECK TABLE tbl_name [, tbl_name] ... [option] ...-- 优化表OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...-- 修复表REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]-- 分析表ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... 字符集编码1234567891011121314151617181920/* 字符集编码 */ -------------------- MySQL、数据库、表、字段均可设置编码-- 数据编码与客户端编码不需一致SHOW VARIABLES LIKE 'character_set_%' -- 查看所有字符集编码项 character_set_client 客户端向服务器发送数据时使用的编码 character_set_results 服务器端将结果返回给客户端所使用的编码 character_set_connection 连接层编码 SET 变量名 = 变量值 SET character_set_client = gbk; SET character_set_results = gbk; SET character_set_connection = gbk;SET NAMES GBK; -- 相当于完成以上三个设置-- 校对集 校对集用以排序 SHOW CHARACTER SET [LIKE 'pattern']/SHOW CHARSET [LIKE 'pattern'] 查看所有字符集 SHOW COLLATION [LIKE 'pattern'] 查看所有校对集 CHARSET 字符集编码 设置字符集编码 COLLATE 校对集编码 设置校对集编码 数据类型(列类型)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/* 数据类型（列类型） */ ------------------1. 数值类型-- a. 整型 ---------- 类型 字节 范围（有符号位） tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255 smallint 2字节 -32768 ~ 32767 mediumint 3字节 -8388608 ~ 8388607 int 4字节 bigint 8字节 int(M) M表示总位数 - 默认存在符号位，unsigned 属性修改 - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数'123'，补填后为'00123' - 在满足要求的情况下，越小越好。 - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。 -- b. 浮点型 ---------- 类型 字节 范围 float(单精度) 4字节 double(双精度) 8字节 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。 -- c. 定点数 ---------- decimal -- 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。 2. 字符串类型-- a. char, varchar ---------- char 定长字符串，速度快，但浪费空间 varchar 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3 -- b. blob, text ---------- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值 -- c. binary, varbinary ---------- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob. 3. 日期时间类型 一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。 datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3字节 日期 1000-01-01 到 9999-12-31 timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07 time 3字节 时间 -838:59:59 到 838:59:59 year 1字节 年份 1901 - 2155 datetime YYYY-MM-DD hh:mm:ss timestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmss date YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDD time hh:mm:ss hhmmss hhmmss year YYYY YY YYYY YY4. 枚举和集合-- 枚举(enum) ----------enum(val1, val2, val3...) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。 -- 集合（set） ----------set(val1, val2, val3...) create table tab ( gender set('男', '女', '无') ); insert into tab values ('男, 女'); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。 列属性(列约束)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* 列属性（列约束） */ ------------------1. PRIMARY 主键 - 能唯一标识记录的字段，可以作为主键。 - 一个表只能有一个主键。 - 主键具有唯一性。 - 声明字段时，用 primary key 标识。 也可以在字段列表之后声明 例：create table tab ( id int, stu varchar(10), primary key (id)); - 主键字段的值不能为null。 - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age)); 2. UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。 3. NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, 'val'); -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null 4. DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, 'val'); -- 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp ); -- 表示将当前时间的时间戳设为默认值。 current_date, current_time 5. AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x; 6. COMMENT 注释 例：create table tab ( id int ) comment '注释内容'; 7. FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id); -- 将表t1的t1_id外键关联到表t2的id字段。 -- 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束： 语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 3. restrict，拒绝父表删除和更新。 注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。 建表规范1234567891011121314151617/* 建表规范 */ ------------------ -- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表 -- 1NF, 第一范式 字段不能再分，就满足第一范式。 -- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除符合主键就可以避免部分依赖。增加单列关键字。 -- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。 UNION12345678/* UNION */ ------------------ 将多个select查询的结果组合成一个结果集合。 SELECT ... UNION [ALL|DISTINCT] SELECT ... 默认 DISTINCT 方式，即所有返回的行都是唯一的 建议，对每个SELECT查询加上小括号包裹。 ORDER BY 排序时，需加上 LIMIT 进行结合。 需要各select查询的字段数量一样。 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。 子查询12345678910111213141516171819202122232425262728293031323334/* 子查询 */ ------------------ - 子查询需用括号包裹。 -- from型 from后要求是一个表，必须给子查询结果取个别名。 - 简化每个查询内的条件。 - from型需将结果生成一个临时表格，可用以原表的锁定的释放。 - 子查询返回一个表，表型子查询。 select * from (select * from tb where id&gt;0) as subfrom where id&gt;1; -- where型 - 子查询返回一个值，标量子查询。 - 不需要给子查询取别名。 - where子查询内的表，不能直接用以更新。 select * from tb where money = (select max(money) from tb); -- 列子查询 如果子查询结果返回的是一列。 使用 in 或 not in 完成查询 exists 和 not exists 条件 如果子查询返回数据，则返回1或0。常用于判断条件。 select column1 from t1 where exists (select * from t2); -- 行子查询 查询条件是一个行。 select * from t1 where (id, gender) in (select id, gender from t2); 行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 -- 特殊运算符 != all() 相当于 not in = some() 相当于 in。any 是 some 的别名 != some() 不等同于 not in，不等于其中某一个。 all, some 可以配合其他运算符一起使用。 连接查询(join)123456789101112131415161718192021222324252627/* 连接查询(join) */ ------------------ 将多个表的字段进行连接，可以指定连接条件。 -- 内连接(inner join) - 默认就是内连接，可省略inner。 - 只有数据存在时才能发送连接。即连接结果不能出现空行。 on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真） 也可用where表示连接条件。 还有 using, 但需字段名相同。 using(字段名) -- 交叉连接 cross join 即，没有条件的内连接。 select * from tb1 cross join tb2; -- 外连接(outer join) - 如果数据不存在，也会出现在连接结果中。 -- 左外连接 left join 如果数据不存在，左表记录会出现，而右表为null填充 -- 右外连接 right join 如果数据不存在，右表记录会出现，而左表为null填充 -- 自然连接(natural join) 自动判断连接条件完成连接。 相当于省略了using，会自动查找相同字段名。 natural join natural left join natural right joinselect info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id; TRUNCATE123456789/* TRUNCATE */ ------------------TRUNCATE [TABLE] tbl_name清空数据删除重建表区别：1，truncate 是删除表再创建，delete 是逐条删除2，truncate 重置auto_increment的值。而delete不会3，truncate 不知道删除了几条，而delete知道。4，当被用于带分区的表时，truncate 会保留分区 备份与还原1234567891011121314151617181920212223/* 备份与还原 */ ------------------备份，将数据的结构与表内数据保存起来。利用 mysqldump 指令完成。-- 导出mysqldump [options] db_name [tables]mysqldump [options] ---database DB1 [DB2 DB3...]mysqldump [options] --all--database1. 导出一张表 mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql)2. 导出多张表 mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql)3. 导出所有表 mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql)4. 导出一个库 mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 &gt; 文件名(D:/a.sql)可以-w携带WHERE条件-- 导入1. 在登录mysql的情况下： source 备份文件2. 在不登录的情况下 mysql -u用户名 -p密码 库名 &lt; 备份文件 视图1234567891011121314151617181920212223242526272829303132333435什么是视图： 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 视图具有表结构文件，但不存在数据文件。 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。-- 创建视图CREATE [OR REPLACE] [ALGORITHM = &#123;UNDEFINED | MERGE | TEMPTABLE&#125;] VIEW view_name [(column_list)] AS select_statement - 视图名必须唯一，同时不能与表重名。 - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。 - 可以指定视图执行的算法，通过ALGORITHM指定。 - column_list如果存在，则数目必须等于SELECT语句检索的列数 -- 查看结构 SHOW CREATE VIEW view_name -- 删除视图 - 删除视图后，数据依然存在。 - 可同时删除多个视图。 DROP VIEW [IF EXISTS] view_name ... -- 修改视图结构 - 一般不修改视图，因为不是所有的更新视图都会映射到表上。 ALTER VIEW view_name [(column_list)] AS select_statement -- 视图作用 1. 简化业务逻辑 2. 对客户端隐藏真实的表结构 -- 视图算法(ALGORITHM) MERGE 合并 将视图的查询语句，与外部查询需要先合并再执行！ TEMPTABLE 临时表 将视图执行完毕后，形成临时表，再做外层查询！ UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。 事务(transaction)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 - 支持连续SQL的集体成功或集体撤销。 - 事务是数据库在数据晚自习方面的一个功能。 - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。 - InnoDB被称为事务安全型引擎。 -- 事务开启 START TRANSACTION; 或者 BEGIN; 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。 -- 事务提交 COMMIT; -- 事务回滚 ROLLBACK; 如果部分操作发生问题，映射到事务开启前。 -- 事务的特性 1. 原子性（Atomicity） 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2. 一致性（Consistency） 事务前后数据的完整性必须保持一致。 - 事务开始和结束时，外部数据一致 - 在整个事务过程中，操作是连续的 3. 隔离性（Isolation） 多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。 4. 持久性（Durability） 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。 -- 事务的实现 1. 要求是事务支持的表类型 2. 执行一组相关的操作前开启事务 3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。 -- 事务的原理 利用InnoDB的自动提交(autocommit)特性完成。 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。 -- 注意 1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。 2. 事务不能被嵌套 -- 保存点 SAVEPOINT 保存点名称 -- 设置一个事务保存点 ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 RELEASE SAVEPOINT 保存点名称 -- 删除保存点 -- InnoDB自动提交特性设置 SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。 - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。 - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是， SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接) 而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务) 锁表1234567/* 锁表 */表锁定只用于防止其它客户端进行不正当地读取和写入MyISAM 支持表锁，InnoDB 支持行锁-- 锁定 LOCK TABLES tbl_name [AS alias]-- 解锁 UNLOCK TABLES 触发器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* 触发器 */ ------------------ 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象 监听：记录的增加、修改、删除。 -- 创建触发器CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 参数： trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。 trigger_event指明了激活触发程序的语句的类型 INSERT：将新行插入表时激活触发程序 UPDATE：更改某一行时激活触发程序 DELETE：从表中删除某一行时激活触发程序 tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。 trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构 -- 删除DROP TRIGGER [schema_name.]trigger_name可以使用old和new代替旧的和新的数据 更新操作，更新前是old，更新后是new. 删除操作，只有old. 增加操作，只有new.-- 注意 1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。 -- 字符连接函数concat(str1,str2,...])concat_ws(separator,str1,str2,...)-- 分支语句if 条件 then 执行语句elseif 条件 then 执行语句else 执行语句end if;-- 修改最外层语句结束符delimiter 自定义结束符号 SQL语句自定义结束符号delimiter ; -- 修改回原来的分号-- 语句块包裹begin 语句块end-- 特殊的执行1. 只要添加记录，就会触发程序。2. Insert into on duplicate key update 语法会触发： 如果没有重复记录，会触发 before insert, after insert; 如果有重复记录并更新，会触发 before insert, before update, after update; 如果有重复记录但是没有发生更新，则触发 before insert, before update3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert SQL编程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/* SQL编程 */ --------------------// 局部变量 ------------ 变量声明 declare var_name[,...] type [default value] 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。-- 赋值 使用 set 和 select into 语句为变量赋值。 - 注意：在函数内是可以使用全局变量（用户自定义的变量）--// 全局变量 ------------ 定义、赋值set 语句可以定义并为变量赋值。set @var = value;也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。select @var:=20;select @v1:=id, @v2=name from t1 limit 1;select * from tbl_name where @var:=30;select into 可以将表中查询获得的数据赋给变量。 -| select max(height) into @max_height from tb;-- 自定义变量名为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。@var=10; - 变量被定义后，在整个会话周期都有效（登录到退出）--// 控制结构 ------------ if语句if search_condition then statement_list [elseif search_condition then statement_list]...[else statement_list]end if;-- case语句CASE value WHEN [compare-value] THEN result[WHEN [compare-value] THEN result ...][ELSE result]END-- while循环[begin_label:] while search_condition do statement_listend while [end_label];- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave 退出当前循环 iterate 通过退出的标签决定退出哪个循环--// 内置函数 ------------ 数值函数abs(x) -- 绝对值 abs(-10.9) = 10format(x, d) -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46ceil(x) -- 向上取整 ceil(10.1) = 11floor(x) -- 向下取整 floor (10.1) = 10round(x) -- 四舍五入去整mod(m, n) -- m%n m mod n 求余 10%3=1pi() -- 获得圆周率pow(m, n) -- m^nsqrt(x) -- 算术平方根rand() -- 随机数truncate(x, d) -- 截取d位小数-- 时间日期函数now(), current_timestamp(); -- 当前日期时间current_date(); -- 当前日期current_time(); -- 当前时间date('yyyy-mm-dd hh:ii:ss'); -- 获取日期部分time('yyyy-mm-dd hh:ii:ss'); -- 获取时间部分date_format('yyyy-mm-dd hh:ii:ss', '%d %y %a %d %m %b %j'); -- 格式化时间unix_timestamp(); -- 获得unix时间戳from_unixtime(); -- 从时间戳获得时间-- 字符串函数length(string) -- string长度，字节char_length(string) -- string的字符个数substring(str, position [,length]) -- 从str的position开始,取length个字符replace(str ,search_str ,replace_str) -- 在str中用replace_str替换search_strinstr(string ,substring) -- 返回substring首次在string中出现的位置concat(string [,...]) -- 连接字串charset(str) -- 返回字串字符集lcase(string) -- 转换成小写left(string, length) -- 从string2中的左边起取length个字符load_file(file_name) -- 从文件读取内容locate(substring, string [,start_position]) -- 同instr,但可指定开始位置lpad(string, length, pad) -- 重复用pad加在string开头,直到字串长度为lengthltrim(string) -- 去除前端空格repeat(string, count) -- 重复count次rpad(string, length, pad) --在str后用pad补充,直到长度为lengthrtrim(string) -- 去除后端空格strcmp(string1 ,string2) -- 逐字符比较两字串大小-- 流程函数case when [condition] then result [when [condition] then result ...] [else result] end 多分支if(expr1,expr2,expr3) 双分支。-- 聚合函数count()sum();max();min();avg();group_concat()-- 其他常用函数md5();default();--// 存储函数，自定义函数 ------------ 新建 CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型 函数体 - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。 - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。 - 参数部分，由\"参数名\"和\"参数类型\"组成。多个参数用逗号隔开。 - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。 - 多条语句应该使用 begin...end 语句块包含。 - 一定要有 return 返回值语句。-- 删除 DROP FUNCTION [IF EXISTS] function_name;-- 查看 SHOW FUNCTION STATUS LIKE 'partten' SHOW CREATE FUNCTION function_name;-- 修改 ALTER FUNCTION function_name 函数选项--// 存储过程，自定义功能 ------------ 定义存储存储过程 是一段代码（过程），存储在数据库中的sql组成。一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。-- 创建CREATE PROCEDURE sp_name (参数列表) 过程体参数列表：不同于函数的参数列表，需要指明参数类型IN，表示输入型OUT，表示输出型INOUT，表示混合型注意，没有返回值。 存储过程12345678910111213141516/* 存储过程 */ ------------------存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。调用：CALL 过程名-- 注意- 没有返回值。- 只能单独调用，不可夹杂在其他语句中-- 参数IN|OUT|INOUT 参数名 数据类型IN 输入：在调用过程中，将数据输入到过程体内部的参数OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端INOUT 输入输出：既可输入，也可输出-- 语法CREATE PROCEDURE 过程名 (参数列表)BEGIN 过程体END 用户和权限管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/* 用户和权限管理 */ -------------------- root密码重置1. 停止MySQL服务2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &amp; [Windows] mysqld --skip-grant-tables3. use mysql;4. UPDATE `user` SET PASSWORD=PASSWORD(\"密码\") WHERE `user` = \"root\";5. FLUSH PRIVILEGES;用户信息表：mysql.user-- 刷新权限FLUSH PRIVILEGES;-- 增加用户CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。 - 只能创建用户，不能赋予权限。 - 用户名，注意引号：如 'user_name'@'192.168.1.1' - 密码也需引号，纯数字密码也要加引号 - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD-- 重命名用户RENAME USER old_user TO new_user-- 设置密码SET PASSWORD = PASSWORD('密码') -- 为当前用户设置密码SET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码-- 删除用户DROP USER 用户名-- 分配权限/添加用户GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] 'password'] - all privileges 表示所有权限 - *.* 表示所有库的所有表 - 库名.表名 表示某库下面的某表 GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817';-- 查看权限SHOW GRANTS FOR 用户名 -- 查看当前用户权限 SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();-- 撤消权限REVOKE 权限列表 ON 表名 FROM 用户名REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限-- 权限层级-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 当使用REVOKE时，您必须指定与被授权列相同的列。-- 权限列表ALL [PRIVILEGES] -- 设置除GRANT OPTION之外的所有简单权限ALTER -- 允许使用ALTER TABLEALTER ROUTINE -- 更改或取消已存储的子程序CREATE -- 允许使用CREATE TABLECREATE ROUTINE -- 创建已存储的子程序CREATE TEMPORARY TABLES -- 允许使用CREATE TEMPORARY TABLECREATE USER -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。CREATE VIEW -- 允许使用CREATE VIEWDELETE -- 允许使用DELETEDROP -- 允许使用DROP TABLEEXECUTE -- 允许用户运行已存储的子程序FILE -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILEINDEX -- 允许使用CREATE INDEX和DROP INDEXINSERT -- 允许使用INSERTLOCK TABLES -- 允许对您拥有SELECT权限的表使用LOCK TABLES","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/tags/数据库/"},{"name":"文档","slug":"文档","permalink":"http://laochenpi.top/tags/文档/"}]},{"title":"Java8 Stream 流操作","slug":"Stream流操作","date":"2019-03-29T02:06:00.000Z","updated":"2019-04-01T08:56:13.002Z","comments":true,"path":"2019/03/29/Stream流操作/","link":"","permalink":"http://laochenpi.top/2019/03/29/Stream流操作/","excerpt":"","text":"记录下 stream 流操作相关代码和一些细节问题。 Stream(流)Stream 流基本特性，不改变源数据、延迟执行、不存在数据，可简化代码可读性更高、美观、干净。有代码洁癖的小伙伴赶紧使用起来，它支持筛选、排序、聚合等，Stream 的聚合、消费、收集等操作只能进行一次。 常用方法12345678910111213141516171819202122232425262728293031List&lt;String&gt; strings = Arrays.asList(\"3\",\"1\",\"2\", \"4\");# filter 筛选操作int count = strings.stream() .filter(string -&gt; string.isEmpty()) .count();# limit 数量限制strings.stream() .limit(5) .forEach(System.out::println);# map 将每个元素映射为其他strings.stream() .map(string-&gt;string+\"s\") .collect(Collectors.toList());# skip 忽略前N个元素strings.stream() .skip(2) .collect(Collectors.toList());# distinct 去重 非基本类型需要重写 hashcode equals 方法strings.stream() .distinct() .forEach(System.out::println);# sorted 排序 非基本类型需要重写 hashcode equals 方法strings.stream() .sorted(Comparator.comparing(s -&gt; s)) .forEach(System.out::println);","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"String 类和常量池","slug":"String类和常量池","date":"2019-03-28T08:09:24.000Z","updated":"2019-07-24T07:08:51.749Z","comments":true,"path":"2019/03/28/String类和常量池/","link":"","permalink":"http://laochenpi.top/2019/03/28/String类和常量池/","excerpt":"","text":"面试经常会问到””创建的String和通过new String创建有什么不同。 String 类和常量池String 对象创建的2种方式123String str1 = \"abcd\";String str2 = new String(\"abcd\");System.out.println(str1==str2); 使用==比较的是内存地址，虽然他们的值相同但是由于创建方式的原因它们的内存地址不一样，通过&quot;&quot;方式创建的字符串存放在常量池中，通过new方式是在堆内存中创建一个新的对象，所有他们的内存地址不一样输出false。 注意：只要是通过new方式创建即会创建一个新的对象String 类型的常量池比较 直接通过&quot;&quot;声明出来的 String 对象会直接存储在常量池中。 如果不是通过&quot;&quot;声明的 String 对象。可以使用intern方法，它是一个Native方法,在运行时常量池中如有值匹配的String字符串则返回，否则创建一个字符串并返回其引用。12345String s1 = new String(\"计算机\");String s2 = s1.intern();String s3 = \"计算机\";System.out.println(s1 == s2);System.out.println(s3 == s2); 输出 false、true，s1 属于堆中对象，s2 是常量池中对象,s3 属于常量池中对象 String 字符串拼接123456789String str1 = \"str\";String str2 = \"ing\";String str3 = \"str\" + \"ing\";String str4 = str1 + str2; String str5 = \"string\";System.out.println(str3 == str4);System.out.println(str3 == str5);System.out.println(str4 == str5); 输出false、true、false，str3常量池对象、str2常量池对象、str3常量池对象、str4堆内对象、str5常量池对象 String s= new String(“abc”)生成了几个对象面试经常会问到这样的问题，首先在常量池会生成&quot;abc&quot;对象，通过new会在堆中生成abc对象，所以答案是2个对象。 常量池拓展Java基本类型的包装类的大部门实现了常量池技术，有Byte、Short、Long、Charact、Boolean。这5种包装类默认创建了[-128,127]的相应类型的缓存数据，超出范围的仍然需去创建新的对象。 以Integer为例123456789Integer i1 = 33;Integer i2 = 33;System.out.println(i1 == i2);// 输出trueInteger i11 = 333;Integer i22 = 333;System.out.println(i11 == i22);// 输出falseDouble i3 = 1.2;Double i4 = 1.2;System.out.println(i3 == i4);// 输出false 代码中Integer i1 = 33在遍历时会把带代码封装成Integer i1 = Integer.valueOf(33),从而使用的是常量池中的缓存对象。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"MySql 主从集群配置","slug":"Mysql 主从配置","date":"2019-03-25T01:07:05.000Z","updated":"2019-03-27T02:16:16.132Z","comments":true,"path":"2019/03/25/Mysql 主从配置/","link":"","permalink":"http://laochenpi.top/2019/03/25/Mysql 主从配置/","excerpt":"","text":"记录安装MySql 过程，并搭建主从模式集群。主从模式在项目中的运用例如读写分离，提高吞吐量在大量需要读操作时可以把压力分散到各个从库不影响主库写操作，如发生主库异常宕机也可以通过从库的数据进行恢复或者顶替主库。 MySQL 安装官方网站下载最靠谱，不要在奇奇怪怪的网站下可能会有乱七八糟的插件之类的，唯一指定网站 https://www.mysql.com/ ，本人下载的ZIP包解压，进入文件夹进行数据库配置，默认配置为dafult.ini如果没有则创建my.ini配置文件。 MySQL 同步原理 Master端需要开启bin.log，在每次数据发生改变会往bin.log增量写入数据并更新Pos，以备下一次增量写入标记Pos。 Slave端的I/O读取master.info文件，获取binlog文件名和位置点并向Master端的I/O线程发起读取请求。 Master端的I/O线程会根据Slave端的I/O线程请求信息来读取binlog日志信息与及读取到最新的binlog文件名和Pos一同返回给Slave的I/O线程。 Slave端的I/O线程会把获取到的binlog日志写入relay日志（中继日志）文件中，并且更新master.info文件信息(包含最后一次读取Pos用于下次同步更新的位置点)。 Slave端的SQL线程会定期读取relay日志，把二进制的日志解析成SQL语句并执行同步数据到从库。 Master 节点配置12345678910111213141516171819202122[mysql]# 设置mysql客户端默认字符集UTF8default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-master# 设置mysql数据库的数据的存放目录datadir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-master\\\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 服务唯一IDserver-id=1# 开启Log二进制日志log-bin=master-bin# 二进制日志记录方式 混合模式binlog_format=mixed 配置完毕进入bin文件夹下打开控制台进行安装初始化123456# 初始化mysqld --initialize --console# 注册服务mysqld --install [服务名]# 启动服务net start [服务名] 特别注意 mysqld --initialize --console 执行会给你初始化密码，使用命令 mysql -uroot -p 登录MySQL 在master库中执行以下脚本123456# 创建用于同步数据的用户CREATE USER 'slave3307'@'127.0.0.1' IDENTIFIED BY '123123';# 赋予权限GRANT REPLICATION SLAVE,FILE ON *.* TO 'slave3307'@'127.0.0.1';# 刷新权限FLUSH PRIVILEGES; SLAVE 节点配置12345678910111213141516171819202122[mysql]# 设置mysql客户端默认字符集UTF8default-character-set=utf8 [mysqld]#设置3307端口port = 3307 # 设置mysql的安装目录basedir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-slave# 设置mysql数据库的数据的存放目录datadir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-slave\\\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 服务唯一IDserver-id=2# 只读设置read_only=1# 需要同步的数据库名称，如有多个需配置多条replicate-do-db=mastersql read_only 这里设置为只读模式，不会影响到slave的同步复制功能，可以限制普通用户写入操作防止修改数据导致主从数据不一致，但是无法限制super用户的修改数据权限，所以同步复制需要新建一个普通用户用于链接同步。 同步配置在5.7版本之前需要在my.ini配置文件[mysqld]下添加12345678910# 主节点地址master-host=127.0.0.1# 主节点端口master-port=3306# 主节点复制账号master-user= slave3307# 主节点复制密码master-password= 123123# 重连时间master-connect-retry=60 5.7版本之后的主从配置直接通过动态配置无需修改ini123456# 改变同步配置change master to master_host='127.0.0.1',master_port=3306, master_user='slave3307', master_password='123123',master_log_file='binlog.000003',master_log_pos=7676;# 开启同步start slave;# 查看同步状态show slave status; 执行show slave status语句可以查看当前同步状态，Slave_IO_Running和Slave_SQL_Running是否为Yes，证明同步是否开启成功。Seconds_Behind_Master为从库与主库同步位置差异一般为0。执行stop slave可停止同步进行修改同步设置然后使用start slave重新开启。 语句解释 master_host和master_port 为主库地址信息 master_port和master_password 同步的账号密码，我们已配置用户为slave3307密码为123。 在master库中执行show master status;获取master_log_file 主库日志和master_log_pos当前日志位置，这里可以根据实际情况来设置master_log_pos的起始位置。 同步开启后可以尝试在主库下创建一个新数据库mastersql,然后新建一张表mytest。切换到从库你会发现从库也会自动创建mastersql数据库并有一张同名的表mytest，说明同步成功。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/tags/数据库/"}]},{"title":"JVM 内存区域","slug":"JVM 内存区域","date":"2019-03-21T13:01:28.000Z","updated":"2019-05-15T03:07:18.747Z","comments":true,"path":"2019/03/21/JVM 内存区域/","link":"","permalink":"http://laochenpi.top/2019/03/21/JVM 内存区域/","excerpt":"","text":"JVM 复习基本概念学习和记录 概述对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像C/C++程序开发程序员这样为内一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。 JVM 运行时候数据区域Java 虚拟机在执行 java 程序的过程中会把管理的内存划分为若干个不同的数据区域，JDK 1.8 和之前的版本有不同。 线程私有的：程序计数器、虚拟机栈、本地方法栈 线程共享的：堆、方法区、直接内存（非运行数据区的一部分） 直接内存 程序计数器程序计数器（Pargram Counter Register）是一块很小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作通过改变计数器的值来选择下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都依赖此计数器。多线程中每个线程都有一个计数器用来记录线程执行的位置，每个计数器之间相互不影响独立，独立存储，被称为“线程私有”的内存。 程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建才创建，结束而结束。 虚拟机栈 Java 虚拟机栈（Jasva Virtual Machine Stacks）也是私有内存，它的生命周期和线程一样，描述的是 Java 方法执行的内存模型： 每个方法在执行的同时都会创建一个帧栈（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法的执行完成的过程对应着每个帧栈在虚拟栈中入栈到出栈的过程。 局部变量表的主要存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置） 虚拟机栈只会出现2种异常 StackOverFlowError：如虚拟机不支持内存动态扩展，当线程请求栈的深度大于虚拟机的最大阈值，则会抛出StackOverFlowError。 OutOfMemoryError：如果虚拟机支持内存动态扩展，当线程申请内存无法再动态扩展时，会抛出OutOfMemoryError 本地方法栈虚拟机栈为虚拟机执行 Java 方法（字节码）服务，而本地方法栈为虚拟机使用Native方法服务。在HotSpot中 Java 虚拟机合二为一。 堆Java 堆（Java Heap）是虚拟机所管理的内存中最大的一块，Java 堆是被所有线程所共享的一块内存区域，在虚拟机启动时创建用于存放几乎所有的对象实例和数组。 Java 堆是 垃圾回收器管理的主要区域 GC 堆（Garbage Collector Heap）,垃圾回收采用分代垃圾收集算法，可以细分为：新生代和老年代,在细致点可分为：Eden空间、From Survivor、To Survivor空间等。eden、s0、s1区属于新生代，tentired区属于老年区。 通常虚拟机的内存拓展是通过（-Xms 和 -Xms控制）。 方法区方法区（Method Area）和 Java 堆一样属于共享的内存区域，用于存放已经被虚拟机啊加载的类信息、常量、静态变量、即时编译器后的代码等数据。为区分 Java 堆，方法区也叫Non-Heap（非堆）。 JDK 1.8 的时候，方法区（HotSpot的永久代）被彻底移除了（JDK1.7就已经开始了），取而代之是元空间，元空间使用的是直接内存。 运行时常量池运行时常量（Running Constant Pool）是方法区的一部分。Class文件除了有类的版本、字段、方法、接口等描述信息外，还有常量池（Constant Pool Table）,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 直接内存直接内存（Direct Memory）不是虚拟机运行时数据区的一部分，也不是虚拟机规范中划分的内存区域。 JDK 1.4中新加入的NIO(New Input/OutPut)类，引入基于通道(Channel)与缓冲区（Buffer）的I/O方式，它可以直接通过Native函数直接分配堆外内存，然后通过Java中DirectByBuffer对象来操作这些内存。这样避免 Java 堆和 Native 堆之间来回复制数据浪费性能。 直接内存分配不受 Java 堆的限制，但是受限于机器的物理内存大小和逻辑器寻址空间限制。 所有内容摘自 《深入理解 Java 虚拟机》 和 https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F.md","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://laochenpi.top/tags/Jvm/"}]},{"title":"JVM 类加载","slug":"JVM 类加载","date":"2019-03-21T13:01:28.000Z","updated":"2019-04-18T01:13:14.323Z","comments":true,"path":"2019/03/21/JVM 类加载/","link":"","permalink":"http://laochenpi.top/2019/03/21/JVM 类加载/","excerpt":"","text":"JVM 复习基本概念学习和记录 概述","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Jvm","slug":"Jvm","permalink":"http://laochenpi.top/tags/Jvm/"}]},{"title":"RabbitMQ 消息队列中间件","slug":"RabbitMq 消息队列中间件","date":"2019-03-20T06:35:19.000Z","updated":"2019-04-29T03:18:17.887Z","comments":true,"path":"2019/03/20/RabbitMq 消息队列中间件/","link":"","permalink":"http://laochenpi.top/2019/03/20/RabbitMq 消息队列中间件/","excerpt":"","text":"RabbitMq消息队列中间件记录一些基本的概念和实际项目运用，消息队列常常会作为解决项目之间解耦的方案之一，特点异步消息可持久化不丢失高可用。实际项目中有各类场景可使用消息队列，例如发送邮件模块、业务消息通知、异步回调结果、日志信息的收集聚合等。 RabbitMQRabbitMq 是一款由erlang开发实现 AMQP（Advanced Message Queueing Protocal）的开源消息中间件，消息中间件主要运用于组件之间解耦，消息发送者不需关心消息消费者的存在，AMQP 的主要特征是面向消息、队列、路由（点对点和发布/订阅）、可靠性、安全。 Rabbit 基本概念 Message由消息头和消息体组成，消息头里包含了routeKey用于标记消息需要发送到那个队列，priority消息优先权，delivery-mode消息可能需要持久性存储。 Channel信道，多路复用连接中的一条独立的双向数据流通道，是建立在TCP连接内的虚拟连接，发布消息、订阅队列、接受消息等都是通过信道完成，当你的项目连接上RabbitMq你可以在控制台Channel中发现一条新的记录包含了信道的各类信息，当项目停止后该条信道就会销毁。 Exchanges交换器，消息发送到交换器根据配置的规则再转发到相应队列，转发的规则有4中分别为direct、topic、fonout、headers。 Exchanges 路由规则 direct属于最常见的一种转发规则，单播模式根据routeKey匹配唯一的队列进行发送。 topic主题模式通过#（匹配0个或多个单词）和*（匹配一个单词）来绑定队列，如果不使用通配符可作为普通的direct队列，根据实际情况灵活配置。 fanout广播模式，每个发送到交换器上的信息都会被转发到绑定到该交换器上的所有队列，fanout类型的转发消息是最快的。 安装Rabbit官方网站进行下载，由于 RabbitMQ 由 ERLANG 开发需要安装相关环境,具体版本查看官方文档。安装完毕可以通过http://127.0.0.1:15672 查看 RabbitMQ 管理中心，包含了 RabbitMQ 配置主题、队列、运行情况、连接等。 初始登陆账号：admin 密码：admin SpringBoot 集成SpringBoot 微服务项目集成 RabbitMQ 特别方便，Maven项目依赖添加spring-boot-starter-amqp依赖然后进行基本配置，添加@EnableRabbit开启 RabbitMQ 自动配置，自动装配的源码可以查看RabbitAutoConfiguration类。 Maven 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 配置123456789101112spring: rabbitmq: host: ip地址 port: 端口号默认5672 username: 用户名 password: 密码 publisher-confirms: 是否启动推送自动确认 true or false listener: direct: acknowledge-mode: ack消息确认方式：auto 自动 manual 手动 none 不确认 simple acknowledge-mode: ack消息确认方式：auto 自动 manual 手动 none 不确认 ACK机制就是为了保证数据一定被消费确认，默认配置为auto自动,在实际项目中如果消费者出现程序异常或者意外服务宕机会导致消息未消费但是ACK自动确认后，提供者并不知道消费者消费失败导致业务数据不一致。ACK 可以设置为手动 manual只有当消费者告诉中间件已经消费中间件才会把这条消息从队列中删除,否者这条消息会一直在队列中存在直到消费者重新消息掉。 提供者123456789101112131415161718package com.example.rabbitmq.rabbitProvider;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.stereotype.Component;import javax.annotation.Resource;@Componentpublic class RabbitMqProvider &#123; @Resource private RabbitTemplate rabbitTemplate; public void provider()&#123; rabbitTemplate.convertAndSend(\"myTestQueue\",\"测试测试123\"); &#125;&#125; 这里使用RabbitTemplete进行发送消息，已封装了各类常用的推送消息方法，myTestQueue为队列名称。 消费者 Ack 确认12345678910111213141516171819202122package com.example.rabbitmq.mytest;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitHandler;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Component@RabbitListener(queues = \"myTestQueue\")public class RabbitMqConsumer &#123;@RabbitHandler()public void consumer(String msg, Channel channel, Message message) &#123; try &#123; System.out.println(\"接受消息\" + msg); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 上述代码使用了Channel进行Ack确认，队列中有无数条信息为了确认唯一性，调用basicAck方法进行确认，message.getMessageProperties().getDeliveryTag()获取消息的唯一tag值。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"http://laochenpi.top/tags/中间件/"}]},{"title":"ArrayList源码阅读","slug":"ArrayList源码阅读","date":"2019-03-18T13:01:48.000Z","updated":"2019-03-27T03:42:46.340Z","comments":true,"path":"2019/03/18/ArrayList源码阅读/","link":"","permalink":"http://laochenpi.top/2019/03/18/ArrayList源码阅读/","excerpt":"","text":"记录学习回顾Java基础学习源码思想ArrayList，平时光顾着写业务代码基础细节都没有进行积累导致出去面试被人家一顿虐，只注重外功不注重内功是不行的。 ArrayList平时最常用的集合，特点有序查找效率高线程不安全底层是数组实现了动态数组的功能，实现了RandomAccess(快速随机访问)、Cloneable(克隆接口)、Serializabele(序列化)等接口。 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认的初始化容量 10 */ private static final int DEFAULT_CAPACITY = 10; /** * 共享的静态空Object数组用于空实例 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 共享的静态空数组实例 用于最常用的new ArrayList() 无参实例使用 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 用于存放加入的数据数组 transient 关键字用于标记不需要序列化的字段 */ transient Object[] elementData; // non-private to simplify nested class access /** * * 整个数组的长度 size 即size()返回值 * @serial */ private int size; /** * 有参数的构造函数 initialCapacity 用于给集合初始化容量 */ public ArrayList(int initialCapacity) &#123; //初始化一个大小为 initialCapacity 的Object数组 if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //如果初始容量为0使用静态 EMPTY_ELEMENTDATA 默认的空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; /** * 最常用的初始化方法 */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * Collection 传入一个集合元素列表 E为泛型 指定传入的集合类型 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; //集合转化为数组 并初始化elementData elementData = c.toArray(); //初始化size的值 if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) // 由于传入的集合真实类型不一样所以需要调用 Arrays.copyOf 复制到一个新的Object[]数组中，以便可以存放任意类型 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** *修改当前容器值为实际元素的个数 */ public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; /** * 自行控制扩容大小 * 如果扩容值大于默认值10 则按传入值进行扩容处理判断 */ public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125; &#125; /** * 计算最小容量 */ private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity; &#125; /** * 根据minCapacity进行扩容 */ private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &#125; /** * 判断是否需要进行扩容操作 如果扩容值大于实际的数组长度则进行扩容 */ private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; /** * 能分配的最大的数组大小 Integer数值最大值(2^31-1)-8 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * 扩容的核心代码 * 每次扩容的大小为 当前数组长度+(数组长度/2) * 如果扩容新容量小于需要扩容量值则覆盖新容量值 * 如果扩容新容量大于MAX_ARRAY_SIZE则直接使用Interger.MAX_VALUE否则使用MAX_ARRAY_SIZE */ private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; /** *当需要扩容大于MAX_ARRAY_SIEZ或小于0 返回合适值 */ private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"Redis 缓存问题场景","slug":"Redis缓存场景","date":"2019-02-22T02:27:08.000Z","updated":"2019-03-27T05:39:06.860Z","comments":true,"path":"2019/02/22/Redis缓存场景/","link":"","permalink":"http://laochenpi.top/2019/02/22/Redis缓存场景/","excerpt":"","text":"记录下学习Redis缓存实际项目中会出现的一些场景和解决方案，缓存穿透、缓存击穿、缓存雪崩 Redis 缓存穿透缓存穿透是指缓存和数据库都查询到不到，例如查询UserId=-1的用户，当大量类似访问请求发送到服务端，由于数据库一直无法查找到数据则缓存无法更新和插入，后续大量的请求全部落到了DB上。导致DB数据库压力增大发生崩溃、变慢。 解决方案 在接口层面或者通过过滤器拦截器过滤掉一些恶意查询条件。 如果有查询不到的大量请求，可以设置Key-Null和TTL的时间设置30-60秒(具体根据实际业务需求来设定)，避免大量的后续恶意请求落在DB上。 Redis 缓存雪崩缓存雪崩是指缓存中大量的Key同一时间失效或缓存服务直接宕机导致大量的访问请求都落到了DB上，使得数据库压力过大导致连锁反应瘫痪宕机。 失效解决： 热门数据缓存设置TTL延长或者永久 数据的缓存设置随机TTL防止同一时间失效 服务宕机： Redis 高可用，使用主从+哨兵 redis cluster，避免全盘崩溃 本地 ehcache 缓存 + hystrix 限流/降级，避免DB被打死 Redis 持久化，一旦重启立刻恢复数据 3.Redis 缓存击穿缓存击穿是指同一个热门Key突然失效，大量的并发访问导致直接落在DB上，导致DB数据库压力增大宕机，与雪崩不同的是击穿是单一Key雪崩是大量热门Key。 数据的缓存TTL设置永久 使用互斥锁等待第一次请求缓存构建完成后释放锁，让其余所有请求直接通过缓存拿取数据。单机环境Lock类型，集群使用Setnx(set if not exits) 查考资料https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md","categories":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/categories/数据库/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"http://laochenpi.top/tags/Redis/"}]},{"title":"Redis 持久化","slug":"Redis持久化","date":"2019-02-22T02:27:08.000Z","updated":"2019-03-27T03:09:48.410Z","comments":true,"path":"2019/02/22/Redis持久化/","link":"","permalink":"http://laochenpi.top/2019/02/22/Redis持久化/","excerpt":"","text":"记录学习Redis持久化，Redis为内存数据库当服务器异常关闭或重启会导致内存里的Redis数据丢失，Redis提供持久化方案来保证数据不丢失. Redis 持久化Redis持久化有多种不同级别的方式 RDB 持久化可以在指定时间范围内服务器生成数据集的Snapshot 时间点快照point-in-time(数据库中所有键值对数据) AOF 持久化记录服务器执行过的写操作命令，在服务启动通过执行命令来恢复数据集。AOF文件中的命令以Redis协议的格式保存，新命令会追加到文件末尾。 RDB AOF同时使用，在Redis重启时优先使用AOF进行数据恢复，因为AOF的保存的数据通常比RDB文件所保存的数据更完整。 关闭持久化，数据仅在服务器运行时存在 RDB 持久化-配置 save save m n (m 代表时间范围内 n 修改次数) 例如默认配置文件中的save 900 1 900秒内至少有一个Key发生变化则保存。 stop-writes-on-bgsave-error 默认值yes，当Redis后台保存失败时是否停止接受写操作。如果已经设置一些监控可选择关闭。 rdbcompression 默认值yes，对存储到磁盘的快照文件是否进行压缩(LZF算法压缩)，压缩会消耗一定CPU性能，具体根据实际情况设置是否压缩。 rdbchecksum 默认值yes，对于存储的快照文件使用CRC64算法进行数据校验，校验大概消耗10%的性能，如需大量性能可关闭跳过校验过程。 dbfilename 默认值 dump.rbd， 快照文件的名称。 dir 默认当前目录，快照文件的存放文件路径 RDB 优点 Redis在保存RDB会fork出子进程进行，几乎不影响Redis处理效率。 RDB非常适合灾难恢复（disaster reconvery），每次快照会生成完整的快照文件，可根据业务需求进行多备云备份。 RDB在恢复大数据集时比AOF速度更快。 RDB 缺点 RDB快照是定期生成，在时间范围内服务发生宕机可能导致会丢失部分数据 RDB在大数据快照生成上会消耗大量CPU性能，如CPU性能不足或紧张时会影响Redis对外服务。 AOF 持久化AOF（append-only file）持久化:将Redis执行的每一条写请求都记录在一个日志文件里，在Redis启动后会执行所有的写操作达来恢复数据。AOF 默认是关闭状态，AOF 提供3种fsync配置 appendfsync no 不进行fsync，由OS来决定什么时候进行同步，速度最快 appendfsync always 每一次操作都进行fsync，速度较慢 appendfsync everysec 折中的做法，交由后台线程每秒fsync一次 AOF优点数据更安全，在配置 appendfsync always或 appendfsync everysec会及时把每条执行的写操作都记录都追加到AOF文件末尾即使是服务出现故障至多损失1s之内的数据。 查考地址http://doc.redisfans.com/topic/persistence.htmlhttps://baijiahao.baidu.com/s?id=1611955931705092609&amp;wfr=spider&amp;for=pc","categories":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/categories/数据库/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laochenpi.top/tags/Redis/"}]},{"title":"Docker 环境搭建","slug":"Docker环境搭建","date":"2018-08-20T06:11:30.000Z","updated":"2019-04-16T03:28:20.199Z","comments":true,"path":"2018/08/20/Docker环境搭建/","link":"","permalink":"http://laochenpi.top/2018/08/20/Docker环境搭建/","excerpt":"","text":"开发-&gt;部署测试-&gt;发布正式 在整体流程中每个人的开发环境可能各不相同、编译环境、运行环境。单机服务调整控制环境版本等可以保证发布一致性，但是如果当业务越来越庞大集群处理时需要部署多台机器时，可能每台机器的大大小小差异都会导致发布失败，处理起来非常麻烦。docker虚拟化来处理能保证发布环境一致性，可移植。通过docker 镜像你可以在任何版本linux服务器上进行发布。每个镜像就相当于个一个系统相互不影响独立环境。 1.Docker 介绍Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 2.Docker 安装我的VPS用的Centos 7 那就用本版本记录搭建过程，docker的版本用CE社区版12345678910#下载yum-utils工具用于管理yum-config-manager可以配置源yum install yum-utils#添加docker-ce源yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#查询docker-ce版本yum list docker-ce --showduplicates | sort -r #指定安装18.06.0 版本yum install dock-ce-18.06.0.ce&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD======= 安装docker，默认是安装最高版本测试可以用，但是生产环境为了稳定尽量指定版本(stable稳定版) 3.Docker 常用命令1234#启动docker服务systemctl start docker#自动启动docker服务systemctl enable docker 安装docker,默认是安装最高版本测试可以用，但是生产环境为了稳定尽量指定版本(stable稳定版) 3.Docker 镜像 容器镜像查询拉取安装 docker 完毕，可以尝试安装一个镜像并运行，搜索镜像使用 docker search [镜像名称],搜索的镜像 OFFICAL 标识的为官方镜像，其余的都是非官方人员自行构建的镜像并上传库共享。使用 docker pull alpine 下载拉取alpine镜像,然后使用docker images 查看镜像已有镜像，这里以alpine为模板 运行容器基于alpine镜像启动一个容器1docker run -itd -p 8081:8081 --name myTest alpine -i：以交互模式运行容器，通常与 -t 同时使用 -d: 后台运行容器，并返回容器ID -t : 为容器重新分配一个伪输入终端，通常与 -i 同时使用 -p: 端口映射，格式为：主机(宿主)端口:容器端口 8080端口的访问转发到容器的8080端口上 –name: 为容器指定一个容器名 alpine：这是指用 alpine 镜像为基础来启动容器。 启动完毕后 docker ps 查看正在运行的容器, docker ps -a 查看容器。 容器操作1234567891011##### myTest 为容器名称 ##### #进行容器docker attach myTest#容器中执行脚本返回结果 (由于是alpine所以执行的)docker exec -it myTest /bin/sh#删除容器docker rm myTest#启动已有容器docker start myTest#停止容器docker stop myTest 在容器中退出容器时需要注意的是通过exit返回宿主主机会导致容器直接停止并不是我们想要的结果，官方给出的退出容器并使其在后台继续运行使用 ctrl+p+q 安全退出不影响容器运行。 4.DockerFileDockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。我们可以根据实际的开发需求通过dockerfile来自定义镜像，JUST DO IT！ FROM 指令FROM &lt;image>:&lt;tag> 相当于建造一个大楼地基的选择，选择不同的地基来搭建不一样的大楼。 操作系统类基础搭建例如 ubuntu、dabin、centos 开发语言作为基础搭建例如java、nodejs、python 服务类镜像作为基础 oralce、mysql、nginx、tomcat 自定义混合类作为基础在其他自定义环境镜像基础上搭建 所有的镜像地基都可以从docker库中拉取，选择合理的基础镜像可以让你更快的去构建你的镜像，省心省力。 RUN 指令RUN 就像是执行shell指令，常常用于更新安装需要的生产软件服务等。RUN有2种执行方式 shell 格式： RUN &lt;命令&gt; ，就像直接在命令行中输入的命令一样：RUN apt-get --update exec 格式： RUN [“可执行文件”, “参数1”, “参数2”]：RUN [&quot;apt-get&quot;,&quot;--update&quot;] 注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层.多少个RUN就构建了多少层镜像，会造成镜像的臃肿多层，不仅仅增加了构件部署的时间，还容易出错。RUN书写时的换行符是\\，记得下载压缩软件操作完毕后rm不必要的软件压缩包和缓存让镜像更精简。 CMD 指令CMD 指令的格式和 RUN 相似也是两种格式，CMD 执行脚本在dockerfile只能存在一条，多条只执行最后一条，当有多个时只会执行最后一个，一般用于执行开启某些服务 tomcat、oracle、nginx等。 ENTRYPOINT 指令ENTRYPOINT 执行脚本在dockerfile只能存在一条，多条只执行最后一条，容器启动后执行且不会被docker run提供的参数覆盖。 RUN ENTRYPOINT CMD 小结 CMD 和 ENTRYPOINT 推荐使用Exec格式，因为指令可读性更强，更容易理解。RUN 则两种格式都可以。 RUN用来执行脚本构建基础镜像，CMD ENTRYPOINT 用来构建完镜像容器启动后执行一些操作。 CMD 会被docker run 后的执行脚本覆盖不执行，ENTRYPOINT 则不会被覆盖始终会被执行，如果需要覆盖运行需要–entrypoint参数。 ENTRYPOINT 和 CMD 同时存在时谁在最后谁能执行，CMD 可作为 ENTRYPOINT 的执行参数灵活配合使用。 COPY 指令用于从上下文路径复制文件到容器目标路径中，copy package.json /usr/src/app/ 把package.json复制到容器 /usr/src/app路径下 COPY &lt;源路径&gt;… &lt;目标路径&gt; COPY [“&lt;源路径&gt;”，……，”&lt;目标路径&gt;”] ......代表若干源路径 ADD 指令ADD 指令和 COPY 的格式和性质基本一致，是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个URL，这种情况下 Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。如果&lt;源路径&gt;为一个tar 压缩文件的话，压缩格式为gzip , bzip2 以及 xz 的情况下，ADD指令将会自动解压缩这个压缩文件到&lt;目标路径&gt;去。ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢，ADD 还包含了一些复杂的的功能其行为也不一定清晰，所以官方推荐使用COPY来进行文件的复制。 ENV 指令ENV 用于设置环境变量在后续的指令可以直接引用 ENV &lt;key> &lt;value> ENV &lt;key1>=&lt;value1> &lt;key2>=&lt;value2>… Docker build构建所有的脚本编写完毕使用docker bulid 对 Dockerfile 进行构建，详细的命令如下12 12345#基于镜像 这里使用alpine 主要是体积小构建速度更快FROM alpine#构建维修者 MAINTAINER 285635652@qq.comRUN apt-get update / &amp;&amp; apt-get java","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"Winsw 把 java 项目做成服务","slug":"Winsw把java项目做成服务","date":"2018-08-16T12:04:17.000Z","updated":"2019-03-27T02:16:16.138Z","comments":true,"path":"2018/08/16/Winsw把java项目做成服务/","link":"","permalink":"http://laochenpi.top/2018/08/16/Winsw把java项目做成服务/","excerpt":"","text":"jar项目需要通过命令行jar -jar 执行脚本启动显示控制台，由于强迫症可以使用javaw -jar来执行可以在后台执行，但通过java编译启动在window环境下进程名都为java.exe一旦项目多了当你要更新部署更新关闭项目时候就懵逼了有可能就会误操作，通过Google发现有个开源的软件winsw 可以把任何软件做为window 的服务来管理，这样在services.msc 服务管理里可以很方便的进行管理更新部署。 1.Winsw 环境Winsw是个开源项目，Github地址为:https://github.com/kohsuke/winsw 依赖环境为NET2 或 NET4， 可通过配置文件进行修改。 2.JAVA 项目注册服务根据作者的介绍注册的服务依赖于配置文件 *.xml，这里需要注意的是xml的文件名称必须和winsw.exe同名。默认是按软件的名称来匹配配置文件。例如你把winsw.exe重复名为test.exe那配置文件必须为test.xml不然不无法使用。123456789&lt;service&gt; &lt;id&gt;MyTest&lt;/id&gt; &lt;name&gt;MyTest&lt;/name&gt; &lt;description&gt;测试jar项目服务&lt;/description&gt; &lt;env name=\"JENKINS_HOME\" value=\"%BASE%\"/&gt; &lt;executable&gt;java&lt;/executable&gt; &lt;arguments&gt;-Xrs -Xmx256m -jar \"%BASE%\\test.jar\" --httpPort=8080&lt;/arguments&gt; &lt;logmode&gt;rotate&lt;/logmode&gt;&lt;/service&gt; 配置文件解释: id：服务名称 (唯一) name：显示服务名称 description：服务描述 env：环境变量 JENKINS_HOME 赋值给 %BASE% executable：执行命令 这里我们是用java启动 arguments：执行的一些参数 logmode：日志模式这里 executable arguments 就相当于你在控制台执行的脚本，根据你的需求进行改变命令和参数。通过控制台进入winsw软件目录执行winsw.exe install 注册服务， winsw为软件名称可以自行修改。执行成功可以在控制看到 如果发现错误请查看 [软件名称].wrapper.log 日志排查，是否配置文件名和软件名不一致或者配置的地址不存在等。然后你可以通过 services.msc 对你的服务进行操作了启动，停止。注册的服务默认是AutoStart每次重启电脑都会自动启动。 配置文件的相关其他设置可以参考: https://github.com/kohsuke/winsw/blob/master/doc/xmlConfigFile.md","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"SpringCloud 服务中心之 Eureka","slug":"SprintCloud微服务-Eureka","date":"2018-08-01T08:43:15.000Z","updated":"2019-03-27T05:39:31.810Z","comments":true,"path":"2018/08/01/SprintCloud微服务-Eureka/","link":"","permalink":"http://laochenpi.top/2018/08/01/SprintCloud微服务-Eureka/","excerpt":"","text":"SpringCloud微服务架构基于SpringBoot进行开发组件，即插即用非常方便，用了Spring Boot根本停不下来。SpringCloud包含了服务和注册中心(Zookeeper Eureka Consul)、熔断器(Hystrix)、动态路由(Zuul)、配置中心(Spring cloud config)、负责均衡(Ribbon)、REST服务调用(Fegin)等集成组件。让我们一步步通过项目来学习SpringCloud！ 1. Eureka 服务发现和注册Eureka 是 Netflix 旗下微服务开发组件，用于服务发现和注册中心，分为服务端和客户端，服务端作为注册中心作为其他客户端的提供注册服务，客户端将需要暴露的接口服务注册到服务端中，通过周期性向服务端发送心跳保证自身健康可用性。 2. EurekaServer 注册中心搭建首先建立项目使用maven来构建项目，pom.xml依赖关系如下本项目用最新的版本进行教程，相关的官方教程可查看Spring Cloud Eureka pom.xml maven依赖配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;EurekaServer&lt;/artifactId&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--项目构建maven插件--&gt;&lt;build&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt; SpringBoot 启动配置项1234567891011121314package com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;@SpringBootApplication@EnableEurekaServer@EnableWebSecuritypublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class，args); &#125;&#125; WebSecurityConfig 安全认证配置123456789101112131415package com.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configurationpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable(); //关闭csrf http.authorizeRequests().anyRequest().authenticated().and().httpBasic(); //开启认证 &#125;&#125; application.yml 基本配置项12345678910111213141516#Eureka 服务中心设置 eureka: client: #自身不注册 register-with-eureka: false #是否开启检索服务 fetch-registry: false#security安全校验 spring: security: user: name: root password: 123123#服务器端口设置server: port: 8888 启动项目通过 http://localhost:8888 查看Eureka注册中心管理页面，为了安全性加入了security安全校验，输入账号密码进入管理页面。 3. EurekaClient 服务搭建pom.xml maven依赖配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;EurekaClient&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; SpringBoot 启动配置项1234567891011121314151617181920212223242526package com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@EnableEurekaClient@RestControllerpublic class Application &#123; @RequestMapping(\"/test1\") public String myTestService()&#123; return \"测试1\"; &#125; @RequestMapping(\"/test2\") public String myTestService2()&#123; return \"测试2\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class，args); &#125;&#125; application.yml配置123456789# 设置服务名spring: application: name: EurekaClient1# 设置注册中心地址 root:123123为注册中心设置的账号密码eureka: client: service-url: defaultZone: http://root:123123@localhost:8888/eureka","categories":[{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/tags/Spring/"}]},{"title":"Hexo部署到VPS自动发布","slug":"Hexo部署到VPS自动发布","date":"2018-07-26T07:02:30.000Z","updated":"2019-08-09T07:27:50.318Z","comments":true,"path":"2018/07/26/Hexo部署到VPS自动发布/","link":"","permalink":"http://laochenpi.top/2018/07/26/Hexo部署到VPS自动发布/","excerpt":"","text":"Hexo部署到github访问的速度较慢，所以想着把Hexo直接丢在自己VPS上去，部署一套git环境以后方便自动发布更新 1.Git 安装1234#通常使用的方法下载gityum -y install git#查看版本 这种下载一般不是最新的版本yum --version 发现并不是最新版本逼死强迫症啊，只能通过下载最新git源码自行编译安装。Git 的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具。在有 yum 的系统上（比如 Fedora）或者有 apt-get 的系统上（比如 Debian 体系），可以用 下面的命令安装： 12345678910111213141516171819202122#卸载旧版本gityum remove git#安装依赖环境yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel#安装编译工具yum install gcc perl-ExtUtils-MakeMaker#下载最新版gitwget https://github.com/git/git/archive/v2.19.1.tar.gz#解压tar -zxvf v2.18.0.tar.gz#进入解压文件夹cd git-2.18.0#编译代码 perfix这里为赋值变量make prefix=/usr/local/git all#安装软件 make prefix=/usr/local/git install#清除编译数据make clean all#环境变量配置echo export PATH=$PATH:/usr/local/git/bin &gt;&gt;/etc/bashrc#生效环境变量source /etc/bashrc /etc/profile，/etc/bashrc 是系统全局环境变量设定 ~/.profile，~/.bashrc用户家目录下的私有环境变量设定 2.创建 git 仓库创建一个git库用来存放Hexo生成的html静态文件和相关资源，然后通过 post-receive 钩子函数进行自动执行脚本讲生成的资源checkout发布到nginx达到自动发布更新的功能。1234567891011121314#创建git用户adduser git#设置密码passwd git#创建Hexo博客库 目录自行选择mkdir laochenpiBlog &amp;&amp; chown git:git laochenpiBlog#laochenpiBlog目录下创建blog.git --bare裸仓库 没有工作空间git init --bare blog.git &amp;&amp; chown git:git -R blog.git #laochenpiBlog 目录下创建静态网页库 mkdir blog.site &amp;&amp; chown git:git blog.site#进入钩子函数目录cd hooks/#创建钩子函数文件touch post-receive &amp;&amp; chown git:git post-receive &amp;&amp; chmod 755 post-receive 为Hexo编写自动化脚本在仓库hooks创建脚本 vi post-receive ，脚本会在git有收发的时候就会调用执行1git --work-tree=/var/laochenpiBlog/blog.site --git-dir=/var/laochenpiBlog/blog.git checkout -f 3.Hexo 配置发布测试终于把Git环境弄好了，现在就需要修改配置文件_config.yml 中的发布项1234567#Deployment## repo 为你的vps创建的库地址## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo : git@45.77.87.214:/var/laochenpiBlog/blog.git branch: master 修改完毕，见证奇迹的时候到了，找到自己博客目录下用 git bash 发布 12#清除缓存 重编译 发布hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 输入密码发布完毕，然后远程上你的VPS查看下你的 blog.site 是否自动 check out了最新发布的内容了。 4.Git 免密发布每次发布都需要输入密码实在是太麻烦了而且在有可能泄露密码引起安全问题，有什么比较方面安全的方式呢，通过google一波发现可以通过秘钥的形式实现无密码发布登录。 秘钥方式通过RSA加密生成公有秘钥，然后把公有秘钥提交到VPS 上的秘钥认证文件中 authroized_keys，修改 OpenSSH 客户端的配置 sshd_config 实现RSA秘钥认证方式。 那么我们开始吧！ 服务器端修改 OpenSSH 认证 vi /etc/ssh/sshd_config开启公钥认证 PubkeyAuthentication yes认证Keys文件目录 用户/.ssh/文件名 AuthorizedKeysFile .ssh/authorized_keysRSA加密认证 RSAAuthentication yes 这里要提示一点 Centos 7 和 Centos 6 遇到的问题，Centos 7 由于OpenSSH版本原因 RSAAuthentication 已经弃用，无需添加修改.123456#用户提交的git用户的秘钥文件夹创建和权限分配#——————————————————————————————————————#创建认证文件authorized_keystouch /home/git/.ssh/authorized_keys#.ssh权限 700 authorized_keys 权限600chmod 700 /home/git/.ssh &amp;&amp; chmod 600 /home/git/.ssh/authorize_keys 这里要注意 .ssh 和 authorize_keys 的权限问题，可能在加密认证的时候由于权限导致失败，SSH登录日志可以用 tail /var/log/secure 查看，sshd -t进行查看配置是否正常 需要在~目录下执行，执行systemctl restart sshd 重启 SSH服务 客户端ssh-keygen -t rsa -C userName 生成秘钥文件，地址一般在 ~/.ssh 中。id_rsa 加密公钥 id_rsa.pub 加密公钥 多用户用cat 追加秘钥到认证文件中 12#上传认证秘钥到服务器上 对应用户的authorized_keys中cat ~/.ssh/id_rsa.pub | ssh git@45.77.87.214 \"cat - &gt;&gt; /home/git/.ssh/authorized_keys\" 配置完毕后使用 ssh -vvT git@45.77.87.214 看看是不是不用密码就可以登录VPS了，然后发布就再也不用密码了，一条命令就OK。 5. Nginx配置映射终于到最后一步了，就差最后一步配置 Nginx 服务映射静态文件了。123456#Centos yum源安装yum install nginx#启动nginx服务systemctl start nginx#查看服务状态systemctl status nginx -l 这里有可能出现的问题：1.无法从外网访问 检查下80端口是否开启，添加80端口firewall-cmd --permanent --zone=public --add-port=80/tcp --permanent 和 firewall-cmd --reload 重载配置2.服务可能没有启动成功，排查下配置问题 修改80端口默认映射库地址，nginx -t查看nginx配置文件地址 12345678#停止Nginx服务systemctl stop nginx#修改Nginx的配置文件rootvi /etc/nginx/nginx_conf#修改 root 配置hexo静态文件地址，即之前创建的静态文件地址root [hexo静态文件地址]#修改完毕退出 重启Nginx服务systemctl start nginx 修改完毕启动好服务然后通过外网访问你 VPS IP地址即可访问，大功告成以后可以在任意地方通过git提交的方式进行自动发布。请记得随时备份自己的重要文件以免丢失！ 遇到的问题已配置秘钥但是SSH还是需要密码，相信很多小伙伴都遇到过，下面是可能原因 查看sshd_config 配置文件是否正确开启了3个认证配置，更改后重启OpenSSH服务 查看下ssh登录日志 排查下原因，可能是认证文件目录权限问题，.shh 700 authorized_key 600 过大或者过小的权限都有可能导致认证是失败。 authorized_key 中秘钥千万千万不要直接从客户端直接复制过来，可能会有空格和其他转义一些特殊情况导致秘钥不正确。可通过 cat或scp 命令远程进行上传秘钥保证正确性。 Centos 7 版本的 OpenSSH RSAAuthentication已经弃用无需设置、添加该设置可能导致启动异常。","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 文件权限管理","slug":"Linux-文件权限管理","date":"2018-07-25T07:07:09.000Z","updated":"2019-03-27T02:57:57.601Z","comments":true,"path":"2018/07/25/Linux-文件权限管理/","link":"","permalink":"http://laochenpi.top/2018/07/25/Linux-文件权限管理/","excerpt":"","text":"为了保证文件系统的安全隐私，对文件进行权限控制，防止非法用户查看、修改、删除等操作。只有在指定用户或用户组才能进行操作，例如一些隐私文件或者文件夹不想被其他人进行访问查看可对文件进行权限控制。 1. ls 命令查询文件属性12345678910111213[root@vultr ~]# ls -altotal 44dr-xr-x--- 4 root root 4096 Jul 19 05:05 .dr-xr-xr-x 18 root root 4096 Jun 5 21:42 ..-rw------- 1 root root 4369 Jul 25 07:02 .bash_history-rw-r--r-- 1 root root 18 Dec 29 2013 .bash_logout-rw-r--r-- 1 root root 176 Dec 29 2013 .bash_profile-rw-r--r-- 1 root root 176 Dec 29 2013 .bashrcdrwx------ 3 root root 4096 Jul 18 07:35 .cache-rw-r--r-- 1 root root 100 Dec 29 2013 .cshrcdrwxr----- 3 root root 4096 Jun 5 21:45 .pki-rw-r--r-- 1 root root 129 Dec 29 2013 .tcshrc[权限] [连接数][所有者][用户组][文件容量][修改时间] [文件名] [权限]第一个字符代表文件是 “目录、文件或链接文件等” [d] 代表是目录，例如 .pki [-] 代表是文件，例如 .tcshrc [l] 代表为链接文件(linkfile) [b] 代表设备文件里的可以供存储的接口设备 [c] 代表设备文件里的串行端口，例如键盘、鼠标接下来的3个为位一组，均为 “rwx” 3个参数组合 [r] 代表read 可读 [w] 代表write 可写 [x] 代表execute 可执行 [-] 代表没有权限 第一组代表 “文件所有者的权限”，第二组代表 “同用户组的权限”，第三组代表 “其他非本用户组的权限” [连接数] 文件的硬链接个数 [所有者] 文件的所有者账号 [用户组] 文件的所有用户组 [文件容量] 文件的容量 单位/B [修改时间] 文件的创建时间或最近的一次修改时间 [文件名] 文件的名称 带 “.” 则表示当前文件为隐藏文件 3.改变文件属性和权限命令 chgrp 改变文件所属用户组改变的用户组必须存在于/etc/group，对于不存在的用户组改变会执行失败 1234#示例 [-R] 递归 文件或者目录下所有的的文件chgrp [-R] [文件或目录]#更新install.log用户组为userchgrp user install.log chown 改变文件所有者改变的用户必须存在于/etc/passwd，对于不存在的用户改变会执行失败 123456#示例 [-R] 递归 文件或者目录下所有的的文件chown [-R] [文件或目录]#更新install.log用户所属为testchown test install.log#可用.[用户组] 改变用户组 将install.log所属用户组改为groupTestchown .groupTest install.log chmod 改变文件的权限改变rwx 读写执 3个权限，3个身份owner，group，others，组合9个权限。 数字类型改变权限:权限rwx按分数 r : 4 w : 2 x : 1，改变权限的组合方式按分数来决定权限rwxrwxrwx 对应777，rw–wx— 对应610 1234#示例 [-R] 递归 文件或者目录下所有的的文件chmod [-R] [分数组合] [文件或目录]#改变install.log的权限 763代表了 rwxrw---xchown 763 install.log 符号类型改变权限:权限rwx按符号 u(user)，g(group)，o(others)，a(all)，+(加入)，-(除去)，=(设置)组合。 123456#用户拥有读写，用户组读，其他执行 u=rw-，g=r--，o=--xchmod u=rw-，g=r--，o=--x install.log#所有身份都去除写权限 chmod a-r install.log#所有身份都添加执行权限chmod a+x install.log 2.RWX 对于文件和目录的差别对于文件来说： r (read) 可以读取文件的实际内容 w (write) 可以编辑、新增、或修改文件的内容，但是不能删除文件 x (execute) 可以执行，可执行并非由文件的后缀来决定例如常见的.exe .bat .com 等，而是由x 属性来决定 对于文件目录来说： r (read contents in directory) 可以查询该目录下的文件名数据既可使用ls查询 w (modify contents of directory) 可以新建新的文件和目录、删除已存在的文件和目录（无视改文件的权限控制）、转义目录内的文件和文件夹 x (access directory) 可以进入该目录文件 既可使用cd进入该目录","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 关机重启命令","slug":"Linux-关机重启命令","date":"2018-07-25T05:50:04.000Z","updated":"2019-03-27T02:16:16.128Z","comments":true,"path":"2018/07/25/Linux-关机重启命令/","link":"","permalink":"http://laochenpi.top/2018/07/25/Linux-关机重启命令/","excerpt":"","text":"记录学习鸟哥的私房菜之开启重启shell笔记，主要有命令shutdown，reboot，halt，poweroff 1.Shutdown 命令介绍 可以自由的选择关机模式：关机、重启或者进入单用户操作模式即可 可以设置关机时间：设置在特定时间或经过多少时长后关闭，也可以立刻关闭 可以自定义关机消息：在关闭服务可以通知其他登录的用户 可以发送警告命令：在执行一些测试脚本或者可以影响到其他的登录用户的操作时，可以发送警告信息进行提示，但不是真的关机 12345678910#脚本参数 shutdown [-t秒] [-arkhncfF] 时间 [警告消息]-t sec： -t 后单位/秒 经过多少秒后执行-k ：不是真关机仅发出警告信息-r ：服务关闭后，关闭并重启-h : 服务关闭后，立刻关机-c ：取消已经在进行中的关闭操作-f ：关机启动后，启动略过fsck磁盘检查-F ：关机启动后 ，强制进行fsck磁盘检查# 3600秒后进行关闭并提示警告语shutdown -t 3600 'Computer will shutdown after 30 min'","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Log4j 自定义多文件分离","slug":"Log4j-学习笔记","date":"2018-07-20T09:32:59.000Z","updated":"2019-03-27T03:31:07.362Z","comments":true,"path":"2018/07/20/Log4j-学习笔记/","link":"","permalink":"http://laochenpi.top/2018/07/20/Log4j-学习笔记/","excerpt":"","text":"在工作开发中遇到一个需求需要通过某一些条件逻辑进行分组细化日志，用配置的一些条件进行不同的日志管理和处理，由于之前的日志没有细化会导致在很多日志中无法更快和更精准的定位某一个模块的错误，如大海捞针效率极低，细分后方便开发和维护人员对日志更快更精准的排查修改BUG。 1.Log4j 介绍 Log4j有三个主要的组件：Loggers(记录器)，Appenders (输出源)和Layouts(布局)。这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。 2.Log4j 组件Appender 配置 ConsoleAppender (控制台) Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 FileAppender (文件) Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 DailyRollingFileAppender (按照日期格式生成) DatePattern=’.’yyyy-MM：根据时间格式按照年月日为单位生成log文件‘.’yyyy-MM：每月‘.’yyyy-ww：每周‘.’yyyy-MM-dd：每天‘.’yyyy-MM-dd-a：每天两次‘.’yyyy-MM-dd-HH：每小时‘.’yyyy-MM-dd-HH-mm：每分钟 RollingFileAppender (文件大小到达指定尺寸的时候产生一个新的文件) MaxFileSize=100KB：后缀可以是KB， MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文 SocketAppender (发送远程服务 Tip:可配合logstash使用) host，String，指定服务器的主机名。（必需） immediateFlush，boolean，是否立即flush，还是等待缓存到一定大小后在flush。 layout，Layout，log event输出的格式。 port，integer，远程服务器坚挺log event的应用的端口号。 protocol，String，发送log event所使用的协议，”TCP” 或”UDP”。 reconnectionDelay，integer，当连接断开时，延迟等待的ms数。 name，String ，Appender的名称。 protocol，String，通讯协议 默认TCP。可选值 “TCP” (default)， “SSL” or “UDP”. SSL，SslConfiguration，包含密钥存储库和信任存储库的配置. filter，Filter，一个过滤器来确定事件应该由这个Appender。 不止一个过滤器 可以通过使用一个CompositeFilter。 immediateFail，boolean，设置为true时，日志事件不会等待尝试重新连接，将立即如果失败 套接字是不可用的。 immediateFlush，boolean， 当该值设置成真时，默认情况下，每个写将冲洗。 这将保证写的数据 到磁盘，但可能会影响性能。 layout，Layout，LogEvent ，布局使用格式。 缺省值是SerializedLayout。 reconnectionDelay，integer ，如果设置为值大于0，一个错误后SocketManager将尝试重新连接 在指定的毫秒数后的服务器。 如果连接失败 将抛出一个异常(可以被应用程序如果ignoreExceptions是 设置为假)。 ignoreExceptions，boolean，默认值是真正的添加事件时，遇到了引起异常 内部记录，然后忽略。 当设置为假将传播到异常 调用者。 你必须设置这个假当包装这个AppenderFailoverAppender。 SMTPAppender (发送邮件) smtpHost= mtp.163.com：邮件服务器地址 smtpPort=30 ：端口号 from= *@.com：发送方邮箱 replyTo = *@.com： 接收方方邮箱 smtpUsername = 285635652@qq.com：发送方邮箱账号 smtpPassword = **：发送方邮箱密码 log4j.additivity.[appenderName]=false (用于独立输出日志，Logger只会在自己的appender里输出，而不会在父Logger的appender里输出。)默认为true Layouts HTMLLayout（以HTML表格形式布局） PatternLayout（可以灵活地指定布局模式） SimpleLayout（包含日志信息的级别和信息字符串） TTCCLayout（包含日志产生的时间、线程、类别等信息） 3.Spring 运用 Log4j123456789101112131415161718192021222324252627282930313233343536373839# LOG4J配置log4j.rootCategory=INFO， stdout， filelog4j.logger.errorfile=error，errorfile# 控制台输出log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n# root日志输出log4j.appender.file=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.file.file=logs/all.loglog4j.appender.file.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n# error日志输出log4j.appender.errorfile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.errorfile.file=logs/error.loglog4j.appender.errorfile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.errorfile.Threshold = ERRORlog4j.appender.errorfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.errorfile.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n#自定义业务分组 team mytest输出目标log4j.logger.team=INFO，mytest#自定义日志输出#输出的各种Appenderlog4j.appender.mytest=org.apache.log4j.DailyRollingFileAppender#父类节点不输出 分级log4j.additivity.team=false#输出的日志地址log4j.appender.mytest.file=logs/mytest.log#记录的时间单位 天 log4j.appender.mytest.DatePattern=&apos;.&apos;yyyy-MM-dd#布局log4j.appender.mytest.layout=org.apache.log4j.PatternLayout#输出内容log4j.appender.mytest.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L ---- %m%n 讲解 rootCategory 主节点 [日志级别]，[输出目标]，[输出目标]，[…] category 子节点 特别会集成主节点的设置 日志级别 log4j.appender.[输出目标] 日志的输出设置 包含输出格式、布局、方式等 优先级：DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL PatternLayout 布局 ConversionPattern相关设置%m 输出代码中指定的消息%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL%r 输出自应用启动到输出该log信息耗费的毫秒数%c 输出所属的类目，通常就是所在类的全名%t 输出产生该日志事件的线程名%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy MMM ddHH:mm:ss，SSS}，输出类似：2002年10月18日 22：10：28，921%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。[QC]是log信息的开头，可以为任意字符，一般为项目简称。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"CentOs FireWall 脚本","slug":"CentOs-Firewalld-脚本","date":"2018-07-19T06:20:43.000Z","updated":"2019-03-27T02:16:16.126Z","comments":true,"path":"2018/07/19/CentOs-Firewalld-脚本/","link":"","permalink":"http://laochenpi.top/2018/07/19/CentOs-Firewalld-脚本/","excerpt":"","text":"经过之前自己搭建了Shadowsocks接触Linux慢慢想深入学习下一些常用Shell，之前在配置Shadowsocks遇到启动服务但是PC客户端连接没有网络，通过查阅一些教程发现Centos7默认开启了防火墙Firewall导致如果没有开放Shadowsocks的相关端口是无法访问的，现在记录下Firewall的一些相关命令 1.Firewalld 简介CentOs7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念，有图形界面和工具界面，由于我在服务器上使用，图形界面请参照官方文档，本文以字符界面做介绍，firewalld的字符界面管理工具是 firewall-cmd 默认配置文件有两个：/usr/lib/firewalld/ （用户配置地址） 和 /etc/firewalld/ （系统配置，尽量不要修改） 2.Zone 概念Firewall 能将不同的网络连接归类到不同的信任级别，Zone 提供了以下几个级别 drop: 丢弃所有进入的包，而不给出任何响应 block: 拒绝所有外部发起的连接，允许内部发起的连接 public: 允许指定的进入连接 external: 同上，对伪装的进入连接，一般用于路由转发 dmz: 允许受限制的进入连接 work: 允许受信任的计算机被限制的进入连接，类似 workgroup home: 同上，类似 homegroup internal: 同上，范围针对所有互联网用户 trusted: 信任所有连接 3.过滤规则过滤规则的优先级遵循如下顺序source&gt;interface&gt;firewalld.conf source: 根据源地址过滤 interface: 根据网卡过滤 service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 4.使用方法firewall-cmd [指令]–zone 作用域–permanent 永久修改–reload 重载生效–timeout=seconds 持续时间，一般用于调试 使用实例:1234567891011121314151617181920212223242526#查看开放的Zonefirewall-cmd --get-active-zones#查看firewalld状态firewall-cmd --state#查看firewalld开放的端口firewall-cmd --zone=dmz --list-ports#重新加载配置 (无需重启)firewall-cmd --reload#重新加载配置 (重启服务器加载)firewall-cmd --complete-reload #添加一个端口允许访问 (临时添加)firewall-cmd --zone=dwz --add-port=8080/tcp#添加一个端口允许访问 (永久添加)firewall-cmd --zone=dwz --add-port=8080/tcp --permanent#添加一个端口允许访问 (持续300秒)firewall-cmd --zone=dwz --add-port=8080/tcp --timeout=300#添加一个服务允许访问firewall-cmd --zone=dwz --add-service=smtp#启用firewalldsystemctl start firewalld#停止firewalldsystemctl stop firewalld#重启firewalldsystemctrl restart firewalld#禁用firewalldsystemctrl disable firewalld","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 搭建 Shadowsocks","slug":"Linxu搭建SS","date":"2018-07-13T08:25:43.000Z","updated":"2019-03-27T02:16:16.129Z","comments":true,"path":"2018/07/13/Linxu搭建SS/","link":"","permalink":"http://laochenpi.top/2018/07/13/Linxu搭建SS/","excerpt":"","text":"作为一个码农没有科学上网怎么能行，刚好Vultr新注册送钱买一个云主机玩玩，以CentOs7做一个教程，之前在网上找的搭建方法很多错误导致一直不成功现在自己整理并通过测试，踩了很多坑 1.Shadowsocks 环境准备12345678910#安装epel扩展源yum install epel-release#安装Pipyum -y install python-pip#升级Pippip install --upgrade pip #清除yum缓存yum clean all#安装shadowsocks客户端pip install shadowsocks 2.Shadowsocks 配置123456789101112131415161718192021222324252627#创建shadowsocks配置vi /etc/shadowsocks.json#单用户 &#123; \"server\":\"server_ip\"， \"server_port\":25， \"local_address\": \"127.0.0.1\"， \"local_port\":1080， \"password\":\"password\"， \"timeout\":300， \"method\":\"aes-256-cfb\"， \"fast_open\": false &#125;#多用户&#123; \"server\":\"server_ip\"， \"port_password\":&#123; \"port_1\":\"pwd1\"， \"port_2\":\"pwd2\"， \"port_3\":\"pwd3\" &#125;， \"local_address\":\"127.0.0.1\"， \"local_port\":1080， \"timeout\":300， \"method\":\"aes-256-cfb\"&#125; 参数详解: server 服务器地址 127.0.0.1 或者0.0.0.0 server_port 服务端口号 外部连接需要填写的服务端口号 local_port 本地端口号 password 连接密码 timeout 超时时间 method 加密方式 3.Shadowsocks 启动1234#启动ssserver -c /etc/shadowsocks.json -d start#停止ssserver -c /etc/shadowsocks.json -d stop 由于每次都需要服务器重启都需要手动去启动不便，可以注册成服务自动启动123456789101112131415#创建服务脚本 servicename 填写shadowsocksvi /etc/systemd/system/[servicename].service#编辑脚本[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json startExecStop=/usr/bin/ssserver -c /etc/shadowsocks.json stop[Install]WantedBy=multi-user.target 这里会遇到一个坑：ExecStart 这里填写的启动脚本 少了一个start不知道是不是我本身脚本问题 参数详解: Description服务描述 ExecStart 服务启动执行脚本 ExecStop 服务停止执行脚本 WantedBy 系统以该形式运行时，服务方可启动 4.Systemctl 命令注册服务 systemctl enable shadowsocks所有服务 systemctl list-units --type=service服务状态 systemctl status shadowsocks -l启动服务 systemctl start shadowsocks停止服务 systemctl stop shadowsocks重启服务 systemctl restart shadowsocks 5.Shadowsocks 客户端安装环境支持 Shadowsocks for Win Microsoft .NET Framework 4.6.2 Microsoft Visual C++ 2015 Redistributable (x86) 安装完毕配置启动即可 贴士提示 CentOs7需要配置下防火墙端口白名单1234#添加端口号8388(设置的server-port) --permanent永久生效firewall-cmd --zone=public --add-port=8388/tcp --permanent #重载配置firewall-cmd --reload","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Logstash同步数据库","slug":"Logstah同步Es","date":"2018-05-25T08:27:08.000Z","updated":"2019-03-27T02:16:16.131Z","comments":true,"path":"2018/05/25/Logstah同步Es/","link":"","permalink":"http://laochenpi.top/2018/05/25/Logstah同步Es/","excerpt":"","text":"由于业务需求需要同步某些数据库的表数据更新修改删除需同步ES保证同步性，在进行curd用AOP可实现同步，但是考虑到解耦分离后续系统水平拓展，查询资料可以用Logstash进行同步Es，Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到Elasticsearch. 1.Logstash依赖环境 JDK1.8 下载地址 Ruby环境 下载地址 logstash 6.3.1 下载地址 2.Logstash同步配置文件 Logstash由三个组件构造成，分别是input、filter以及output。我们可以吧Logstash三个组件的工作流理解为：input收集数据，filter处理数据，output输出数据。至于怎么收集、去哪收集、怎么处理、处理什么、怎么发生以及发送到哪等等一些列的问题就是我们接下啦要讨论的一个重点。123456789101112131415161718192021222324252627282930313233343536input &#123; jdbc&#123; #数据库驱动jar包 jdbc_driver_library =&gt; &quot;\\policySyn\\ojdbc6.jar&quot; #数据库地址 jdbc_connection_string =&gt; &quot;jdbc:oracle:thin:@192.168.105.16:1523:gnnt&quot; #数据库用户名密码 jdbc_user =&gt; &quot;plane_tick&quot; jdbc_password =&gt; &quot;ora123&quot; #数据库驱动类 jdbc_driver_class =&gt; &quot;Java::oracle.jdbc.driver.OracleDriver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; #执行sql绝对路径 或相对路径 statement_filepath =&gt; &quot;\\policySyn\\syn.sql&quot; #更新时间记录和存放 record_last_run =&gt; &quot;true&quot; last_run_metadata_path =&gt; &quot;\\policySyn\\synDate.txt&quot; #定时更新频率 20分钟一次 schedule =&gt; &quot;* * * * *&quot; #索引类型 type =&gt; &quot;policyteam_dev&quot; &#125;&#125;//同步目的地output &#123; elasticsearch&#123; hosts =&gt; &quot;http://192.168.105.13:9200&quot; index =&gt; &quot;policyteam_dev&quot; document_id =&gt; &quot;%&#123;zcbh&#125;&quot; &#125; stdout &#123; codec =&gt; json_lines &#125;&#125; 3.启动同步脚本进入Logstash目录bin文件夹下执行脚本12#config为执行配置文件绝对路径或相对路径logstash -f [config]","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"Python验证码识别","slug":"Python 第三方库 PIL","date":"2018-05-25T08:27:08.000Z","updated":"2019-03-27T02:16:16.133Z","comments":true,"path":"2018/05/25/Python 第三方库 PIL/","link":"","permalink":"http://laochenpi.top/2018/05/25/Python 第三方库 PIL/","excerpt":"","text":"Python 第三方库 PIL Pytesseract tesseract-ocr 进行爬虫验证码识别 1.Python 第三方库依赖 通过cmd控制台进入python pip目录执行pip install requests 进行安装 其他的第三方库都可以通过这种形式进行安装12345678910#进入Python脚本文件夹cd C:\\Users\\serwer\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts#安装 requests 请求http库pip install requests #安装 pytesseract 基础识别库pip install pytesseract#安装 Image图片处理 为更好识别验证码pip install Image#显示requests相关信息pip show requests 可以通过配置pip环境变量达到在任意文件夹目录进行pip脚本执行 2.OCR图形识别软件 （Google维护的开源的OCR）Tesseract-ocr github地址 window 可选择Tesseract-ocr-setup-3.05.01.exe 123456789101112131415161718192021222324252627282930313233343536373839import requestsimport pytesseractfrom PIL import ImageimagePath = &quot;D:\\\\1.gif&quot;imageUrl = &quot;http://112.112.9.205:88/ValiateNum.ashx&quot;def getAuthCodeImage(): r = requests.get(imageUrl， stream=True) with open(imagePath， &apos;wb&apos;) as fd: for chunk in r.iter_content(1024): fd.write(chunk) fd.closedef disposeImage(): image = Image.open(imagePath) table = [] for i in range(256): if i &lt; 140: table.append(0) else: table.append(1) image = image.convert(&apos;L&apos;) image = image.resize((300，100)，Image.BILINEAR) image = image.point(table，&apos;1&apos;) image.save(&quot;D:\\\\1.png&quot;，&quot;png&quot;)def discernCode(): im=Image.open(&quot;D:\\\\1.png&quot;) code = pytesseract.image_to_string(im) print(code)#获取验证码并保存getAuthCodeImage()#验证码图片处理 灰阶处理disposeImage()#识别验证码discernCode()","categories":[{"name":"Python","slug":"Python","permalink":"http://laochenpi.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://laochenpi.top/tags/Python/"}]},{"title":"Hexo+GitHub 第一次搭建笔记","slug":"hexo","date":"2018-05-24T06:48:00.000Z","updated":"2019-03-27T05:39:48.866Z","comments":true,"path":"2018/05/24/hexo/","link":"","permalink":"http://laochenpi.top/2018/05/24/hexo/","excerpt":"","text":"Hexo+GitHub 搭建踩坑行动，平时有什么代码心得或者遇到一些奇葩BUG、都没有记下来，后来遇到类似的问题居然又忘记了，所以想自己搭建一个博客记录下一些平时遇到的问题和需要解决的一些技术问题记录下来以便以后回来还可以查阅，就用Hexo搭建一个静态的博客。 1.Hexo 环境准备 Node.js hexo依赖环境 Git Bash 根据OS下载安装包 用于发布和更新微博 安装 Hexo12345678#1.安装hexo环境npm install hexo-cli -g #2.初始化hexo blog 文件夹和相关带代码 bolgName为文件夹名称hexo init [blogName]#3.进入博客文件夹cd blog#4.进行依赖更新安装npm install 常用指令12345678910111213141516#新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。$ hexo init [folder]#新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 #default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。$ hexo new [layout] &lt;title&gt;#生成静态文件。$ hexo g#发表草稿$ hexo publish [layout] &lt;filename&gt;# 启动服务器。默认情况下，访问网址为： http://localhost:4000/$ hexo s# 部署网站$ hexo deploy# -p， --port 重设端口# -s， --static 只使用静态文件# -l， --log 启动日记记录，使用覆盖记录格式 2.GitHub Page 准备 登录Github创建一个reqo，名称为 [yourname].github.io (这里注意下yourname最好跟你库的用户名一样) 本地使用git设置username 和email 12git config --global user.name [username]git config --global user.email [email] GitHub SSH KEY 设置 1ssh-keygen -t rsa -C [email] 秘钥 C:\\Users\\serwer\\.ssh\\id_rsa.pub 复制添加到Github SSH Key中 在 Git Bash 中验证是否添加成功：ssh -T git@github.com 配置_config.yml 发布静态文件到github，修改_config.yml进行github发布设置 1234deploy: type: git repo: git@github.com:[username]/[username].github.io.git branch: master 通过 Git Bash hexo d 进行发布更新到github 然后访问你的reqo page即可看到属于你自己的静态微博 可能遇到的问题： 解决方法:npm install --save hexo-deployer-git 安装hexo git发布插件然后执行hexo d","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"心得","slug":"心得","permalink":"http://laochenpi.top/tags/心得/"}]}]}