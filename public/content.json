{"meta":{"title":"老陈皮加工厂","subtitle":null,"description":null,"author":"老陈皮","url":"http://laochenpi.top"},"pages":[],"posts":[{"title":"MySql 主从集群配置","slug":"Mysql安装记录","date":"2019-03-25T01:07:05.000Z","updated":"2019-03-27T02:16:16.132Z","comments":true,"path":"2019/03/25/Mysql安装记录/","link":"","permalink":"http://laochenpi.top/2019/03/25/Mysql安装记录/","excerpt":"","text":"记录安装MySql 过程，并搭建主从模式集群。主从模式在项目中的运用例如读写分离，提高吞吐量在大量需要读操作时可以把压力分散到各个从库不影响主库写操作，如发生主库异常宕机也可以通过从库的数据进行恢复或者顶替主库。 MySQL 安装官方网站下载最靠谱，不要在奇奇怪怪的网站下可能会有乱七八糟的插件之类的，唯一指定网站 https://www.mysql.com/ ，本人下载的ZIP包解压，进入文件夹进行数据库配置，默认配置为dafult.ini如果没有则创建my.ini配置文件。 MySQL 同步原理 Master端需要开启bin.log，在每次数据发生改变会往bin.log增量写入数据并更新Pos，以备下一次增量写入标记Pos。 Slave端的I/O读取master.info文件，获取binlog文件名和位置点并向Master端的I/O线程发起读取请求。 Master端的I/O线程会根据Slave端的I/O线程请求信息来读取binlog日志信息与及读取到最新的binlog文件名和Pos一同返回给Slave的I/O线程。 Slave端的I/O线程会把获取到的binlog日志写入relay日志（中继日志）文件中，并且更新master.info文件信息(包含最后一次读取Pos用于下次同步更新的位置点)。 Slave端的SQL线程会定期读取relay日志，把二进制的日志解析成SQL语句并执行同步数据到从库。 Master 节点配置12345678910111213141516171819202122[mysql]# 设置mysql客户端默认字符集UTF8default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-master# 设置mysql数据库的数据的存放目录datadir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-master\\\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 服务唯一IDserver-id=1# 开启Log二进制日志log-bin=master-bin# 二进制日志记录方式 混合模式binlog_format=mixed 配置完毕进入bin文件夹下打开控制台进行安装初始化123456# 初始化mysqld --initialize --console# 注册服务mysqld --install [服务名]# 启动服务net start [服务名] 特别注意 mysqld --initialize --console 执行会给你初始化密码，使用命令 mysql -uroot -p 登录MySQL 在master库中执行以下脚本123456# 创建用于同步数据的用户CREATE USER 'slave3307'@'127.0.0.1' IDENTIFIED BY '123123';# 赋予权限GRANT REPLICATION SLAVE,FILE ON *.* TO 'slave3307'@'127.0.0.1';# 刷新权限FLUSH PRIVILEGES; SLAVE 节点配置12345678910111213141516171819202122[mysql]# 设置mysql客户端默认字符集UTF8default-character-set=utf8 [mysqld]#设置3307端口port = 3307 # 设置mysql的安装目录basedir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-slave# 设置mysql数据库的数据的存放目录datadir=D:\\\\Program Files (x86)\\\\mysql-8.0.15-winx64-slave\\\\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为UTF8character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 服务唯一IDserver-id=2# 只读设置read_only=1# 需要同步的数据库名称，如有多个需配置多条replicate-do-db=mastersql read_only 这里设置为只读模式，不会影响到slave的同步复制功能，可以限制普通用户写入操作防止修改数据导致主从数据不一致，但是无法限制super用户的修改数据权限，所以同步复制需要新建一个普通用户用于链接同步。 同步配置在5.7版本之前需要在my.ini配置文件[mysqld]下添加12345678910# 主节点地址master-host=127.0.0.1# 主节点端口master-port=3306# 主节点复制账号master-user= slave3307# 主节点复制密码master-password= 123123# 重连时间master-connect-retry=60 5.7版本之后的主从配置直接通过动态配置无需修改ini123456# 改变同步配置change master to master_host='127.0.0.1',master_port=3306, master_user='slave3307', master_password='123123',master_log_file='binlog.000003',master_log_pos=7676;# 开启同步start slave;# 查看同步状态show slave status; 执行show slave status语句可以查看当前同步状态，Slave_IO_Running和Slave_SQL_Running是否为Yes，证明同步是否开启成功。Seconds_Behind_Master为从库与主库同步位置差异一般为0。执行stop slave可停止同步进行修改同步设置然后使用start slave重新开启。 语句解释 master_host和master_port 为主库地址信息 master_port和master_password 同步的账号密码，我们已配置用户为slave3307密码为123。 在master库中执行show master status;获取master_log_file 主库日志和master_log_pos当前日志位置，这里可以根据实际情况来设置master_log_pos的起始位置。 同步开启后可以尝试在主库下创建一个新数据库mastersql,然后新建一张表mytest。切换到从库你会发现从库也会自动创建mastersql数据库并有一张同名的表mytest，说明同步成功。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/categories/数据库/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://laochenpi.top/tags/数据库/"}]},{"title":"JVM 基础概念","slug":"JVM基础概念","date":"2019-03-21T13:01:28.000Z","updated":"2019-03-27T02:15:54.688Z","comments":true,"path":"2019/03/21/JVM基础概念/","link":"","permalink":"http://laochenpi.top/2019/03/21/JVM基础概念/","excerpt":"","text":"JVM 复习基本概念学习和记录 概述对于 Java 程序员来说，在虚拟机自动内存管理机制下，不再需要像C/C++程序开发程序员这样为内一个 new 操作去写对应的 delete/free 操作，不容易出现内存泄漏和内存溢出问题。正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。 JVM 运行时候数据区域Java 虚拟机在执行 java 程序的过程中会把管理的内存划分为若干个不同的数据区域，JDK 1.8 和之前的版本有不同。 线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存（非运行数据区的一部分） 程序计数器程序计数器（Pargram Counter Register）是一块很小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作通过改变计数器的值来选择下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都依赖此计数器。多线程中每个线程都有一个计数器用来记录线程执行的位置，每个计数器之间相互不影响独立，独立存储，被称为“线程私有”的内存。 程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建才创建，结束而结束。 虚拟机栈 Java 虚拟机栈（Jasva Virtual Machine Stacks）也是私有内存，它的生命周期和线程一样，描述的是 Java 方法执行的内存模型： 每个方法在执行的同时都会创建一个帧栈（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法的执行完成的过程对应着每个帧栈在虚拟栈中入栈到出栈的过程。 局部变量表的主要存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"RabbitMQ 消息队列中间件","slug":"RabbitMq 消息队列中间件","date":"2019-03-20T06:35:19.000Z","updated":"2019-03-27T02:16:16.134Z","comments":true,"path":"2019/03/20/RabbitMq 消息队列中间件/","link":"","permalink":"http://laochenpi.top/2019/03/20/RabbitMq 消息队列中间件/","excerpt":"","text":"RabbitMq消息队列中间件记录一些基本的概念和实际项目运用，消息队列常常会作为解决项目之间解耦的方案之一，特点异步消息可持久化不丢失高可用。实际项目中有各类场景可使用消息队列，例如发送邮件模块、业务消息通知、异步回调结果、日志信息的收集聚合等。 RabbitMQRabbitMq 是一款由erlang开发实现 AMQP（Advanced Message Queueing Protocal）的开源消息中间件，消息中间件主要运用于组件之间解耦，消息发送者不需关心消息消费者的存在，AMQP 的主要特征是面向消息、队列、路由（点对点和发布/订阅）、可靠性、安全。 安装Rabbit官方网站进行下载，由于 RabbitMQ 由ERLANG 开发需要安装相关环境,具体版本查看官方文档。安装完毕可以通过http://127.0.0.1:15672 查看 RabbitMQ 管理中心，包含了 RabbitMQ 配置主题、队列、运行情况、连接等。初始登陆账号：admin 密码：admin SpringBoot 集成SpringBoot 微服务项目集成 RabbitMQ 特别方便，Maven项目依赖添加spring-boot-starter-amqp依赖然后进行基本配置。 Maven 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; yml 配置12345678910spring: rabbitmq: host: ip地址 port: 端口号默认5672 username: 用户名 password: 密码 publisher-confirms: 是否启动推送自动确认 true or false listener: direct: acknowledge-mode: ack消息确认方式：auto 自动 manual 手动 none 不确认 ACK机制就是为了保证数据一定被消费确认，默认配置为auto自动,在实际项目中如果消费者出现程序异常或者意外服务宕机会导致消息未消费但是ACK自动确认后，提供者并不知道消费者消息失败导致业务数据不一致。ACK 可以设置为手动 manual只有当消费者告诉中间件已经消费中间件才会吧这条消息删除掉,否者这条消息会一直在队列中存在直到消费者消息掉。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"http://laochenpi.top/tags/中间件/"}]},{"title":"ArrayList源码阅读","slug":"ArrayList源码阅读","date":"2019-03-18T13:01:48.000Z","updated":"2019-03-27T02:15:54.685Z","comments":true,"path":"2019/03/18/ArrayList源码阅读/","link":"","permalink":"http://laochenpi.top/2019/03/18/ArrayList源码阅读/","excerpt":"","text":"记录学习回顾Java基础学习源码思想ArrayList，平时光顾着写业务代码基础细节都没有进行积累导致出去面试被人家一顿虐，只注重外功不注重内功是不行的。 ArrayList平时最常用的集合，特点有序查找效率高线程不安全底层是数组实现了动态数组的功能，实现了RandomAccess(快速随机访问)、Cloneable(克隆接口)、Serializabele(序列化)等接口。 源码解析 java public class ArrayList extends AbstractList implements List, RandomAccess, Cloneable, java.io.Serializable{ private static final long serialVersionUID = 8683452581122892189L; /** * 默认的初始化容量 10 */ private static final int DEFAULT_CAPACITY = 10; /** * 共享的静态空Object数组用于空实例 */ private static final Object[] EMPTY_ELEMENTDATA = {}; /** * 共享的静态空数组实例 用于最常用的new ArrayList() 无参实例使用 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 用于存放加入的数据数组 transient 关键字用于标记不需要序列化的字段 */ transient Object[] elementData; // non-private to simplify nested class access /** * * 整个数组的长度 size 即size()返回值 * @serial */ private int size; /** * 有参数的构造函数 initialCapacity 用于给集合初始化容量 */ public ArrayList(int initialCapacity) { //初始化一个大小为 initialCapacity 的Object数组 if (initialCapacity &gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //如果初始容量为0使用静态 EMPTY_ELEMENTDATA 默认的空数组 this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); } } /** * 最常用的初始化方法 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * Collection 传入一个集合元素列表 E为泛型 指定传入的集合类型 */ public ArrayList(Collection&lt;? extends E&gt; c) { //集合转化为数组 并初始化elementData elementData = c.toArray(); //初始化size的值 if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) // 由于传入的集合真实类型不一样所以需要调用 Arrays.copyOf 复制到一个新的Object[]数组中，以便可以存放任意类型 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; } } /** *修改当前容器值为实际元素的个数 */ public void trimToSize() { modCount++; if (size &lt; elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } /** * 自行控制扩容大小 * 如果扩容值大于默认值10 则按传入值进行扩容处理判断 */ public void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It&apos;s already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) { ensureExplicitCapacity(minCapacity); } } /** * 计算最小容量 */ private static int calculateCapacity(Object[] elementData, int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { return Math.max(DEFAULT_CAPACITY, minCapacity); } return minCapacity; } /** * 根据minCapacity进行扩容 */ private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } /** * 判断是否需要进行扩容操作 如果扩容值大于实际的数组长度则进行扩容 */ private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity); } /** * 能分配的最大的数组大小 Integer数值最大值(2^31-1)-8 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * 扩容的核心代码 * 每次扩容的大小为 当前数组长度+(数组长度/2) * 如果扩容新容量小于需要扩容量值则覆盖新容量值 * 如果扩容新容量大于MAX_ARRAY_SIZE则直接使用Interger.MAX_VALUE否则使用MAX_ARRAY_SIZE */ private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } /** * Returns the number of elements in this list. * * @return the number of elements in this list */ public int size() { return size; } /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this list contains no elements. * * @return &lt;tt&gt;true&lt;/tt&gt; if this list contains no elements */ public boolean isEmpty() { return size == 0; } /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this list contains the specified element. * More formally, returns &lt;tt&gt;true&lt;/tt&gt; if and only if this list contains * at least one element &lt;tt&gt;e&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;e==null&amp;nbsp;:&amp;nbsp;o.equals(e))&lt;/tt&gt;. * * @param o element whose presence in this list is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this list contains the specified element */ public boolean contains(Object o) { return indexOf(o) &gt;= 0; } /** * Returns the index of the first occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the lowest index &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. */ public int indexOf(Object o) { if (o == null) { for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; } return -1; } /** * Returns the index of the last occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the highest index &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. */ public int lastIndexOf(Object o) { if (o == null) { for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; } else { for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; } return -1; } /** * Returns a shallow copy of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance. (The * elements themselves are not copied.) * * @return a clone of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance */ public Object clone() { try { ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; } catch (CloneNotSupportedException e) { // this shouldn&apos;t happen, since we are Cloneable throw new InternalError(e); } } /** * Returns an array containing all of the elements in this list * in proper sequence (from first to last element). * * &lt;p&gt;The returned array will be &quot;safe&quot; in that no references to it are * maintained by this list. (In other words, this method must allocate * a new array). The caller is thus free to modify the returned array. * * &lt;p&gt;This method acts as bridge between array-based and collection-based * APIs. * * @return an array containing all of the elements in this list in * proper sequence */ public Object[] toArray() { return Arrays.copyOf(elementData, size); } /** * Returns an array containing all of the elements in this list in proper * sequence (from first to last element); the runtime type of the returned * array is that of the specified array. If the list fits in the * specified array, it is returned therein. Otherwise, a new array is * allocated with the runtime type of the specified array and the size of * this list. * * &lt;p&gt;If the list fits in the specified array with room to spare * (i.e., the array has more elements than the list), the element in * the array immediately following the end of the collection is set to * &lt;tt&gt;null&lt;/tt&gt;. (This is useful in determining the length of the * list &lt;i&gt;only&lt;/i&gt; if the caller knows that the list does not contain * any null elements.) * * @param a the array into which the elements of the list are to * be stored, if it is big enough; otherwise, a new array of the * same runtime type is allocated for this purpose. * @return an array containing the elements of the list * @throws ArrayStoreException if the runtime type of the specified array * is not a supertype of the runtime type of every element in * this list * @throws NullPointerException if the specified array is null */ @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T[] toArray(T[] a) { if (a.length &lt; size) // Make a new array of a&apos;s runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; } // Positional Access Operations @SuppressWarnings(&quot;unchecked&quot;) E elementData(int index) { return (E) elementData[index]; } /** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position in this list * @throws IndexOutOfBoundsException {@inheritDoc} */ public E get(int index) { rangeCheck(index); return elementData(index); } /** * Replaces the element at the specified position in this list with * the specified element. * * @param index index of the element to replace * @param element element to be stored at the specified position * @return the element previously at the specified position * @throws IndexOutOfBoundsException {@inheritDoc} */ public E set(int index, E element) { rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; } /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by {@link Collection#add}) */ public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } /** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException {@inheritDoc} */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } /** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). * * @param index the index of the element to be removed * @return the element that was removed from the list * @throws IndexOutOfBoundsException {@inheritDoc} */ public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } /** * Removes the first occurrence of the specified element from this list, * if it is present. If the list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists). Returns &lt;tt&gt;true&lt;/tt&gt; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &lt;tt&gt;true&lt;/tt&gt; if this list contained the specified element */ public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work } /** * Removes all of the elements from this list. The list will * be empty after this call returns. */ public void clear() { modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; } /** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the * specified collection&apos;s Iterator. The behavior of this operation is * undefined if the specified collection is modified while the operation * is in progress. (This implies that the behavior of this call is * undefined if the specified collection is this list, and this * list is nonempty.) * * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */ public boolean addAll(Collection&lt;? extends E&gt; c) { Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; } /** * Inserts all of the elements in the specified collection into this * list, starting at the specified position. Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices). The new elements will appear * in the list in the order that they are returned by the * specified collection&apos;s iterator. * * @param index index at which to insert the first element from the * specified collection * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws IndexOutOfBoundsException {@inheritDoc} * @throws NullPointerException if the specified collection is null */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; } /** * Removes from this list all of the elements whose index is between * {@code fromIndex}, inclusive, and {@code toIndex}, exclusive. * Shifts any succeeding elements to the left (reduces their index). * This call shortens the list by {@code (toIndex - fromIndex)} elements. * (If {@code toIndex==fromIndex}, this operation has no effect.) * * @throws IndexOutOfBoundsException if {@code fromIndex} or * {@code toIndex} is out of range * ({@code fromIndex &lt; 0 || * fromIndex &gt;= size() || * toIndex &gt; size() || * toIndex &lt; fromIndex}) */ protected void removeRange(int fromIndex, int toIndex) { modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) { elementData[i] = null; } size = newSize; } /** * Checks if the given index is in range. If not, throws an appropriate * runtime exception. This method does *not* check if the index is * negative: It is always used immediately prior to an array access, * which throws an ArrayIndexOutOfBoundsException if index is negative. */ private void rangeCheck(int index) { if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * A version of rangeCheck used by add and addAll. */ private void rangeCheckForAdd(int index) { if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * Constructs an IndexOutOfBoundsException detail message. * Of the many possible refactorings of the error handling code, * this &quot;outlining&quot; performs best with both server and client VMs. */ private String outOfBoundsMsg(int index) { return &quot;Index: &quot;+index+&quot;, Size: &quot;+size; } /** * Removes from this list all of its elements that are contained in the * specified collection. * * @param c collection containing elements to be removed from this list * @return {@code true} if this list changed as a result of the call * @throws ClassCastException if the class of an element of this list * is incompatible with the specified collection * (&lt;a href=&quot;Collection.html#optional-restrictions&quot;&gt;optional&lt;/a&gt;) * @throws NullPointerException if this list contains a null element and the * specified collection does not permit null elements * (&lt;a href=&quot;Collection.html#optional-restrictions&quot;&gt;optional&lt;/a&gt;), * or if the specified collection is null * @see Collection#contains(Object) */ public boolean removeAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c); return batchRemove(c, false); } /** * Retains only the elements in this list that are contained in the * specified collection. In other words, removes from this list all * of its elements that are not contained in the specified collection. * * @param c collection containing elements to be retained in this list * @return {@code true} if this list changed as a result of the call * @throws ClassCastException if the class of an element of this list * is incompatible with the specified collection * (&lt;a href=&quot;Collection.html#optional-restrictions&quot;&gt;optional&lt;/a&gt;) * @throws NullPointerException if this list contains a null element and the * specified collection does not permit null elements * (&lt;a href=&quot;Collection.html#optional-restrictions&quot;&gt;optional&lt;/a&gt;), * or if the specified collection is null * @see Collection#contains(Object) */ public boolean retainAll(Collection&lt;?&gt; c) { Objects.requireNonNull(c); return batchRemove(c, true); } private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) { final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try { for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; } finally { // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. if (r != size) { System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; } if (w != size) { // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; } } return modified; } /** * Save the state of the &lt;tt&gt;ArrayList&lt;/tt&gt; instance to a stream (that * is, serialize it). * * @serialData The length of the array backing the &lt;tt&gt;ArrayList&lt;/tt&gt; * instance is emitted (int), followed by all of its elements * (each an &lt;tt&gt;Object&lt;/tt&gt;) in the proper order. */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException{ // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) { s.writeObject(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } /** * Reconstitute the &lt;tt&gt;ArrayList&lt;/tt&gt; instance from a stream (that is, * deserialize it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) { // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) { a[i] = s.readObject(); } } } /** * Returns a list iterator over the elements in this list (in proper * sequence), starting at the specified position in the list. * The specified index indicates the first element that would be * returned by an initial call to {@link ListIterator#next next}. * An initial call to {@link ListIterator#previous previous} would * return the element with the specified index minus one. * * &lt;p&gt;The returned list iterator is &lt;a href=&quot;#fail-fast&quot;&gt;&lt;i&gt;fail-fast&lt;/i&gt;&lt;/a&gt;. * * @throws IndexOutOfBoundsException {@inheritDoc} */ public ListIterator&lt;E&gt; listIterator(int index) { if (index &lt; 0 || index &gt; size) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index); return new ListItr(index); } /** * Returns a list iterator over the elements in this list (in proper * sequence). * * &lt;p&gt;The returned list iterator is &lt;a href=&quot;#fail-fast&quot;&gt;&lt;i&gt;fail-fast&lt;/i&gt;&lt;/a&gt;. * * @see #listIterator(int) */ public ListIterator&lt;E&gt; listIterator() { return new ListItr(0); } /** * Returns an iterator over the elements in this list in proper sequence. * * &lt;p&gt;The returned iterator is &lt;a href=&quot;#fail-fast&quot;&gt;&lt;i&gt;fail-fast&lt;/i&gt;&lt;/a&gt;. * * @return an iterator over the elements in this list in proper sequence */ public Iterator&lt;E&gt; iterator() { return new Itr(); } /** * An optimized version of AbstractList.Itr */ private class Itr implements Iterator&lt;E&gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; Itr() {} public boolean hasNext() { return cursor != size; } @SuppressWarnings(&quot;unchecked&quot;) public E next() { checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } @Override @SuppressWarnings(&quot;unchecked&quot;) public void forEachRemaining(Consumer&lt;? super E&gt; consumer) { Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i &gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) { throw new ConcurrentModificationException(); } while (i != size &amp;&amp; modCount == expectedModCount) { consumer.accept((E) elementData[i++]); } // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); } final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } } /** * An optimized version of AbstractList.ListItr */ private class ListItr extends Itr implements ListIterator&lt;E&gt; { ListItr(int index) { super(); cursor = index; } public boolean hasPrevious() { return cursor != 0; } public int nextIndex() { return cursor; } public int previousIndex() { return cursor - 1; } @SuppressWarnings(&quot;unchecked&quot;) public E previous() { checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[lastRet = i]; } public void set(E e) { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.set(lastRet, e); } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } public void add(E e) { checkForComodification(); try { int i = cursor; ArrayList.this.add(i, e); cursor = i + 1; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } } /** * Returns a view of the portion of this list between the specified * {@code fromIndex}, inclusive, and {@code toIndex}, exclusive. (If * {@code fromIndex} and {@code toIndex} are equal, the returned list is * empty.) The returned list is backed by this list, so non-structural * changes in the returned list are reflected in this list, and vice-versa. * The returned list supports all of the optional list operations. * * &lt;p&gt;This method eliminates the need for explicit range operations (of * the sort that commonly exist for arrays). Any operation that expects * a list can be used as a range operation by passing a subList view * instead of a whole list. For example, the following idiom * removes a range of elements from a list: * &lt;pre&gt; * list.subList(from, to).clear(); * &lt;/pre&gt; * Similar idioms may be constructed for {@link #indexOf(Object)} and * {@link #lastIndexOf(Object)}, and all of the algorithms in the * {@link Collections} class can be applied to a subList. * * &lt;p&gt;The semantics of the list returned by this method become undefined if * the backing list (i.e., this list) is &lt;i&gt;structurally modified&lt;/i&gt; in * any way other than via the returned list. (Structural modifications are * those that change the size of this list, or otherwise perturb it in such * a fashion that iterations in progress may yield incorrect results.) * * @throws IndexOutOfBoundsException {@inheritDoc} * @throws IllegalArgumentException {@inheritDoc} */ public List&lt;E&gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); } static void subListRangeCheck(int fromIndex, int toIndex, int size) { if (fromIndex &lt; 0) throw new IndexOutOfBoundsException(&quot;fromIndex = &quot; + fromIndex); if (toIndex &gt; size) throw new IndexOutOfBoundsException(&quot;toIndex = &quot; + toIndex); if (fromIndex &gt; toIndex) throw new IllegalArgumentException(&quot;fromIndex(&quot; + fromIndex + &quot;) &gt; toIndex(&quot; + toIndex + &quot;)&quot;); } private class SubList extends AbstractList&lt;E&gt; implements RandomAccess { private final AbstractList&lt;E&gt; parent; private final int parentOffset; private final int offset; int size; SubList(AbstractList&lt;E&gt; parent, int offset, int fromIndex, int toIndex) { this.parent = parent; this.parentOffset = fromIndex; this.offset = offset + fromIndex; this.size = toIndex - fromIndex; this.modCount = ArrayList.this.modCount; } public E set(int index, E e) { rangeCheck(index); checkForComodification(); E oldValue = ArrayList.this.elementData(offset + index); ArrayList.this.elementData[offset + index] = e; return oldValue; } public E get(int index) { rangeCheck(index); checkForComodification(); return ArrayList.this.elementData(offset + index); } public int size() { checkForComodification(); return this.size; } public void add(int index, E e) { rangeCheckForAdd(index); checkForComodification(); parent.add(parentOffset + index, e); this.modCount = parent.modCount; this.size++; } public E remove(int index) { rangeCheck(index); checkForComodification(); E result = parent.remove(parentOffset + index); this.modCount = parent.modCount; this.size--; return result; } protected void removeRange(int fromIndex, int toIndex) { checkForComodification(); parent.removeRange(parentOffset + fromIndex, parentOffset + toIndex); this.modCount = parent.modCount; this.size -= toIndex - fromIndex; } public boolean addAll(Collection&lt;? extends E&gt; c) { return addAll(this.size, c); } public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); int cSize = c.size(); if (cSize==0) return false; checkForComodification(); parent.addAll(parentOffset + index, c); this.modCount = parent.modCount; this.size += cSize; return true; } public Iterator&lt;E&gt; iterator() { return listIterator(); } public ListIterator&lt;E&gt; listIterator(final int index) { checkForComodification(); rangeCheckForAdd(index); final int offset = this.offset; return new ListIterator&lt;E&gt;() { int cursor = index; int lastRet = -1; int expectedModCount = ArrayList.this.modCount; public boolean hasNext() { return cursor != SubList.this.size; } @SuppressWarnings(&quot;unchecked&quot;) public E next() { checkForComodification(); int i = cursor; if (i &gt;= SubList.this.size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (offset + i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[offset + (lastRet = i)]; } public boolean hasPrevious() { return cursor != 0; } @SuppressWarnings(&quot;unchecked&quot;) public E previous() { checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (offset + i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[offset + (lastRet = i)]; } @SuppressWarnings(&quot;unchecked&quot;) public void forEachRemaining(Consumer&lt;? super E&gt; consumer) { Objects.requireNonNull(consumer); final int size = SubList.this.size; int i = cursor; if (i &gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; if (offset + i &gt;= elementData.length) { throw new ConcurrentModificationException(); } while (i != size &amp;&amp; modCount == expectedModCount) { consumer.accept((E) elementData[offset + (i++)]); } // update once at end of iteration to reduce heap write traffic lastRet = cursor = i; checkForComodification(); } public int nextIndex() { return cursor; } public int previousIndex() { return cursor - 1; } public void remove() { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { SubList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = ArrayList.this.modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } public void set(E e) { if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.set(offset + lastRet, e); } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } public void add(E e) { checkForComodification(); try { int i = cursor; SubList.this.add(i, e); cursor = i + 1; lastRet = -1; expectedModCount = ArrayList.this.modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } final void checkForComodification() { if (expectedModCount != ArrayList.this.modCount) throw new ConcurrentModificationException(); } }; } public List&lt;E&gt; subList(int fromIndex, int toIndex) { subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, offset, fromIndex, toIndex); } private void rangeCheck(int index) { if (index &lt; 0 || index &gt;= this.size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } private void rangeCheckForAdd(int index) { if (index &lt; 0 || index &gt; this.size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } private String outOfBoundsMsg(int index) { return &quot;Index: &quot;+index+&quot;, Size: &quot;+this.size; } private void checkForComodification() { if (ArrayList.this.modCount != this.modCount) throw new ConcurrentModificationException(); } public Spliterator&lt;E&gt; spliterator() { checkForComodification(); return new ArrayListSpliterator&lt;E&gt;(ArrayList.this, offset, offset + this.size, this.modCount); } } @Override public void forEach(Consumer&lt;? super E&gt; action) { Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings(&quot;unchecked&quot;) final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) { action.accept(elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } /** * Creates a &lt;em&gt;&lt;a href=&quot;Spliterator.html#binding&quot;&gt;late-binding&lt;/a&gt;&lt;/em&gt; * and &lt;em&gt;fail-fast&lt;/em&gt; {@link Spliterator} over the elements in this * list. * * &lt;p&gt;The {@code Spliterator} reports {@link Spliterator#SIZED}, * {@link Spliterator#SUBSIZED}, and {@link Spliterator#ORDERED}. * Overriding implementations should document the reporting of additional * characteristic values. * * @return a {@code Spliterator} over the elements in this list * @since 1.8 */ @Override public Spliterator&lt;E&gt; spliterator() { return new ArrayListSpliterator&lt;&gt;(this, 0, -1, 0); } /** Index-based split-by-two, lazily initialized Spliterator */ static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; { /* * If ArrayLists were immutable, or structurally immutable (no * adds, removes, etc), we could implement their spliterators * with Arrays.spliterator. Instead we detect as much * interference during traversal as practical without * sacrificing much performance. We rely primarily on * modCounts. These are not guaranteed to detect concurrency * violations, and are sometimes overly conservative about * within-thread interference, but detect enough problems to * be worthwhile in practice. To carry this out, we (1) lazily * initialize fence and expectedModCount until the latest * point that we need to commit to the state we are checking * against; thus improving precision. (This doesn&apos;t apply to * SubLists, that create spliterators with current non-lazy * values). (2) We perform only a single * ConcurrentModificationException check at the end of forEach * (the most performance-sensitive method). When using forEach * (as opposed to iterators), we can normally only detect * interference after actions, not before. Further * CME-triggering checks apply to all other possible * violations of assumptions for example null or too-small * elementData array given its size(), that could only have * occurred due to interference. This allows the inner loop * of forEach to run without any further checks, and * simplifies lambda-resolution. While this does entail a * number of checks, note that in the common case of * list.stream().forEach(a), no checks or other computation * occur anywhere other than inside forEach itself. The other * less-often-used methods cannot take advantage of most of * these streamlinings. */ private final ArrayList&lt;E&gt; list; private int index; // current index, modified on advance/split private int fence; // -1 until used; then one past last index private int expectedModCount; // initialized when fence set /** Create new spliterator covering the given range */ ArrayListSpliterator(ArrayList&lt;E&gt; list, int origin, int fence, int expectedModCount) { this.list = list; // OK if null unless traversed this.index = origin; this.fence = fence; this.expectedModCount = expectedModCount; } private int getFence() { // initialize fence to size on first use int hi; // (a specialized variant appears in method forEach) ArrayList&lt;E&gt; lst; if ((hi = fence) &lt; 0) { if ((lst = list) == null) hi = fence = 0; else { expectedModCount = lst.modCount; hi = fence = lst.size; } } return hi; } public ArrayListSpliterator&lt;E&gt; trySplit() { int hi = getFence(), lo = index, mid = (lo + hi) &gt;&gt;&gt; 1; return (lo &gt;= mid) ? null : // divide range in half unless too small new ArrayListSpliterator&lt;E&gt;(list, lo, index = mid, expectedModCount); } public boolean tryAdvance(Consumer&lt;? super E&gt; action) { if (action == null) throw new NullPointerException(); int hi = getFence(), i = index; if (i &lt; hi) { index = i + 1; @SuppressWarnings(&quot;unchecked&quot;) E e = (E)list.elementData[i]; action.accept(e); if (list.modCount != expectedModCount) throw new ConcurrentModificationException(); return true; } return false; } public void forEachRemaining(Consumer&lt;? super E&gt; action) { int i, hi, mc; // hoist accesses and checks from loop ArrayList&lt;E&gt; lst; Object[] a; if (action == null) throw new NullPointerException(); if ((lst = list) != null &amp;&amp; (a = lst.elementData) != null) { if ((hi = fence) &lt; 0) { mc = lst.modCount; hi = lst.size; } else mc = expectedModCount; if ((i = index) &gt;= 0 &amp;&amp; (index = hi) &lt;= a.length) { for (; i &lt; hi; ++i) { @SuppressWarnings(&quot;unchecked&quot;) E e = (E) a[i]; action.accept(e); } if (lst.modCount == mc) return; } } throw new ConcurrentModificationException(); } public long estimateSize() { return (long) (getFence() - index); } public int characteristics() { return Spliterator.ORDERED | Spliterator.SIZED | Spliterator.SUBSIZED; } } @Override public boolean removeIf(Predicate&lt;? super E&gt; filter) { Objects.requireNonNull(filter); // figure out which elements are to be removed // any exception thrown from the filter predicate at this stage // will leave the collection unmodified int removeCount = 0; final BitSet removeSet = new BitSet(size); final int expectedModCount = modCount; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) { @SuppressWarnings(&quot;unchecked&quot;) final E element = (E) elementData[i]; if (filter.test(element)) { removeSet.set(i); removeCount++; } } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } // shift surviving elements left over the spaces left by removed elements final boolean anyToRemove = removeCount &gt; 0; if (anyToRemove) { final int newSize = size - removeCount; for (int i=0, j=0; (i &lt; size) &amp;&amp; (j &lt; newSize); i++, j++) { i = removeSet.nextClearBit(i); elementData[j] = elementData[i]; } for (int k=newSize; k &lt; size; k++) { elementData[k] = null; // Let gc do its work } this.size = newSize; if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } modCount++; } return anyToRemove; } @Override @SuppressWarnings(&quot;unchecked&quot;) public void replaceAll(UnaryOperator&lt;E&gt; operator) { Objects.requireNonNull(operator); final int expectedModCount = modCount; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) { elementData[i] = operator.apply((E) elementData[i]); } if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } modCount++; } @Override @SuppressWarnings(&quot;unchecked&quot;) public void sort(Comparator&lt;? super E&gt; c) { final int expectedModCount = modCount; Arrays.sort((E[]) elementData, 0, size, c); if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } modCount++; } }","categories":[],"tags":[{"name":"-- Java基础 -- 源码","slug":"Java基础-源码","permalink":"http://laochenpi.top/tags/Java基础-源码/"}]},{"title":"Redis 缓存问题场景","slug":"Redis缓存场景","date":"2019-02-22T02:27:08.000Z","updated":"2019-03-27T02:16:16.136Z","comments":true,"path":"2019/02/22/Redis缓存场景/","link":"","permalink":"http://laochenpi.top/2019/02/22/Redis缓存场景/","excerpt":"","text":"记录下学习Redis缓存实际项目中会出现的一些场景和解决方案，缓存穿透、缓存击穿、缓存雪崩 Redis 缓存穿透缓存穿透是指缓存和数据库都查询到不到，例如查询UserId=-1的用户，当大量类似访问请求发送到服务端，由于数据库一直无法查找到数据则缓存无法更新和插入，后续大量的请求全部落到了DB上。导致DB数据库压力增大发生崩溃、变慢。 解决方案 在接口层面或者通过过滤器拦截器过滤掉一些恶意查询条件。 如果有查询不到的大量请求，可以设置Key-Null和TTL的时间设置30-60秒(具体根据实际业务需求来设定)，避免大量的后续恶意请求落在DB上。 Redis 缓存雪崩缓存雪崩是指缓存中大量的Key同一时间失效或缓存服务直接宕机导致大量的访问请求都落到了DB上，使得数据库压力过大导致连锁反应瘫痪宕机。 失效解决： 热门数据缓存设置TTL延长或者永久 数据的缓存设置随机TTL防止同一时间失效 服务宕机： Redis 高可用，使用主从+哨兵 redis cluster，避免全盘崩溃 本地 ehcache 缓存 + hystrix 限流/降级，避免DB被打死 Redis 持久化，一旦重启立刻恢复数据 3.Redis 缓存击穿缓存击穿是指同一个热门Key突然失效，大量的并发访问导致直接落在DB上，导致DB数据库压力增大宕机，与雪崩不同的是击穿是单一Key雪崩是大量热门Key。 数据的缓存TTL设置永久 使用互斥锁等待第一次请求缓存构建完成后释放锁，让其余所有请求直接通过缓存拿取数据。单机环境Lock类型，集群使用Setnx(set if not exits) 查考资料https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://laochenpi.top/categories/NoSql/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"http://laochenpi.top/tags/Redis/"}]},{"title":"Redis 持久化","slug":"Redis持久化","date":"2019-02-22T02:27:08.000Z","updated":"2019-03-27T02:16:16.135Z","comments":true,"path":"2019/02/22/Redis持久化/","link":"","permalink":"http://laochenpi.top/2019/02/22/Redis持久化/","excerpt":"","text":"记录学习Redis持久化，Redis为内存数据库当服务器异常关闭或重启会导致内存里的Redis数据丢失，Redis提供持久化方案来保证数据不丢失. Redis 持久化Redis持久化有多种不同级别的方式 RDB 持久化可以在指定时间范围内服务器生成数据集的Snapshot 时间点快照point-in-time(数据库中所有键值对数据) AOF 持久化记录服务器执行过的写操作命令，在服务启动通过执行命令来恢复数据集。AOF文件中的命令以Redis协议的格式保存，新命令会追加到文件末尾。 RDB AOF同时使用，在Redis重启时优先使用AOF进行数据恢复，因为AOF的保存的数据通常比RDB文件所保存的数据更完整。 关闭持久化，数据仅在服务器运行时存在 RDB 持久化-配置 save save m n (m 代表时间范围内 n 修改次数) 例如默认配置文件中的save 900 1 900秒内至少有一个Key发生变化则保存。 stop-writes-on-bgsave-error 默认值yes，当Redis后台保存失败时是否停止接受写操作。如果已经设置一些监控可选择关闭。 rdbcompression 默认值yes，对存储到磁盘的快照文件是否进行压缩(LZF算法压缩)，压缩会消耗一定CPU性能，具体根据实际情况设置是否压缩。 rdbchecksum 默认值yes，对于存储的快照文件使用CRC64算法进行数据校验，校验大概消耗10%的性能，如需大量性能可关闭跳过校验过程。 dbfilename 默认值 dump.rbd， 快照文件的名称。 dir 默认当前目录，快照文件的存放文件路径 RDB 优点 Redis在保存RDB会fork出子进程进行，几乎不影响Redis处理效率。 RDB非常适合灾难恢复（disaster reconvery），每次快照会生成完整的快照文件，可根据业务需求进行多备云备份。 RDB在恢复大数据集时比AOF速度更快。 RDB 缺点 RDB快照是定期生成，在时间范围内服务发生宕机可能导致会丢失部分数据 RDB在大数据快照生成上会消耗大量CPU性能，如CPU性能不足或紧张时会影响Redis对外服务。 AOF 持久化AOF（append-only file）持久化:将Redis执行的每一条写请求都记录在一个日志文件里，在Redis启动后会执行所有的写操作达来恢复数据。AOF 默认是关闭状态，AOF 提供3种fsync配置 appendfsync no 不进行fsync，由OS来决定什么时候进行同步，速度最快 appendfsync always 每一次操作都进行fsync，速度较慢 appendfsync everysec 折中的做法，交由后台线程每秒fsync一次 AOF优点数据更安全，在配置 appendfsync always或 appendfsync everysec会及时把每条执行的写操作都记录都追加到AOF文件末尾即使是服务出现故障至多损失1s之内的数据。 查考地址http://doc.redisfans.com/topic/persistence.htmlhttps://baijiahao.baidu.com/s?id=1611955931705092609&amp;wfr=spider&amp;for=pc","categories":[{"name":"NoSql","slug":"NoSql","permalink":"http://laochenpi.top/categories/NoSql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://laochenpi.top/tags/Redis/"}]},{"title":"Docker 环境搭建","slug":"Docker环境搭建","date":"2018-08-20T06:11:30.000Z","updated":"2019-03-27T02:16:16.222Z","comments":true,"path":"2018/08/20/Docker环境搭建/","link":"","permalink":"http://laochenpi.top/2018/08/20/Docker环境搭建/","excerpt":"","text":"开发-&gt;部署测试-&gt;发布正式 在整体流程中每个人的开发环境可能各不相同、编译环境、运行环境。单机服务调整控制环境版本等可以保证发布一致性，但是如果当业务越来越庞大集群处理时需要部署多台机器时，可能每台机器的大大小小差异都会导致发布失败，处理起来非常麻烦。docker虚拟化来处理能保证发布环境一致性，可移植。通过docker 镜像你可以在任何版本linux服务器上进行发布。每个镜像就相当于个一个系统相互不影响独立环境。 1.Docker 介绍Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 2.Docker 安装我的VPS用的Centos 7 那就用本版本记录搭建过程，docker的版本用CE社区版12345678910#下载yum-utils工具用于管理yum-config-manager可以配置源yum install yum-utils#添加docker-ce源yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#查询docker-ce版本yum list docker-ce --showduplicates | sort -r #指定安装18.06.0 版本yum install dock-ce-18.06.0.ce&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD======= 安装docker，默认是安装最高版本测试可以用，但是生产环境为了稳定尽量指定版本(stable稳定版) 3.Docker 常用命令12345&gt;&gt;&gt;&gt;&gt;&gt;&gt; 89e26ef27826ebc8a8b06014969c8ead3bb74a3e#启动docker服务systemctl start docker#自动启动docker服务systemctl enable docker 安装docker,默认是安装最高版本测试可以用，但是生产环境为了稳定尽量指定版本(stable稳定版) 3.Docker 镜像 容器镜像查询拉取安装 docker 完毕，可以尝试安装一个镜像并运行，搜索镜像使用 docker search [镜像名称],搜索的镜像 OFFICAL 标识的为官方镜像，其余的都是非官方人员自行构建的镜像并上传库共享。使用 docker pull alpine 下载拉取alpine镜像,然后使用docker images 查看镜像已有镜像，这里以alpine为模板 运行容器基于alpine镜像启动一个容器1docker run -itd -p 8081:8081 --name myTest alpine -i：以交互模式运行容器，通常与 -t 同时使用 -d: 后台运行容器，并返回容器ID -t : 为容器重新分配一个伪输入终端，通常与 -i 同时使用 -p: 端口映射，格式为：主机(宿主)端口:容器端口 8080端口的访问转发到容器的8080端口上 –name: 为容器指定一个容器名 alpine：这是指用 alpine 镜像为基础来启动容器。 启动完毕后 docker ps 查看正在运行的容器, docker ps -a 查看容器。 容器操作1234567891011##### myTest 为容器名称 ##### #进行容器docker attach myTest#容器中执行脚本返回结果 (由于是alpine所以执行的)docker exec -it myTest /bin/sh#删除容器docker rm myTest#启动已有容器docker start myTest#停止容器docker stop myTest 在容器中退出容器时需要注意的是通过exit返回宿主主机会导致容器直接停止并不是我们想要的结果，官方给出的退出容器并使其在后台继续运行使用 ctrl+p+q 安全退出不影响容器运行。 4.DockerFileDockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。我们可以根据实际的开发需求通过dockerfile来自定义镜像，JUST DO IT！ FROM 指令FROM &lt;image>:&lt;tag> 相当于建造一个大楼地基的选择，选择不同的地基来搭建不一样的大楼。 操作系统类基础搭建例如 ubuntu、dabin、centos 开发语言作为基础搭建例如java、nodejs、python 服务类镜像作为基础 oralce、mysql、nginx、tomcat 自定义混合类作为基础在其他自定义环境镜像基础上搭建 所有的镜像地基都可以从docker库中拉取，选择合理的基础镜像可以让你更快的去构建你的镜像，省心省力。 RUN 指令RUN 就像是执行shell指令，常常用于更新安装需要的生产软件服务等。RUN有2种执行方式 shell 格式： RUN &lt;命令&gt; ，就像直接在命令行中输入的命令一样：RUN apt-get --update exec 格式： RUN [“可执行文件”, “参数1”, “参数2”]：RUN [&quot;apt-get&quot;,&quot;--update&quot;] 注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层.多少个RUN就构建了多少层镜像，会造成镜像的臃肿多层，不仅仅增加了构件部署的时间，还容易出错。RUN书写时的换行符是\\，记得下载压缩软件操作完毕后rm不必要的软件压缩包和缓存让镜像更精简。 CMD 指令CMD 指令的格式和 RUN 相似也是两种格式，CMD 执行脚本在dockerfile只能存在一条，多条只执行最后一条，当有多个时只会执行最后一个，一般用于执行开启某些服务 tomcat、oracle、nginx等。 ENTRYPOINT 指令ENTRYPOINT 执行脚本在dockerfile只能存在一条，多条只执行最后一条，容器启动后执行且不会被docker run提供的参数覆盖。 RUN ENTRYPOINT CMD 小结 CMD 和 ENTRYPOINT 推荐使用Exec格式，因为指令可读性更强，更容易理解。RUN 则两种格式都可以。 RUN用来执行脚本构建基础镜像，CMD ENTRYPOINT 用来构建完镜像容器启动后执行一些操作。 CMD 会被docker run 后的执行脚本覆盖不执行，ENTRYPOINT 则不会被覆盖始终会被执行，如果需要覆盖运行需要–entrypoint参数。 ENTRYPOINT 和 CMD 同时存在时谁在最后谁能执行，CMD 可作为 ENTRYPOINT 的执行参数灵活配合使用。 COPY 指令用于从上下文路径复制文件到容器目标路径中，copy package.json /usr/src/app/ 把package.json复制到容器 /usr/src/app路径下 COPY &lt;源路径&gt;… &lt;目标路径&gt; COPY [“&lt;源路径&gt;”，……，”&lt;目标路径&gt;”] ......代表若干源路径 ADD 指令ADD 指令和 COPY 的格式和性质基本一致，是在 COPY 基础上增加了一些功能。比如&lt;源路径&gt;可以是一个URL，这种情况下 Docker 引擎会试图去下载这个链接的文件放到&lt;目标路径&gt;去。如果&lt;源路径&gt;为一个tar 压缩文件的话，压缩格式为gzip , bzip2 以及 xz 的情况下，ADD指令将会自动解压缩这个压缩文件到&lt;目标路径&gt;去。ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢，ADD 还包含了一些复杂的的功能其行为也不一定清晰，所以官方推荐使用COPY来进行文件的复制。 ENV 指令ENV 用于设置环境变量在后续的指令可以直接引用 ENV &lt;key> &lt;value> ENV &lt;key1>=&lt;value1> &lt;key2>=&lt;value2>… Docker build构建所有的脚本编写完毕使用docker bulid 对 Dockerfile 进行构建，详细的命令如下12 123456#基于镜像 这里使用alpine 主要是体积小构建速度更快FROM alpine#构建维修者 MAINTAINER 285635652@qq.comRUN apt-get update / &amp;&amp; apt-get java","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"Winsw 把 java 项目做成服务","slug":"Winsw把java项目做成服务","date":"2018-08-16T12:04:17.000Z","updated":"2019-03-27T02:16:16.138Z","comments":true,"path":"2018/08/16/Winsw把java项目做成服务/","link":"","permalink":"http://laochenpi.top/2018/08/16/Winsw把java项目做成服务/","excerpt":"","text":"jar项目需要通过命令行jar -jar 执行脚本启动显示控制台，由于强迫症可以使用javaw -jar来执行可以在后台执行，但通过java编译启动在window环境下进程名都为java.exe一旦项目多了当你要更新部署更新关闭项目时候就懵逼了有可能就会误操作，通过Google发现有个开源的软件winsw 可以把任何软件做为window 的服务来管理，这样在services.msc 服务管理里可以很方便的进行管理更新部署。 1.Winsw 环境Winsw是个开源项目，Github地址为:https://github.com/kohsuke/winsw 依赖环境为NET2 或 NET4， 可通过配置文件进行修改。 2.JAVA 项目注册服务根据作者的介绍注册的服务依赖于配置文件 *.xml，这里需要注意的是xml的文件名称必须和winsw.exe同名。默认是按软件的名称来匹配配置文件。例如你把winsw.exe重复名为test.exe那配置文件必须为test.xml不然不无法使用。123456789&lt;service&gt; &lt;id&gt;MyTest&lt;/id&gt; &lt;name&gt;MyTest&lt;/name&gt; &lt;description&gt;测试jar项目服务&lt;/description&gt; &lt;env name=\"JENKINS_HOME\" value=\"%BASE%\"/&gt; &lt;executable&gt;java&lt;/executable&gt; &lt;arguments&gt;-Xrs -Xmx256m -jar \"%BASE%\\test.jar\" --httpPort=8080&lt;/arguments&gt; &lt;logmode&gt;rotate&lt;/logmode&gt;&lt;/service&gt; 配置文件解释: id：服务名称 (唯一) name：显示服务名称 description：服务描述 env：环境变量 JENKINS_HOME 赋值给 %BASE% executable：执行命令 这里我们是用java启动 arguments：执行的一些参数 logmode：日志模式这里 executable arguments 就相当于你在控制台执行的脚本，根据你的需求进行改变命令和参数。通过控制台进入winsw软件目录执行winsw.exe install 注册服务， winsw为软件名称可以自行修改。执行成功可以在控制看到 如果发现错误请查看 [软件名称].wrapper.log 日志排查，是否配置文件名和软件名不一致或者配置的地址不存在等。然后你可以通过 services.msc 对你的服务进行操作了启动，停止。注册的服务默认是AutoStart每次重启电脑都会自动启动。 配置文件的相关其他设置可以参考: https://github.com/kohsuke/winsw/blob/master/doc/xmlConfigFile.md","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"SpringCloud 服务中心之 Eureka","slug":"SprintCloud微服务-Eureka","date":"2018-08-01T08:43:15.000Z","updated":"2019-03-27T02:16:16.137Z","comments":true,"path":"2018/08/01/SprintCloud微服务-Eureka/","link":"","permalink":"http://laochenpi.top/2018/08/01/SprintCloud微服务-Eureka/","excerpt":"","text":"SpringCloud微服务架构基于SpringBoot进行开发组件，即插即用非常方便，用了Spring Boot根本停不下来。SpringCloud包含了服务和注册中心(Zookeeper Eureka Consul)、熔断器(Hystrix)、动态路由(Zuul)、配置中心(Spring cloud config)、负责均衡(Ribbon)、REST服务调用(Fegin)等集成组件。让我们一步步通过项目来学习SpringCloud！ 1. Eureka 服务发现和注册Eureka 是 Netflix 旗下微服务开发组件，用于服务发现和注册中心，分为服务端和客户端，服务端作为注册中心作为其他客户端的提供注册服务，客户端将需要暴露的接口服务注册到服务端中，通过周期性向服务端发送心跳保证自身健康可用性。 2. EurekaServer 注册中心搭建首先建立项目使用maven来构建项目，pom.xml依赖关系如下本项目用最新的版本进行教程，相关的官方教程可查看Spring Cloud Eureka pom.xml maven依赖配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;EurekaServer&lt;/artifactId&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--项目构建maven插件--&gt;&lt;build&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt;&lt;/project&gt; SpringBoot 启动配置项1234567891011121314package com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;@SpringBootApplication@EnableEurekaServer@EnableWebSecuritypublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class，args); &#125;&#125; WebSecurityConfig 安全认证配置123456789101112131415package com.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;@Configurationpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable(); //关闭csrf http.authorizeRequests().anyRequest().authenticated().and().httpBasic(); //开启认证 &#125;&#125; application.yml 基本配置项12345678910111213141516#Eureka 服务中心设置 eureka: client: #自身不注册 register-with-eureka: false #是否开启检索服务 fetch-registry: false#security安全校验 spring: security: user: name: root password: 123123#服务器端口设置server: port: 8888 启动项目通过 http://localhost:8888 查看Eureka注册中心管理页面，为了安全性加入了security安全校验，输入账号密码进入管理页面。 3. EurekaClient 服务搭建pom.xml maven依赖配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;EurekaClient&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; SpringBoot 启动配置项1234567891011121314151617181920212223242526package com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@EnableEurekaClient@RestControllerpublic class Application &#123; @RequestMapping(\"/test1\") public String myTestService()&#123; return \"测试1\"; &#125; @RequestMapping(\"/test2\") public String myTestService2()&#123; return \"测试2\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class，args); &#125;&#125; application.yml配置123456789# 设置服务名spring: application: name: EurekaClient1# 设置注册中心地址 root:123123为注册中心设置的账号密码eureka: client: service-url: defaultZone: http://root:123123@localhost:8888/eureka","categories":[{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://laochenpi.top/tags/Spring/"}]},{"title":"Hexo部署到VPS自动发布","slug":"Hexo部署到VPS自动发布","date":"2018-07-26T07:02:30.000Z","updated":"2019-03-27T02:16:16.127Z","comments":true,"path":"2018/07/26/Hexo部署到VPS自动发布/","link":"","permalink":"http://laochenpi.top/2018/07/26/Hexo部署到VPS自动发布/","excerpt":"","text":"Hexo部署到github访问的速度较慢，所以想着把Hexo直接丢在自己VPS上去，部署一套git环境以后方便自动发布更新 1.Git 安装1234#通常使用的方法下载gityum -y install git#查看版本 这种下载一般不是最新的版本yum --version 发现并不是最新版本逼死强迫症啊，只能通过下载最新git源码自行编译安装。Git 的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具。在有 yum 的系统上（比如 Fedora）或者有 apt-get 的系统上（比如 Debian 体系），可以用 下面的命令安装： 12345678910111213141516171819202122#卸载旧版本gityum remove git#安装依赖环境yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel#安装编译工具yum install gcc perl-ExtUtils-MakeMaker#下载最新版gitwget https://github.com/git/git/archive/v2.19.1.tar.gz#解压tar -zxvf v2.18.0.tar.gz#进入解压文件夹cd git-2.18.0#编译代码 perfix这里为赋值变量make prefix=/usr/local/git all#安装软件 make prefix=/usr/local/git install#清除编译数据make clean all#环境变量配置echo export PATH=$PATH:/usr/local/git/bin &gt;&gt;/etc/bashrc#生效环境变量source /etc/bashrc /etc/profile，/etc/bashrc 是系统全局环境变量设定 ~/.profile，~/.bashrc用户家目录下的私有环境变量设定 2.创建 git 仓库创建一个git库用来存放Hexo生成的html静态文件和相关资源，然后通过 post-receive 钩子函数进行自动执行脚本讲生成的资源checkout发布到nginx达到自动发布更新的功能。1234567891011121314#创建git用户adduser git#设置密码passwd git#创建Hexo博客库 目录自行选择mkdir laochenpiBlog &amp;&amp; chown git:git laochenpiBlog#laochenpiBlog目录下创建blog.git --bare裸仓库 没有工作空间git init --bare blog.git &amp;&amp; chown git:git -R blog.git #laochenpiBlog 目录下创建静态网页库 mkdir blog.site &amp;&amp; chown git:git blog.site#进入钩子函数目录cd hooks/#创建钩子函数文件touch post-receive &amp;&amp; chown git:git post-receive &amp;&amp; chmod 755 post-receive 为Hexo编写自动化脚本在仓库hooks创建脚本 vi post-receive ，脚本会在git有收发的时候就会调用执行1git --work-tree=/var/laochenpiBlog/blog.site --git-dir=/var/laochenpiBlog/blog.git checkout -f 3.Hexo 配置发布测试终于把Git环境弄好了，现在就需要修改配置文件_config.yml 中的发布项1234567#Deployment## repo 为你的vps创建的库地址## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo : git@45.77.87.214:/var/laochenpiBlog/blog.git branch: master 修改完毕，见证奇迹的时候到了，找到自己博客目录下用 git bash 发布 12#清除缓存 重编译 发布hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 输入密码发布完毕，然后远程上你的VPS查看下你的 blog.site 是否自动 check out了最新发布的内容了。 4.Git 免密发布每次发布都需要输入密码实在是太麻烦了而且在有可能泄露密码引起安全问题，有什么比较方面安全的方式呢，通过google一波发现可以通过秘钥的形式实现无密码发布登录。 秘钥方式通过RSA加密生成公有秘钥，然后把公有秘钥提交到VPS 上的秘钥认证文件中 authroized_keys，修改 OpenSSH 客户端的配置 sshd_config 实现RSA秘钥认证方式。 那么我们开始吧！ 服务器端修改 OpenSSH 认证 vi /etc/ssh/sshd_config开启公钥认证 PubkeyAuthentication yes认证Keys文件目录 用户/.ssh/文件名 AuthorizedKeysFile .ssh/authorized_keysRSA加密认证 RSAAuthentication yes 这里要提示一点 Centos 7 和 Centos 6 遇到的问题，Centos 7 由于OpenSSH版本原因 RSAAuthentication 已经弃用，无需添加修改.123456#用户提交的git用户的秘钥文件夹创建和权限分配#——————————————————————————————————————#创建认证文件authorized_keystouch /home/git/.ssh/authorized_keys#.ssh权限 700 authorize_keys 权限600chmod 700 /home/git/.ssh &amp;&amp; chmod 600 /home/git/.ssh/authorize_keys 这里要注意 .ssh 和 authorize_keys 的权限问题，可能在加密认证的时候由于权限导致失败，SSH登录日志可以用 tail /var/log/secure 查看，sshd -t进行查看配置是否正常 需要在~目录下执行，执行systemctl restart sshd 重启 SSH服务 客户端ssh-keygen -t rsa -C userName 生成秘钥文件，地址一般在 ~/.ssh 中。id_rsa 加密公钥 id_rsa.pub 加密公钥 多用户用cat 追加秘钥到认证文件中 12#上传认证秘钥到服务器上 对应用户的authorized_keys中cat ~/.ssh/id_rsa.pub | ssh git@45.77.87.214 \"cat - &gt;&gt; /home/git/.ssh/authorized_keys\" 配置完毕后使用 ssh -vvT git@45.77.87.214 看看是不是不用密码就可以登录VPS了，然后发布就再也不用密码了，一条命令就OK。 5. Nginx配置映射终于到最后一步了，就差最后一步配置 Nginx 服务映射静态文件了。123456#Centos yum源安装yum install nginx#启动nginx服务systemctl start nginx#查看服务状态systemctl status nginx -l 这里有可能出现的问题：1.无法从外网访问 检查下80端口是否开启，添加80端口firewall-cmd --permanent --zone=public --add-port=80/tcp --permanent 和 firewall-cmd --reload 重载配置2.服务可能没有启动成功，排查下配置问题 修改80端口默认映射库地址，nginx -t查看nginx配置文件地址 12345678#停止Nginx服务systemctl stop nginx#修改Nginx的配置文件rootvi /etc/nginx/nginx_conf#修改 root 配置hexo静态文件地址，即之前创建的静态文件地址root [hexo静态文件地址]#修改完毕退出 重启Nginx服务systemctl start nginx 修改完毕启动好服务然后通过外网访问你 VPS IP地址即可访问，大功告成以后可以在任意地方通过git提交的方式进行自动发布。请记得随时备份自己的重要文件以免丢失！ 遇到的问题已配置秘钥但是SSH还是需要密码，相信很多小伙伴都遇到过，下面是可能原因 查看sshd_config 配置文件是否正确开启了3个认证配置，更改后重启OpenSSH服务 查看下ssh登录日志 排查下原因，可能是认证文件目录权限问题，.shh 700 authorized_key 600 过大或者过小的权限都有可能导致认证是失败。 authorized_key 中秘钥千万千万不要直接从客户端直接复制过来，可能会有空格和其他转义一些特殊情况导致秘钥不正确。可通过 cat或scp 命令远程进行上传秘钥保证正确性。 Centos 7 版本的 OpenSSH RSAAuthentication已经弃用无需设置、添加该设置可能导致启动异常。","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux-文件权限管理","slug":"Linux-文件权限管理","date":"2018-07-25T07:07:09.000Z","updated":"2019-03-27T02:16:16.216Z","comments":true,"path":"2018/07/25/Linux-文件权限管理/","link":"","permalink":"http://laochenpi.top/2018/07/25/Linux-文件权限管理/","excerpt":"","text":"为了保证文件系统的安全隐私，对文件进行权限控制，防止非法用户查看、修改、删除等操作。只有在指定用户或用户组才能进行操作，例如一些隐私文件或者文件夹不想被其他人进行访问查看可对文件进行权限控制。 1. ls 命令查询文件属性12345678910111213[root@vultr ~]# ls -altotal 44dr-xr-x--- 4 root root 4096 Jul 19 05:05 .dr-xr-xr-x 18 root root 4096 Jun 5 21:42 ..-rw------- 1 root root 4369 Jul 25 07:02 .bash_history-rw-r--r-- 1 root root 18 Dec 29 2013 .bash_logout-rw-r--r-- 1 root root 176 Dec 29 2013 .bash_profile-rw-r--r-- 1 root root 176 Dec 29 2013 .bashrcdrwx------ 3 root root 4096 Jul 18 07:35 .cache-rw-r--r-- 1 root root 100 Dec 29 2013 .cshrcdrwxr----- 3 root root 4096 Jun 5 21:45 .pki-rw-r--r-- 1 root root 129 Dec 29 2013 .tcshrc[权限] [连接数][所有者][用户组][文件容量][修改时间] [文件名] [权限]第一个字符代表文件是 “目录、文件或链接文件等” [d] 代表是目录，例如 .pki [-] 代表是文件，例如 .tcshrc [l] 代表为链接文件(linkfile) [b] 代表设备文件里的可以供存储的接口设备 [c] 代表设备文件里的串行端口，例如键盘、鼠标接下来的3个为位一组，均为 “rwx” 3个参数组合 [r] 代表read 可读 [w] 代表write 可写 [x] 代表execute 可执行 [-] 代表没有权限 第一组代表 “文件所有者的权限”，第二组代表 “同用户组的权限”，第三组代表 “其他非本用户组的权限” [连接数] 文件的硬链接个数 [所有者] 文件的所有者账号 [用户组] 文件的所有用户组 [文件容量] 文件的容量 单位/B [修改时间] 文件的创建时间或最近的一次修改时间 [文件名] 文件的名称 带 “.” 则表示当前文件为隐藏文件 3.改变文件属性和权限命令 chgrp 改变文件所属用户组改变的用户组必须存在于/etc/group，对于不存在的用户组改变会执行失败 1234#示例 [-R] 递归 文件或者目录下所有的的文件chgrp [-R] [文件或目录]#更新install.log用户组为userchgrp user install.log chown 改变文件所有者改变的用户必须存在于/etc/passwd，对于不存在的用户改变会执行失败 123456#示例 [-R] 递归 文件或者目录下所有的的文件chown [-R] [文件或目录]#更新install.log用户所属为testchown test install.log#可用.[用户组] 改变用户组 将install.log所属用户组改为groupTestchown .groupTest install.log chmod 改变文件的权限改变rwx 读写执 3个权限，3个身份owner，group，others，组合9个权限。 数字类型改变权限:权限rwx按分数 r : 4 w : 2 x : 1，改变权限的组合方式按分数来决定权限rwxrwxrwx 对应777，rw–wx— 对应610 1234#示例 [-R] 递归 文件或者目录下所有的的文件chmod [-R] [分数组合] [文件或目录]#改变install.log的权限 763代表了 rwxrw---xchown 763 install.log 符号类型改变权限:权限rwx按符号 u(user)，g(group)，o(others)，a(all)，+(加入)，-(除去)，=(设置)组合。 123456#用户拥有读写，用户组读，其他执行 u=rw-，g=r--，o=--xchmod u=rw-，g=r--，o=--x install.log#所有身份都去除写权限 chmod a-r install.log#所有身份都添加执行权限chmod a+x install.log 2.RWX 对于文件和目录的差别对于文件来说： r (read) 可以读取文件的实际内容 w (write) 可以编辑、新增、或修改文件的内容，但是不能删除文件 x (execute) 可以执行，可执行并非由文件的后缀来决定例如常见的.exe .bat .com 等，而是由x 属性来决定 对于文件目录来说： r (read contents in directory) 可以查询该目录下的文件名数据既可使用ls查询 w (modify contents of directory) 可以新建新的文件和目录、删除已存在的文件和目录（无视改文件的权限控制）、转义目录内的文件和文件夹 x (access directory) 可以进入该目录文件 既可使用cd进入该目录","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 关机重启命令","slug":"Linux-关机重启命令","date":"2018-07-25T05:50:04.000Z","updated":"2019-03-27T02:16:16.128Z","comments":true,"path":"2018/07/25/Linux-关机重启命令/","link":"","permalink":"http://laochenpi.top/2018/07/25/Linux-关机重启命令/","excerpt":"","text":"记录学习鸟哥的私房菜之开启重启shell笔记，主要有命令shutdown，reboot，halt，poweroff 1.Shutdown 命令介绍 可以自由的选择关机模式：关机、重启或者进入单用户操作模式即可 可以设置关机时间：设置在特定时间或经过多少时长后关闭，也可以立刻关闭 可以自定义关机消息：在关闭服务可以通知其他登录的用户 可以发送警告命令：在执行一些测试脚本或者可以影响到其他的登录用户的操作时，可以发送警告信息进行提示，但不是真的关机 12345678910#脚本参数 shutdown [-t秒] [-arkhncfF] 时间 [警告消息]-t sec： -t 后单位/秒 经过多少秒后执行-k ：不是真关机仅发出警告信息-r ：服务关闭后，关闭并重启-h : 服务关闭后，立刻关机-c ：取消已经在进行中的关闭操作-f ：关机启动后，启动略过fsck磁盘检查-F ：关机启动后 ，强制进行fsck磁盘检查# 3600秒后进行关闭并提示警告语shutdown -t 3600 'Computer will shutdown after 30 min'","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Log4j 自定义多文件分离","slug":"Log4j-学习笔记","date":"2018-07-20T09:32:59.000Z","updated":"2019-03-27T02:16:16.130Z","comments":true,"path":"2018/07/20/Log4j-学习笔记/","link":"","permalink":"http://laochenpi.top/2018/07/20/Log4j-学习笔记/","excerpt":"","text":"在工作开发中遇到一个需求需要通过某一些条件逻辑进行分组细化日志，用配置的一些条件进行不同的日志管理和处理，由于之前的日志没有细化会导致在很多日志中无法更快和更精准的定位某一个模块的错误，如大海捞针效率极低，细分后方便开发和维护人员对日志更快更精准的排查修改BUG。 1.Log4j 介绍 Log4j有三个主要的组件：Loggers(记录器)，Appenders (输出源)和Layouts(布局)。这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。 2.Log4j 组件Appender 配置 ConsoleAppender (控制台) Threshold=WARN：指定日志信息的最低输出级别，默认为DEBUG。 ImmediateFlush=true：消息都会被立即输出，设为false则不输出，默认值是true。 Target=System.err：默认值是System.out。 FileAppender (文件) Append=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。 File=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。 DailyRollingFileAppender (按照日期格式生成) DatePattern=’.’yyyy-MM：根据时间格式按照年月日为单位生成log文件‘.’yyyy-MM：每月‘.’yyyy-ww：每周‘.’yyyy-MM-dd：每天‘.’yyyy-MM-dd-a：每天两次‘.’yyyy-MM-dd-HH：每小时‘.’yyyy-MM-dd-HH-mm：每分钟 RollingFileAppender (文件大小到达指定尺寸的时候产生一个新的文件) MaxFileSize=100KB：后缀可以是KB， MB 或者GB。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。 MaxBackupIndex=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文 SocketAppender (发送远程服务 Tip:可配合logstash使用) host，String，指定服务器的主机名。（必需） immediateFlush，boolean，是否立即flush，还是等待缓存到一定大小后在flush。 layout，Layout，log event输出的格式。 port，integer，远程服务器坚挺log event的应用的端口号。 protocol，String，发送log event所使用的协议，”TCP” 或”UDP”。 reconnectionDelay，integer，当连接断开时，延迟等待的ms数。 name，String ，Appender的名称。 protocol，String，通讯协议 默认TCP。可选值 “TCP” (default)， “SSL” or “UDP”. SSL，SslConfiguration，包含密钥存储库和信任存储库的配置. filter，Filter，一个过滤器来确定事件应该由这个Appender。 不止一个过滤器 可以通过使用一个CompositeFilter。 immediateFail，boolean，设置为true时，日志事件不会等待尝试重新连接，将立即如果失败 套接字是不可用的。 immediateFlush，boolean， 当该值设置成真时，默认情况下，每个写将冲洗。 这将保证写的数据 到磁盘，但可能会影响性能。 layout，Layout，LogEvent ，布局使用格式。 缺省值是SerializedLayout。 reconnectionDelay，integer ，如果设置为值大于0，一个错误后SocketManager将尝试重新连接 在指定的毫秒数后的服务器。 如果连接失败 将抛出一个异常(可以被应用程序如果ignoreExceptions是 设置为假)。 ignoreExceptions，boolean，默认值是真正的添加事件时，遇到了引起异常 内部记录，然后忽略。 当设置为假将传播到异常 调用者。 你必须设置这个假当包装这个AppenderFailoverAppender。 SMTPAppender (发送邮件) smtpHost= mtp.163.com：邮件服务器地址 smtpPort=30 ：端口号 from= *@.com：发送方邮箱 replyTo = *@.com： 接收方方邮箱 smtpUsername = 285635652@qq.com：发送方邮箱账号 smtpPassword = **：发送方邮箱密码 log4j.additivity.[appenderName]=false (用于独立输出日志，Logger只会在自己的appender里输出，而不会在父Logger的appender里输出。)默认为true Layouts HTMLLayout（以HTML表格形式布局） PatternLayout（可以灵活地指定布局模式） SimpleLayout（包含日志信息的级别和信息字符串） TTCCLayout（包含日志产生的时间、线程、类别等信息） 3.Spring 运用 Log4j123456789101112131415161718192021222324252627282930313233343536373839# LOG4J配置log4j.rootCategory=INFO， stdout， filelog4j.logger.errorfile=error，errorfile# 控制台输出log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n# root日志输出log4j.appender.file=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.file.file=logs/all.loglog4j.appender.file.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n# error日志输出log4j.appender.errorfile=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.errorfile.file=logs/error.loglog4j.appender.errorfile.DatePattern=&apos;.&apos;yyyy-MM-ddlog4j.appender.errorfile.Threshold = ERRORlog4j.appender.errorfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.errorfile.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L - %m%n#自定义业务分组 team mytest输出目标log4j.logger.team=INFO，mytest#自定义日志输出#输出的各种Appenderlog4j.appender.mytest=org.apache.log4j.DailyRollingFileAppender#父类节点不输出 分级log4j.additivity.team=false#输出的日志地址log4j.appender.mytest.file=logs/mytest.log#记录的时间单位 天 log4j.appender.mytest.DatePattern=&apos;.&apos;yyyy-MM-dd#布局log4j.appender.mytest.layout=org.apache.log4j.PatternLayout#输出内容log4j.appender.mytest.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss，SSS&#125; %5p %c&#123;1&#125;:%L ---- %m%n 讲解 rootCategory 主节点 [日志级别]，[输出目标]，[输出目标]，[…] category 子节点 特别会集成主节点的设置 日志级别 log4j.appender.[输出目标] 日志的输出设置 包含输出格式、布局、方式等 优先级：DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL PatternLayout 布局 ConversionPattern相关设置%m 输出代码中指定的消息%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL%r 输出自应用启动到输出该log信息耗费的毫秒数%c 输出所属的类目，通常就是所在类的全名%t 输出产生该日志事件的线程名%n 输出一个回车换行符，Windows平台为“rn”，Unix平台为“n”%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyyy MMM ddHH:mm:ss，SSS}，输出类似：2002年10月18日 22：10：28，921%l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。[QC]是log信息的开头，可以为任意字符，一般为项目简称。","categories":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://laochenpi.top/tags/Java/"}]},{"title":"CentOs FireWall 脚本","slug":"CentOs-Firewalld-脚本","date":"2018-07-19T06:20:43.000Z","updated":"2019-03-27T02:16:16.126Z","comments":true,"path":"2018/07/19/CentOs-Firewalld-脚本/","link":"","permalink":"http://laochenpi.top/2018/07/19/CentOs-Firewalld-脚本/","excerpt":"","text":"经过之前自己搭建了Shadowsocks接触Linux慢慢想深入学习下一些常用Shell，之前在配置Shadowsocks遇到启动服务但是PC客户端连接没有网络，通过查阅一些教程发现Centos7默认开启了防火墙Firewall导致如果没有开放Shadowsocks的相关端口是无法访问的，现在记录下Firewall的一些相关命令 1.Firewalld 简介CentOs7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念，有图形界面和工具界面，由于我在服务器上使用，图形界面请参照官方文档，本文以字符界面做介绍，firewalld的字符界面管理工具是 firewall-cmd 默认配置文件有两个：/usr/lib/firewalld/ （用户配置地址） 和 /etc/firewalld/ （系统配置，尽量不要修改） 2.Zone 概念Firewall 能将不同的网络连接归类到不同的信任级别，Zone 提供了以下几个级别 drop: 丢弃所有进入的包，而不给出任何响应 block: 拒绝所有外部发起的连接，允许内部发起的连接 public: 允许指定的进入连接 external: 同上，对伪装的进入连接，一般用于路由转发 dmz: 允许受限制的进入连接 work: 允许受信任的计算机被限制的进入连接，类似 workgroup home: 同上，类似 homegroup internal: 同上，范围针对所有互联网用户 trusted: 信任所有连接 3.过滤规则过滤规则的优先级遵循如下顺序source&gt;interface&gt;firewalld.conf source: 根据源地址过滤 interface: 根据网卡过滤 service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 4.使用方法firewall-cmd [指令]–zone 作用域–permanent 永久修改–reload 重载生效–timeout=seconds 持续时间，一般用于调试 使用实例:1234567891011121314151617181920212223242526#查看开放的Zonefirewall-cmd --get-active-zones#查看firewalld状态firewall-cmd --state#查看firewalld开放的端口firewall-cmd --zone=dmz --list-ports#重新加载配置 (无需重启)firewall-cmd --reload#重新加载配置 (重启服务器加载)firewall-cmd --complete-reload #添加一个端口允许访问 (临时添加)firewall-cmd --zone=dwz --add-port=8080/tcp#添加一个端口允许访问 (永久添加)firewall-cmd --zone=dwz --add-port=8080/tcp --permanent#添加一个端口允许访问 (持续300秒)firewall-cmd --zone=dwz --add-port=8080/tcp --timeout=300#添加一个服务允许访问firewall-cmd --zone=dwz --add-service=smtp#启用firewalldsystemctl start firewalld#停止firewalldsystemctl stop firewalld#重启firewalldsystemctrl restart firewalld#禁用firewalldsystemctrl disable firewalld","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Linux 搭建 Shadowsocks","slug":"Linxu搭建SS","date":"2018-07-13T08:25:43.000Z","updated":"2019-03-27T02:16:16.129Z","comments":true,"path":"2018/07/13/Linxu搭建SS/","link":"","permalink":"http://laochenpi.top/2018/07/13/Linxu搭建SS/","excerpt":"","text":"作为一个码农没有科学上网怎么能行，刚好Vultr新注册送钱买一个云主机玩玩，以CentOs7做一个教程，之前在网上找的搭建方法很多错误导致一直不成功现在自己整理并通过测试，踩了很多坑 1.Shadowsocks 环境准备12345678910#安装epel扩展源yum install epel-release#安装Pipyum -y install python-pip#升级Pippip install --upgrade pip #清除yum缓存yum clean all#安装shadowsocks客户端pip install shadowsocks 2.Shadowsocks 配置123456789101112131415161718192021222324252627#创建shadowsocks配置vi /etc/shadowsocks.json#单用户 &#123; \"server\":\"server_ip\"， \"server_port\":25， \"local_address\": \"127.0.0.1\"， \"local_port\":1080， \"password\":\"password\"， \"timeout\":300， \"method\":\"aes-256-cfb\"， \"fast_open\": false &#125;#多用户&#123; \"server\":\"server_ip\"， \"port_password\":&#123; \"port_1\":\"pwd1\"， \"port_2\":\"pwd2\"， \"port_3\":\"pwd3\" &#125;， \"local_address\":\"127.0.0.1\"， \"local_port\":1080， \"timeout\":300， \"method\":\"aes-256-cfb\"&#125; 参数详解: server 服务器地址 127.0.0.1 或者0.0.0.0 server_port 服务端口号 外部连接需要填写的服务端口号 local_port 本地端口号 password 连接密码 timeout 超时时间 method 加密方式 3.Shadowsocks 启动1234#启动ssserver -c /etc/shadowsocks.json -d start#停止ssserver -c /etc/shadowsocks.json -d stop 由于每次都需要服务器重启都需要手动去启动不便，可以注册成服务自动启动123456789101112131415#创建服务脚本 servicename 填写shadowsocksvi /etc/systemd/system/[servicename].service#编辑脚本[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json startExecStop=/usr/bin/ssserver -c /etc/shadowsocks.json stop[Install]WantedBy=multi-user.target 这里会遇到一个坑：ExecStart 这里填写的启动脚本 少了一个start不知道是不是我本身脚本问题 参数详解: Description服务描述 ExecStart 服务启动执行脚本 ExecStop 服务停止执行脚本 WantedBy 系统以该形式运行时，服务方可启动 4.Systemctl 命令注册服务 systemctl enable shadowsocks所有服务 systemctl list-units --type=service服务状态 systemctl status shadowsocks -l启动服务 systemctl start shadowsocks停止服务 systemctl stop shadowsocks重启服务 systemctl restart shadowsocks 5.Shadowsocks 客户端安装环境支持 Shadowsocks for Win Microsoft .NET Framework 4.6.2 Microsoft Visual C++ 2015 Redistributable (x86) 安装完毕配置启动即可 贴士提示 CentOs7需要配置下防火墙端口白名单1234#添加端口号8388(设置的server-port) --permanent永久生效firewall-cmd --zone=public --add-port=8388/tcp --permanent #重载配置firewall-cmd --reload","categories":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://laochenpi.top/tags/Linux/"}]},{"title":"Python验证码识别","slug":"Python 第三方库 PIL","date":"2018-05-25T08:27:08.000Z","updated":"2019-03-27T02:16:16.133Z","comments":true,"path":"2018/05/25/Python 第三方库 PIL/","link":"","permalink":"http://laochenpi.top/2018/05/25/Python 第三方库 PIL/","excerpt":"","text":"Python 第三方库 PIL Pytesseract tesseract-ocr 进行爬虫验证码识别 1.Python 第三方库依赖 通过cmd控制台进入python pip目录执行pip install requests 进行安装 其他的第三方库都可以通过这种形式进行安装12345678910#进入Python脚本文件夹cd C:\\Users\\serwer\\AppData\\Local\\Programs\\Python\\Python36-32\\Scripts#安装 requests 请求http库pip install requests #安装 pytesseract 基础识别库pip install pytesseract#安装 Image图片处理 为更好识别验证码pip install Image#显示requests相关信息pip show requests 可以通过配置pip环境变量达到在任意文件夹目录进行pip脚本执行 2.OCR图形识别软件 （Google维护的开源的OCR）Tesseract-ocr github地址 window 可选择Tesseract-ocr-setup-3.05.01.exe 123456789101112131415161718192021222324252627282930313233343536373839import requestsimport pytesseractfrom PIL import ImageimagePath = &quot;D:\\\\1.gif&quot;imageUrl = &quot;http://112.112.9.205:88/ValiateNum.ashx&quot;def getAuthCodeImage(): r = requests.get(imageUrl， stream=True) with open(imagePath， &apos;wb&apos;) as fd: for chunk in r.iter_content(1024): fd.write(chunk) fd.closedef disposeImage(): image = Image.open(imagePath) table = [] for i in range(256): if i &lt; 140: table.append(0) else: table.append(1) image = image.convert(&apos;L&apos;) image = image.resize((300，100)，Image.BILINEAR) image = image.point(table，&apos;1&apos;) image.save(&quot;D:\\\\1.png&quot;，&quot;png&quot;)def discernCode(): im=Image.open(&quot;D:\\\\1.png&quot;) code = pytesseract.image_to_string(im) print(code)#获取验证码并保存getAuthCodeImage()#验证码图片处理 灰阶处理disposeImage()#识别验证码discernCode()","categories":[{"name":"Python","slug":"Python","permalink":"http://laochenpi.top/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://laochenpi.top/tags/Python/"}]},{"title":"Logstash同步数据库","slug":"Logstah同步Es","date":"2018-05-25T08:27:08.000Z","updated":"2019-03-27T02:16:16.131Z","comments":true,"path":"2018/05/25/Logstah同步Es/","link":"","permalink":"http://laochenpi.top/2018/05/25/Logstah同步Es/","excerpt":"","text":"由于业务需求需要同步某些数据库的表数据更新修改删除需同步ES保证同步性，在进行curd用AOP可实现同步，但是考虑到解耦分离后续系统水平拓展，查询资料可以用Logstash进行同步Es，Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到Elasticsearch. 1.Logstash依赖环境 JDK1.8 下载地址 Ruby环境 下载地址 logstash 6.3.1 下载地址 2.Logstash同步配置文件 Logstash由三个组件构造成，分别是input、filter以及output。我们可以吧Logstash三个组件的工作流理解为：input收集数据，filter处理数据，output输出数据。至于怎么收集、去哪收集、怎么处理、处理什么、怎么发生以及发送到哪等等一些列的问题就是我们接下啦要讨论的一个重点。123456789101112131415161718192021222324252627282930313233343536input &#123; jdbc&#123; #数据库驱动jar包 jdbc_driver_library =&gt; &quot;\\policySyn\\ojdbc6.jar&quot; #数据库地址 jdbc_connection_string =&gt; &quot;jdbc:oracle:thin:@192.168.105.16:1523:gnnt&quot; #数据库用户名密码 jdbc_user =&gt; &quot;plane_tick&quot; jdbc_password =&gt; &quot;ora123&quot; #数据库驱动类 jdbc_driver_class =&gt; &quot;Java::oracle.jdbc.driver.OracleDriver&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; #执行sql绝对路径 或相对路径 statement_filepath =&gt; &quot;\\policySyn\\syn.sql&quot; #更新时间记录和存放 record_last_run =&gt; &quot;true&quot; last_run_metadata_path =&gt; &quot;\\policySyn\\synDate.txt&quot; #定时更新频率 20分钟一次 schedule =&gt; &quot;* * * * *&quot; #索引类型 type =&gt; &quot;policyteam_dev&quot; &#125;&#125;//同步目的地output &#123; elasticsearch&#123; hosts =&gt; &quot;http://192.168.105.13:9200&quot; index =&gt; &quot;policyteam_dev&quot; document_id =&gt; &quot;%&#123;zcbh&#125;&quot; &#125; stdout &#123; codec =&gt; json_lines &#125;&#125; 3.启动同步脚本进入Logstash目录bin文件夹下执行脚本12#config为执行配置文件绝对路径或相对路径logstash -f [config]","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/tags/技术/"}]},{"title":"Hexo+GitHub 第一次搭建笔记","slug":"hexo","date":"2018-05-24T06:48:00.000Z","updated":"2019-03-27T02:16:16.139Z","comments":true,"path":"2018/05/24/hexo/","link":"","permalink":"http://laochenpi.top/2018/05/24/hexo/","excerpt":"","text":"Hexo+GitHub 搭建踩坑行动，平时有什么代码心得或者遇到一些奇葩BUG、都没有记下来，后来遇到类似的问题居然又忘记了，所以想自己搭建一个博客记录下一些平时遇到的问题和需要解决的一些技术问题记录下来以便以后回来还可以查阅，就用Hexo搭建一个静态的博客。 1.Hexo 环境准备 Node.js hexo依赖环境 Git Bash 根据OS下载安装包 用于发布和更新微博 安装 Hexo12345678#1.安装hexo环境npm install hexo-cli -g #2.初始化hexo blog 文件夹和相关带代码 bolgName为文件夹名称hexo init [blogName]#3.进入博客文件夹cd blog#4.进行依赖更新安装npm install 常用指令12345678910111213141516#新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。$ hexo init [folder]#新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 #default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。$ hexo new [layout] &lt;title&gt;#生成静态文件。$ hexo g#发表草稿$ hexo publish [layout] &lt;filename&gt;# 启动服务器。默认情况下，访问网址为： http://localhost:4000/$ hexo s# 部署网站$ hexo deploy# -p， --port 重设端口# -s， --static 只使用静态文件# -l， --log 启动日记记录，使用覆盖记录格式 2.GitHub Page 准备 登录Github创建一个reqo，名称为 [yourname].github.io (这里注意下yourname最好跟你库的用户名一样) 本地使用git设置username 和email 12git config --global user.name [username]git config --global user.email [email] GitHub SSH KEY 设置 1ssh-keygen -t rsa -C [email] 秘钥 C:\\Users\\serwer\\.ssh\\id_rsa.pub 复制添加到Github SSH Key中 在 Git Bash 中验证是否添加成功：ssh -T git@github.com 配置_config.yml 发布静态文件到github，修改_config.yml进行github发布设置 1234deploy: type: git repo: git@github.com:[username]/[username].github.io.git branch: master 通过 Git Bash hexo d 进行发布更新到github 然后访问你的reqo page即可看到属于你自己的静态微博 可能遇到的问题： 解决方法:npm install --save hexo-deployer-git 安装hexo git发布插件然后执行hexo d","categories":[{"name":"技术","slug":"技术","permalink":"http://laochenpi.top/categories/技术/"}],"tags":[{"name":"心得","slug":"心得","permalink":"http://laochenpi.top/tags/心得/"}]}]}